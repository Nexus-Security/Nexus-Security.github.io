<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="The increasing prevalence of deep neural networks across diverse industries is undeniable. Their efficacy in addressing various challenges through supervised learning is well-documented. However, achieving optimal performance hinges on the availability of substantial, high-quality training data that accurately reflects the production setting. Although vast amounts of data exist online, a large portion remains unprocessed and unsuitable for machine learning (ML) applications. Consider the development of a traffic light detector for autonomous driving."><title>Improving AI Image Labeling and Semantic Metadata Gathering</title>
<link rel=canonical href=https://Nexus-Security.github.io/improving-ai-image-labeling-and-semantic-metadata-gathering/><link rel=stylesheet href=/scss/style.min.0304c6baf04e01a8fe70693791cb744d56a3578a3120a8796cefc66825aa39c7.css><meta property='og:title' content="Improving AI Image Labeling and Semantic Metadata Gathering"><meta property='og:description' content="The increasing prevalence of deep neural networks across diverse industries is undeniable. Their efficacy in addressing various challenges through supervised learning is well-documented. However, achieving optimal performance hinges on the availability of substantial, high-quality training data that accurately reflects the production setting. Although vast amounts of data exist online, a large portion remains unprocessed and unsuitable for machine learning (ML) applications. Consider the development of a traffic light detector for autonomous driving."><meta property='og:url' content='https://Nexus-Security.github.io/improving-ai-image-labeling-and-semantic-metadata-gathering/'><meta property='og:site_name' content='Nexus Security'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:published_time' content='2023-09-07T00:00:00+00:00'><meta property='article:modified_time' content='2023-09-07T00:00:00+00:00'><meta name=twitter:title content="Improving AI Image Labeling and Semantic Metadata Gathering"><meta name=twitter:description content="The increasing prevalence of deep neural networks across diverse industries is undeniable. Their efficacy in addressing various challenges through supervised learning is well-documented. However, achieving optimal performance hinges on the availability of substantial, high-quality training data that accurately reflects the production setting. Although vast amounts of data exist online, a large portion remains unprocessed and unsuitable for machine learning (ML) applications. Consider the development of a traffic light detector for autonomous driving."><link rel="shortcut icon" href=/fav.ico></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"light")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><ol class=menu-social><li><a href=https://github.com/Nexus-Security target=_blank title=GitHub rel=me><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="150" height="150" viewBox="0 0 150 150"><defs><filter id="alpha" filterUnits="objectBoundingBox" x="0" y="0" width="100%" height="100%"><feColorMatrix type="matrix" in="SourceGraphic" values="0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0"/></filter><mask id="mask0"><g filter="url(#alpha)"><rect x="0" y="0" width="150" height="150" style="fill:#000;fill-opacity:.2;stroke:none"/></g></mask><clipPath id="clip1"><rect x="0" y="0" width="150" height="150"/></clipPath><g id="surface5" clip-path="url(#clip1)"><path style="stroke:none;fill-rule:nonzero;fill:#fff;fill-opacity:1" d="M10.9375 83.867188c0-12.109376 3.46875-21.816407 10.925781-30.535157.71875-.875.925781000000001-2.058593.550781000000001-3.125C21.6875 48.125 21.40625 33.070312 26.488281 17.675781c4.78125 1.207031 16.300781 5.050781 31.65625 16.398438C58.9375 34.65625 59.957031 34.84375 60.894531 34.554688 64.824219 33.382812 71.851562 32.6875 79.6875 32.6875S94.550781 33.386719 98.476562 34.554688C99.417969 34.835938 100.433594 34.65625 101.226562 34.074219 113.96875 24.65625 124.011719 20.445312 129.8125 18.582031c-.476562000000001-1.882812-1.019531-3.746093-1.625-5.589843-4.78125 1.207031-16.300781 5.050781-31.648438 16.394531C95.746094 29.96875 94.730469 30.144531 93.789062 29.867188c-3.925781-1.171876-10.953124-1.875-18.789062-1.875-7.832031.0-14.855469.703124000000003-18.792969 1.871093C55.265625 30.144531 54.246094 29.964844 53.457031 29.382812c-15.355469-11.34375-26.875-15.1875-31.65625-16.402343C16.71875 28.382812 17 43.4375 17.726562 45.523438 18.101562 46.589844 17.890625 47.777344 17.175781 48.648438 9.71875 57.367188 6.25 67.070312 6.25 79.179688c0 23.515624 7.175781 37.921874 17.417969 46.550781C16.007812 116.851562 10.9375 103.582031 10.9375 83.867188zm0 0"/></g><mask id="mask1"><g filter="url(#alpha)"><rect x="0" y="0" width="150" height="150" style="fill:#000;fill-opacity:.101961;stroke:none"/></g></mask><clipPath id="clip2"><rect x="0" y="0" width="150" height="150"/></clipPath><g id="surface8" clip-path="url(#clip2)"><path style="stroke:none;fill-rule:nonzero;fill:#000;fill-opacity:1" d="M32.34375 78.5c3.945312-4 9.382812-5.074219 16.039062-5.074219C51.925781 73.425781 55.824219 73.730469 60.023438 74.054688c4.71875.375 9.589843.71875 14.84375.746093000000002C80.335938 74.917969 85.210938 74.425781 89.976562 74.054688 102.070312 73.125 111.605469 72.367188 117.648438 78.492188c4.527343 4.601562 6.890624 10.328124 7.21875 16.945312C124.925781 94.398438 125 93.382812 125 92.261719c0-7.285157-2.476562-13.492188-7.351562-18.449219-6.042969-6.117188-15.578126-5.367188-27.671876-4.4375C85.210938 69.742188 80.34375 70.238281 74.867188 70.117188 69.914062 70.0625 64.960938 69.8125 60.023438 69.375 55.824219 69.050781 51.929688 68.742188 48.382812 68.742188c-6.65625.0-12.09375 1.070312-16.039062 5.078124C27.476562 78.769531 25 84.976562 25 92.261719 25 93.375 25.074219 94.398438 25.132812 95.445312 25.460938 88.820312 27.820312 83.101562 32.34375 78.5zm0 0"/></g><linearGradient id="linear0" gradientUnits="userSpaceOnUse" x1="10.768" y1="13.86" x2="18.633" y2="21.724" gradientTransform="matrix(6.25,0,0,6.25,0,0)"><stop offset="0" style="stop-color:#000;stop-opacity:.101961"/><stop offset="1" style="stop-color:#000;stop-opacity:0"/></linearGradient><linearGradient id="linear1" gradientUnits="userSpaceOnUse" x1="4.004" y1="18.529" x2="4.047" y2="18.573" gradientTransform="matrix(6.25,0,0,6.25,0,0)"><stop offset="0" style="stop-color:#000;stop-opacity:.101961"/><stop offset="1" style="stop-color:#000;stop-opacity:0"/></linearGradient><linearGradient id="linear2" gradientUnits="userSpaceOnUse" x1=".617" y1="5.771" x2="23.69" y2="16.53" gradientTransform="matrix(6.25,0,0,6.25,0,0)"><stop offset="0" style="stop-color:#fff;stop-opacity:.2"/><stop offset="1" style="stop-color:#fff;stop-opacity:0"/></linearGradient></defs><g id="surface1"><path style="stroke:none;fill-rule:nonzero;fill:#303c42;fill-opacity:1" d="M138.570312 45.789062C139.492188 39.613281 138.867188 23.738281 133.167969 8.292969 132.660156 6.945312 131.300781 6.113281 129.867188 6.273438 129.269531 6.34375 115.1875 8.164062 94.039062 23.46875 89.445312 22.363281 82.632812 21.742188 75 21.742188s-14.4375.625-19.042969 1.726562C34.800781 8.15625 20.71875 6.34375 20.117188 6.273438 18.6875 6.117188 17.332031 6.949219 16.820312 8.292969 11.117188 23.738281 10.5 39.613281 11.425781 45.789062 3.742188 55.289062.0 66.230469.0 79.179688c0 41.632812 21.824219 64.558593 61.457031 64.558593L75 143.75 88.539062 143.738281C128.167969 143.738281 150 120.8125 150 79.179688c0-12.949219-3.742188-23.890626-11.429688-33.390626zm0 0"/><path style="stroke:none;fill-rule:nonzero;fill:#5c6671;fill-opacity:1" d="M88.539062 137.488281 75 137.5 61.457031 137.488281C36.273438 137.488281 6.25 127.367188 6.25 79.179688c0-12.109376 3.46875-21.816407 10.925781-30.535157.71875-.875.925781000000001-2.058593.550781000000001-3.125C17 43.4375 16.71875 28.382812 21.800781 12.988281c4.78125 1.207031 16.300781 5.050781 31.65625 16.398438C54.25 29.96875 55.269531 30.15625 56.207031 29.867188c3.9375-1.171876 10.960938-1.875 18.792969-1.875 7.835938.0 14.863281.703124000000003 18.789062 1.871093C94.730469 30.140625 95.746094 29.964844 96.539062 29.382812c15.347657-11.34375 26.867188-15.1875 31.648438-16.394531 5.082031 15.394531 4.804688 30.449219 4.082031 32.53125C131.867188 46.585938 132.078125 47.785156 132.820312 48.648438 140.273438 57.367188 143.75 67.070312 143.75 79.179688c0 48.1875-30.023438 58.308593-55.210938 58.308593zm0 0"/><use xlink:href="#surface5" mask="url(#mask0)"/><path style="stroke:none;fill-rule:nonzero;fill:#303c42;fill-opacity:1" d="M89.488281 63.144531C84.886719 63.507812 80.125 63.875 75.226562 63.875H74.78125C69.875 63.875 65.117188 63.5 60.519531 63.144531 47.898438 62.164062 35.988281 61.230469 27.894531 69.429688 21.824219 75.59375 18.75 83.28125 18.75 92.261719 18.75 128.238281 46.429688 131.25 75.226562 131.25c28.34375.0 56.023438-3.011719 56.023438-38.988281.0-8.988281-3.074219-16.667969-9.144531-22.835938-8.085938-8.195312-20.003907-7.269531-32.617188-6.28125zm0 0"/><path style="stroke:none;fill-rule:nonzero;fill:#d9cfcc;fill-opacity:1" d="M74.773438 125C42.492188 125 25 119.78125 25 92.261719c0-7.285157 2.476562-13.492188 7.34375-18.449219 3.945312-4 9.382812-5.074219 16.039062-5.074219C51.925781 68.738281 55.824219 69.042969 60.023438 69.367188c4.71875.375 9.589843.71875 14.84375.746093000000002C80.335938 70.230469 85.210938 69.738281 89.976562 69.367188c12.09375-.929687999999999 21.628907-1.6875 27.671876 4.4375C122.523438 78.769531 125 84.976562 125 92.261719 125 119.78125 107.507812 125 74.773438 125zm0 0"/><use xlink:href="#surface8" mask="url(#mask1)"/><path style="stroke:none;fill-rule:nonzero;fill:#303c42;fill-opacity:1" d="M50 75c-7.125.0-12.5 9.40625-12.5 21.875S42.875 118.75 50 118.75s12.5-9.40625 12.5-21.875S57.125 75 50 75zm0 0"/><path style="stroke:none;fill-rule:nonzero;fill:#6d4c41;fill-opacity:1" d="M50 112.5c-2.550781.0-6.25-6.085938-6.25-15.625S47.449219 81.25 50 81.25s6.25 6.085938 6.25 15.625S52.550781 112.5 50 112.5zm0 0"/><path style="stroke:none;fill-rule:nonzero;fill:#303c42;fill-opacity:1" d="M1e2 75c-7.125.0-12.5 9.40625-12.5 21.875S92.875 118.75 1e2 118.75s12.5-9.40625 12.5-21.875S107.125 75 1e2 75zm0 0"/><path style="stroke:none;fill-rule:nonzero;fill:#6d4c41;fill-opacity:1" d="M1e2 112.5c-2.550781.0-6.25-6.085938-6.25-15.625S97.449219 81.25 1e2 81.25s6.25 6.085938 6.25 15.625S102.550781 112.5 1e2 112.5zm0 0"/><path style="stroke:none;fill-rule:nonzero;fill:#a1887f;fill-opacity:1" d="M52.21875 90.511719c0 1.539062-1.246094 2.789062-2.789062 2.789062-1.539063.0-2.785157-1.25-2.785157-2.789062.0-1.539063 1.246094-2.785157 2.785157-2.785157 1.542968.0 2.789062 1.246094 2.789062 2.785157zm0 0"/><path style="stroke:none;fill-rule:nonzero;fill:#a1887f;fill-opacity:1" d="M102.21875 90.511719c0 1.539062-1.246094 2.789062-2.789062 2.789062-1.539063.0-2.785157-1.25-2.785157-2.789062.0-1.539063 1.246094-2.785157 2.785157-2.785157 1.542968.0 2.789062 1.246094 2.789062 2.785157zm0 0"/><path style="stroke:none;fill-rule:nonzero;fill:url(#linear0)" d="M125 72.8125 124.894531 72.855469C129.039062 78.382812 131.25 84.851562 131.25 92.261719c0 35.976562-27.679688 38.988281-56.023438 38.988281-16.664062.0-32.914062-1.054688-43.683593-8.875l13.386719 13.386719c5.507812 1.207031 11.121093 1.71875 16.527343 1.71875L75 137.5 88.539062 137.488281c22.992188.0 49.941407-8.53125 54.472657-46.664062zm0 0"/><path style="stroke:none;fill-rule:nonzero;fill:url(#linear1)" d="M25.070312 115.800781 25 115.832031 25.269531 116.101562zm0 0"/><path style="stroke:none;fill-rule:nonzero;fill:url(#linear2)" d="M138.570312 45.789062C139.492188 39.613281 138.867188 23.738281 133.167969 8.292969 132.660156 6.945312 131.300781 6.113281 129.867188 6.273438 129.269531 6.34375 115.1875 8.164062 94.039062 23.46875 89.445312 22.363281 82.632812 21.742188 75 21.742188s-14.4375.625-19.042969 1.726562C34.800781 8.15625 20.71875 6.34375 20.117188 6.273438 18.6875 6.117188 17.332031 6.949219 16.820312 8.292969 11.117188 23.738281 10.5 39.613281 11.425781 45.789062 3.742188 55.289062.0 66.230469.0 79.179688c0 41.632812 21.824219 64.558593 61.457031 64.558593L75 143.75 88.539062 143.738281C128.167969 143.738281 150 120.8125 150 79.179688c0-12.949219-3.742188-23.890626-11.429688-33.390626zm0 0"/></g></svg></a></li><li><a href=mailto:0x000216@gmail.com target=_blank title=Email rel=me><svg width="512" height="512" viewBox="0 0 512 512"><path d="M33.994 73.934C27.135 76.021 21.866 80.426 18.364 87 16.567 90.374 16.5 96.438 16.5 256V421.5l2.158 4C21.184 430.18 25.101 434.027 30 436.636 33.003 438.235 36.304 438.546 53.246 438.825L72.993 439.15l.253-137.978L73.5 163.194 90 175.45C99.075 182.191 140.17 212.762 181.321 243.386l74.821 55.68 21.179-15.752C288.97 274.65 330 244.021 368.5 215.248l70-52.312L438.754 301.043 439.007 439.15 458.754 438.825C476.726 438.529 478.859 438.306 482.5 436.342 487.18 433.816 491.027 429.899 493.636 425 495.433 421.626 495.5 415.562 495.5 256 495.5 96.438 495.433 90.374 493.636 87 488.565 77.48 482.099 73.799 469.397 73.202L460.293 72.774 454.397 77.337C439.883 88.566 256.423 221.935 255.772 221.73 254.976 221.479 78.972 93.309 62.177 80.75L51.812 73 44.156 73.086C39.945 73.133 35.372 73.515 33.994 73.934" stroke="none" fill="#d34c3c" fill-rule="evenodd"/><path d="M54.528 74.911C55.612 75.963 74.953 90.25 97.507 106.661c22.555 16.412 67.228 48.964 99.275 72.339s58.594 42.604 58.993 42.731C256.549 221.978 454.147 78.147 457.472 74.916 459.416 73.028 456.501 73 256 73 55.677 73 52.586 73.029 54.528 74.911M73 300.878V439H256 439V300.941C439 190.749 438.748 163.038 437.75 163.654 437.063 164.078 405.45 187.632 367.5 215.994c-37.95 28.363-78.528 58.655-90.173 67.316l-21.173 15.748-66.827-49.716C152.572 221.999 111.925 191.776 99 182.18s-24.062-17.892-24.75-18.436C73.251 162.954 73 190.519 73 300.878" stroke="none" fill="#e5e5e5" fill-rule="evenodd"/></svg></a></li><li><a href=https://nexus-security.github.io/index.xml target=_blank title=RSS rel=me><svg id="Layer_1" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 512 512" style="enable-background:new 0 0 512 512"><path style="fill:#f78c20" d="M78.333 355.334C35.14 355.334.0 390.474.0 433.667S35.14 512 78.333 512s78.333-35.14 78.333-78.333-35.14-78.333-78.333-78.333z"/><g><path style="fill:#ffa929" d="M78.333 381.445c-28.795.0-52.222 23.427-52.222 52.222s23.427 52.222 52.222 52.222 52.222-23.427 52.222-52.222-23.427-52.222-52.222-52.222z"/><path style="fill:#ffa929" d="M477.918 264.861c-21.843-51.641-53.111-98.019-92.936-137.842-39.824-39.824-86.201-71.093-137.843-92.935C193.669 11.468 136.874.0 78.333.0c-4.807.0-8.704 3.897-8.704 8.704v85.519c0 4.807 3.897 8.704 8.704 8.704 182.37.0 330.74 148.369 330.74 330.74.0 4.807 3.897 8.704 8.704 8.704h85.52c4.807.0 8.704-3.897 8.704-8.704C512 375.126 500.533 318.331 477.918 264.861z"/><path style="fill:#ffa929" d="M78.333 163.853c-4.807.0-8.704 3.897-8.704 8.704v95.74c0 4.807 3.897 8.704 8.704 8.704 86.386.0 156.666 70.281 156.666 156.666.0 4.807 3.897 8.704 8.704 8.704h95.74c4.807.0 8.704-3.897 8.704-8.704.0-72.07-28.065-139.826-79.027-190.787-50.961-50.961-118.717-79.027-190.787-79.027z"/></g><g><path style="fill:#f78c20" d="M78.333 242.186c-2.918.0-5.817.076-8.704.206v25.905c0 4.807 3.897 8.704 8.704 8.704 86.386.0 156.666 70.281 156.666 156.666.0 4.807 3.897 8.704 8.704 8.704h25.905c.129-2.886.206-5.786.206-8.704.0-105.752-85.729-191.481-191.481-191.481z"/><path style="fill:#f78c20" d="M78.333 68.113c-2.91.0-5.81.042-8.704.11v26.001c0 4.807 3.897 8.704 8.704 8.704 182.37.0 330.74 148.369 330.74 330.74.0 4.807 3.897 8.704 8.704 8.704h26.001c.067-2.894.11-5.793.11-8.704C443.887 231.777 280.223 68.113 78.333 68.113z"/></g><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/></svg></a></li><li><a href=https://x.com/0x000216 target=_blank title=Twitter rel=me><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="150" height="150" viewBox="0 0 150 150"><g id="surface1"><path style="stroke:none;fill-rule:nonzero;fill:#03a9f4;fill-opacity:1" d="M150 33.179688c-5.640625 2.460937-11.609375 4.09375-17.71875 4.855468 6.4375-3.820312 11.25-9.867187 13.527344-16.996094-6.027344 3.574219-12.621094 6.089844-19.5 7.441407-8.628906-9.210938-22.007813-12.214844-33.746094-7.574219-11.738281 4.636719-19.449219 15.980469-19.445312 28.601562.0 2.4375.203124000000003 4.78125.710937000000001 7.015626C49.085938 55.308594 26.03125 43.609375 10.445312 24.355469 2.25 38.402344 6.386719 56.398438 19.894531 65.457031 15.027344 65.324219 10.261719 64.027344 6 61.667969V62.007812c.015625 14.636719 10.304688 27.25 24.636719 30.214844-2.628907.691406000000001-5.339844 1.03125-8.0625 1.011719C20.621094 93.269531 18.667969 93.09375 16.753906 92.710938c4.070313 12.507812 15.585938 21.089843 28.734375 21.421874-10.886719 8.511719-24.308593 13.128907-38.128906 13.113282C4.835938 127.246094 2.417969 127.132812.0 126.824219c14.0625 9.0625 30.445312 13.855469 47.175781 13.800781 56.585938.0 87.523438-46.875 87.523438-87.507812.0-1.359376-.046875-2.671876-.113281000000001-3.972657C140.652344 44.804688 145.875 39.394531 150 33.179688zm0 0"/></g></svg></a></li><li><a href=https://www.minds.com/0x000216/ target=_blank title=Minds rel=me><svg id="Capa_1" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 512 512" style="enable-background:new 0 0 512 512"><g><g><path style="fill:#ffe1b2" d="M256 33.085C245.078 13.38 224.079.0 2e2.0c-23.781.0-45.57 13.293-56.594 34.184C115.711 41.602 96 66.977 96 96c0 .059.0.113.0.172-9.977 7.512-16 19.301-16 31.828.0 1.316.078 2.637.234 3.992C60.211 145.266 48 167.758 48 192c0 14.07 4.039 27.543 11.719 39.262C57.273 236.512 56 242.207 56 248c0 2.738.281 5.445.828 8.098C36.672 267.308 24 288.539 24 312c0 27.973 18.305 52.34 44.109 60.785C65.398 378.828 64 385.324 64 392c0 21.098 13.805 39.508 33.539 45.727C103.891 466.746 129.828 488 160 488c4.617.0 9.227-.512 13.766-1.527C181.992 502 198.141 512 216 512c16.687.0 31.396-8.567 40-21.523V33.085z"/></g><g><g><path style="fill:#ffb980" d="M264 256c-4.422.0-8-3.582-8-8 0-22.055-17.945-40-40-40-8.008.0-15.734 2.355-22.336 6.812-3.023 2.043-7.055 1.781-9.797-.652-3.156-2.809-8.477-6.16-15.867-6.16-4.422.0-8-3.582-8-8s3.578-8 8-8c7.711.0 15.234 2.293 21.719 6.539C197.773 194.246 206.758 192 216 192c30.875.0 56 25.121 56 56C272 252.418 268.422 256 264 256z"/></g></g><g><g><path style="fill:#ffb980" d="M120 120c18.977.0 36.875 7.312 50.414 20.594 3.141 3.09 8.203 3.047 11.312-.109 3.094-3.152 3.047-8.219-.109-11.312C165.07 112.941 143.187 104 120 104c-13.046.0-25.395 2.93-36.542 8.046C81.253 117.019 80 122.423 80 128c0 1.316.078 2.637.234 3.992-.094.062-.173.139-.267.202C91.423 124.501 105.193 120 120 120z"/></g></g><g><g><path style="fill:#ffb980" d="M216 360c0-4.418-3.578-8-8-8s-8 3.582-8 8c0 17.645-14.352 32-32 32-14.211.0-26.82-9.648-30.664-23.465-.703-2.512-2.578-4.523-5.039-5.395-2.453-.871-5.188-.492-7.305 1.02C114.094 371.906 101.305 376 88 376c-6.948.0-13.625-1.149-19.894-3.207-2.214 4.939-3.501 10.19-3.916 15.586C71.714 390.73 79.711 392 88 392c13.297.0 26.187-3.266 37.773-9.52C133.969 397.894 150.141 408 168 408c26.469.0 48-21.531 48-48z"/></g></g><g><path style="fill:#fdc88e" d="M488 312c0-23.461-12.672-44.691-32.828-55.902.547-2.652.828-5.359.828-8.098.0-5.793-1.273-11.488-3.719-16.738C459.961 219.543 464 206.07 464 192c0-24.242-12.211-46.734-32.234-60.008.156-1.355.234-2.676.234-3.992.0-12.527-6.023-24.316-16-31.828.0-.059.0-.113.0-.172.0-29.023-19.711-54.398-47.406-61.816C357.57 13.293 335.781.0 312 0c-24.08.0-45.078 13.38-56 33.085v457.391C264.604 503.433 279.313 512 296 512c17.859.0 34.008-10 42.234-25.527C342.773 487.488 347.383 488 352 488c30.172.0 56.109-21.254 62.461-50.273C434.195 431.508 448 413.097 448 392c0-6.676-1.398-13.172-4.109-19.215C469.695 364.34 488 339.973 488 312z"/></g><g><path style="fill:#f8ab6b" d="M272.008 151.199C272 151.465 272 151.734 272 152c0 26.469 21.531 48 48 48s48-21.531 48-48c0-4.418-3.578-8-8-8s-8 3.582-8 8c0 17.645-14.352 32-32 32s-32-14.355-32-32c0-2.184.219-4.359.656-6.465.492-2.395-.133-4.883-1.703-6.754-1.57-1.871-4.016-3.066-6.352-2.859-.453.012-.891.059-.602.078-13.234.0-24-10.766-24-24v31.813C260.673 147.348 266.061 149.988 272.008 151.199z"/></g><g><path style="fill:#f8ab6b" d="M296 328c9.242.0 18.219-2.246 26.281-6.539C328.765 325.707 336.289 328 344 328c4.422.0 8-3.582 8-8s-3.578-8-8-8c-7.391.0-12.711-3.352-15.867-6.16-2.742-2.434-6.766-2.695-9.797-.656C311.726 309.644 304 312 296 312c-22.055.0-40-17.945-40-40v39.116C266.174 321.517 280.337 328 296 328z"/></g><g><g><path style="fill:#f8ab6b" d="M431.765 131.992c.156-1.355.234-2.676.234-3.992.0-5.577-1.253-10.981-3.458-15.954C417.395 106.93 405.046 104 392 104c-4.422.0-8 3.582-8 8s3.578 8 8 8c14.807.0 28.577 4.501 40.032 12.194C431.939 132.131 431.859 132.054 431.765 131.992z"/></g></g><g><g><path style="fill:#f8ab6b" d="M447.81 388.38c-.415-5.396-1.702-10.647-3.916-15.586C437.624 374.85 430.948 376 424 376c-13.578.0-26.594-4.266-37.641-12.332-2.07-1.5-4.719-1.93-7.133-1.168-2.43.77-4.344 2.648-5.164 5.059C369.101 382.176 355.414 392 340 392c-4.422.0-8 3.582-8 8s3.578 8 8 8c18.875.0 35.961-10.191 45.094-26.156C396.976 388.512 410.258 392 424 392 432.288 392 440.285 390.73 447.81 388.38z"/></g></g></g><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/></svg></a></li><li><a href=https://www.buymeacoffee.com/0x000216 target=_blank title=Coffee rel=me><svg id="Capa_1" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 340 340" style="enable-background:new 0 0 340 340"><g id="XMLID_18_"><polygon id="XMLID_138_" style="fill:#dedde0" points="76.429,290 80,340 170,340 170,290"/><polygon id="XMLID_169_" style="fill:#dedde0" points="170,80 61.429,80 65,130 170,130"/><polygon id="XMLID_197_" style="fill:#acabb1" points="170,290 170,340 260,340 263.571,290"/><polygon id="XMLID_221_" style="fill:#acabb1" points="170,80 170,130 275,130 278.571,80"/><path id="XMLID_222_" style="fill:#ffda44" d="M170 260c-22.091.0-40-22.386-40-50s17.909-50 40-50v-30H65 50l10 160h16.429H170V260z"/><path id="XMLID_33_" style="fill:#ff9811" d="M170 130v30c22.091.0 40 22.386 40 50s-17.909 50-40 50v30h93.571H280l10-160h-15H170z"/><path id="XMLID_223_" style="fill:#50412e" d="M210 210c0-27.614-17.909-50-40-50v1e2c22.091.0 40-22.386 40-50z"/><path id="XMLID_224_" style="fill:#786145" d="M130 210c0 27.614 17.909 50 40 50V160c-22.091.0-40 22.386-40 50z"/><polygon id="XMLID_225_" style="fill:#50412e" points="278.571,80 300,80 300,40 260,40 260,0 80,0 80,40 40,40 40,80 61.429,80 170,80"/></g><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/about/><svg class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg>
<span>About Us</span></a></li><li><a href=/termsofservice/><svg class="icon icon-tabler icon-tabler-pencil" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 20h4L18.5 9.5a1.5 1.5.0 00-4-4L4 16v4"/><line x1="13.5" y1="6.5" x2="17.5" y2="10.5"/></svg>
<span>Terms Of Service</span></a></li><li><a href=/privacypolicy/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Privacy Policy</span></a></li><li><a href=/disclaimer/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>Disclaimer</span></a></li><li><a href=/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/contact/><svg class="icon icon-tabler icon-tabler-mail" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><rect x="3" y="5" width="18" height="14" rx="2"/><polyline points="3 7 12 13 21 7"/></svg>
<span>Contact Us</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>Dark Mode</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#the-crucial-role-of-high-quality-data-in-modern-ai>The Crucial Role of High-quality Data in Modern AI</a></li><li><a href=#a-glimpse-into-large-data-set-processing>A Glimpse into Large Data Set Processing</a><ol><li><a href=#data-collection>Data Collection</a></li><li><a href=#data-labeling>Data Labeling</a></li><li><a href=#quality-assurance>Quality Assurance</a></li></ol></li><li><a href=#cortex-walkthrough-from-url-to-labeled-image>Cortex Walkthrough: From URL to Labeled Image</a><ol><li><a href=#code-examples-and-implementation>Code Examples and Implementation</a></li><li><a href=#foundation-models-and-chatgpt-integration>Foundation Models and ChatGPT Integration</a></li></ol></li><li><a href=#image-data-labeling-the-backbone-of-ai-systems>Image Data Labeling: The Backbone of AI Systems</a></li></ol></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><div class=article-title-wrapper><h2 class=article-title><a href=/improving-ai-image-labeling-and-semantic-metadata-gathering/>Improving AI Image Labeling and Semantic Metadata Gathering</a></h2></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Sep 07, 2023</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>13 minute read</time></div></footer></div></header><section class=article-content><p>The increasing prevalence of deep neural networks across diverse industries is undeniable. Their efficacy in addressing various challenges through supervised learning is well-documented. However, achieving optimal performance hinges on the availability of substantial, high-quality training data that accurately reflects the production setting.</p><p>Although vast amounts of data exist online, a large portion remains unprocessed and unsuitable for machine learning (ML) applications. Consider the development of a traffic light detector for autonomous driving. Training images must incorporate traffic lights and precise bounding boxes to delineate their boundaries. Transforming raw data into this structured, labeled, and usable format is both time-intensive and complex.</p><p>To streamline this process, I created <a class=link href=https://www.piculjantechnologies.ai/cortex-platform target=_blank rel=noopener>Cortex: The Biggest AI Dataset</a>, a novel SaaS product centered around image data labeling and computer vision. Its capabilities extend beyond these areas to encompass diverse data types and artificial intelligence (AI) subfields. Cortex offers numerous use cases across multiple domains and image categories:</p><ul><li><strong>Enhanced model performance through fine-tuning with custom data sets:</strong> Pretraining a model on a large, diverse data set like Cortex can substantially elevate its performance when fine-tuned on a smaller, specialized data set. Take, for instance, a cat breed identification app. Pretraining a model on a comprehensive collection of cat images enables it to swiftly discern features across different breeds. This, in turn, enhances the app&rsquo;s accuracy in classifying breeds when fine-tuned on a targeted data set.</li><li><strong>Training a model for general object detection:</strong> The data set&rsquo;s labeled images of various objects allow for training models to detect and classify specific objects within images. A prevalent example is car identification, which proves valuable in applications like automated parking, traffic control, law enforcement, and security. This general object detection methodology can be broadened to encompass <a class=link href=https://www.v7labs.com/blog/coco-dataset-guide target=_blank rel=noopener>other MS COCO classes</a> (currently, the data set handles only MS COCO classes).</li><li><strong>Training a model for object embedding extraction:</strong> Object embeddings represent objects in a high-dimensional space. Training a model using Cortex enables it to generate object embeddings from images. These embeddings have applications in areas such as similarity search or clustering.</li><li><strong>Semantic metadata generation for images:</strong> Cortex can produce semantic metadata, such as object labels, for images. This empowers application users with richer insights and interactivity (e.g., clicking objects in an image for further details or viewing related images on news platforms). This feature proves particularly beneficial in interactive learning environments where users can delve deeper into objects (like animals, vehicles, or household items).</li></ul><p>Our exploration of Cortex will concentrate on the last use case: extracting semantic metadata from website images and overlaying them with clickable bounding boxes. Clicking on a bounding box triggers a Google search for the MS COCO object class identified within it.</p><h2 id=the-crucial-role-of-high-quality-data-in-modern-ai>The Crucial Role of High-quality Data in Modern AI</h2><p>Recent years have witnessed remarkable advancements in various AI subfields, including computer vision, natural language processing (NLP), and <a class=link href=https://www.kaggle.com/code/kobbiemanrique/tabular-data-in-the-age-of-ai target=_blank rel=noopener>tabular data analysis</a>. These breakthroughs share a common thread: a reliance on high-quality data. Since AI systems are limited by the data they learn from, data-centric AI has emerged as a critical research area. Techniques such as transfer learning and synthetic data generation have been developed to address data scarcity, while data labeling and cleaning remain vital for ensuring data quality.</p><p>Labeled data is paramount in developing modern AI models, including fine-tuned LLMs and computer vision models. While obtaining basic labels for pretraining language models (e.g., predicting the next word in a sentence) is straightforward, collecting labeled data for conversational AI models like ChatGPT is more intricate. These labels must exemplify the model&rsquo;s desired behavior to create the illusion of meaningful conversation. Image labeling presents even greater challenges. Training models like DALL-E 2 and Stable Diffusion to generate images from user prompts necessitates vast data sets comprising labeled images and textual descriptions.</p><p>Using subpar data for systems like ChatGPT would result in poor conversational abilities. Similarly, low-quality image object bounding box data would lead to inaccurate predictions, such as misclassifications, missed objects, and other errors. Noise and blurriness in image data further exacerbate these issues. Cortex seeks to provide developers with readily available, high-quality data for creating and training image models, making the process faster, more efficient, and predictable.</p><h2 id=a-glimpse-into-large-data-set-processing>A Glimpse into Large Data Set Processing</h2><p>Building a comprehensive AI data set is a multi-phased process. It typically begins with data collection, where images are scraped from the Internet, and their URLs and structural attributes (e.g., image hash, dimensions, and histogram) are stored. Subsequently, models automatically label these images with semantic metadata (e.g., image embeddings, object detection labels). Finally, quality assurance (QA) measures, encompassing rule-based and ML-based approaches, verify the accuracy of the assigned labels.</p><h3 id=data-collection>Data Collection</h3><p>Several methods exist for acquiring data for AI systems, each with its own strengths and weaknesses:</p><ul><li><p><strong>Labeled data sets:</strong> Developed by researchers to address specific problems, these data sets, such as <a class=link href=https://www.kaggle.com/datasets/hojjatk/mnist-dataset target=_blank rel=noopener>MNIST</a> and <a class=link href=https://www.image-net.org/ target=_blank rel=noopener>ImageNet</a>, come pre-labeled for model training. Platforms like Kaggle facilitate the sharing and discovery of such data sets, although they are primarily intended for research rather than commercial use.</p></li><li><p><strong>Private data:</strong> Proprietary to organizations, this data type is often rich in domain-specific information. However, it often requires additional cleaning, data labeling, and potential consolidation from different subsystems.</p></li><li><p><strong>Public data:</strong> Freely available online, this data can be collected using web crawlers. However, this approach can be time-consuming, especially when data resides on high-latency servers.</p></li><li><p><strong>Crowdsourced data:</strong> Involving human workers to gather real-world data, this method can lead to inconsistencies in data quality and format due to variations in individual worker output.</p></li><li><p><strong>Synthetic data:</strong> Generated by applying controlled modifications to existing data, synthetic data techniques, including generative adversarial networks (GANs) or basic image augmentations, prove particularly useful when substantial data is already available.</p></li></ul><p>Obtaining the right data is paramount to building effective and accurate AI systems.</p><div data-testid=image-container class="X3Bg-O9c _1xIzGpI7"><figure class=_1sK7TguO><a href=https://bs-uploads.toptal.io/blackfish-uploads/public_files/AI-image-labeling-Indexing-internal-9995a5a0fdcb8ab02a838b87924da3b5.png target=_blank rel="noopener noreferrer" class=_5xZOBTsv><picture class=!contents data-testid=picture><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FAI-image-labeling-Indexing-internal-9995a5a0fdcb8ab02a838b87924da3b5.png&amp;width=360, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FAI-image-labeling-Indexing-internal-9995a5a0fdcb8ab02a838b87924da3b5.png&amp;width=360&amp;dpr=2 2x" media="(max-width: 360px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FAI-image-labeling-Indexing-internal-9995a5a0fdcb8ab02a838b87924da3b5.png&amp;width=480, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FAI-image-labeling-Indexing-internal-9995a5a0fdcb8ab02a838b87924da3b5.png&amp;width=480&amp;dpr=2 2x" media="(min-width: 360.1px) and (max-width: 480px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FAI-image-labeling-Indexing-internal-9995a5a0fdcb8ab02a838b87924da3b5.png&amp;width=768, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FAI-image-labeling-Indexing-internal-9995a5a0fdcb8ab02a838b87924da3b5.png&amp;width=768&amp;dpr=2 2x" media="(min-width: 480.1px) and (max-width: 768px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FAI-image-labeling-Indexing-internal-9995a5a0fdcb8ab02a838b87924da3b5.png&amp;width=1024, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FAI-image-labeling-Indexing-internal-9995a5a0fdcb8ab02a838b87924da3b5.png&amp;width=1024&amp;dpr=2 2x" media="(min-width: 768.1px) and (max-width: 1024px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FAI-image-labeling-Indexing-internal-9995a5a0fdcb8ab02a838b87924da3b5.png&amp;width=1440, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FAI-image-labeling-Indexing-internal-9995a5a0fdcb8ab02a838b87924da3b5.png&amp;width=1440&amp;dpr=2 2x" media="(min-width: 1024.1px) and (max-width: 1440px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FAI-image-labeling-Indexing-internal-9995a5a0fdcb8ab02a838b87924da3b5.png&amp;width=1920, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FAI-image-labeling-Indexing-internal-9995a5a0fdcb8ab02a838b87924da3b5.png&amp;width=1920&amp;dpr=2 2x" media="(min-width: 1440.1px) and (max-width: 1920px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FAI-image-labeling-Indexing-internal-9995a5a0fdcb8ab02a838b87924da3b5.png" media="(min-width: 1920.1px)"><img alt="An indexing flowchart shows images from four sources entering the database and being indexed and stored in internal data storage if theyâ€™re not available online." src="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FAI-image-labeling-Indexing-internal-9995a5a0fdcb8ab02a838b87924da3b5.png" loading=lazy decoding=async class=Djd3YO_2></picture></a></figure></div><h3 id=data-labeling>Data Labeling</h3><p>Data labeling involves assigning labels to data samples, enabling AI systems to learn from them. Commonly used data labeling methods include:</p><ul><li><p><strong>Manual data labeling:</strong> The most straightforward method, manual data labeling involves human annotators examining and labeling each data sample individually. While time-consuming and potentially costly, this approach is often necessary for data requiring specific domain knowledge or subjective interpretation.</p></li><li><p><strong>Rule-based labeling:</strong> An alternative to manual labeling, this method employs predefined rules or algorithms to assign labels. For instance, when labeling video frames, annotating the first and last frames and programmatically interpolating for intermediate frames can replace manual annotation of every frame.</p></li><li><p><strong>ML-based labeling:</strong> Utilizing pre-trained machine learning models, this approach automatically generates labels for new data samples. For example, a model trained on a large, labeled image data set can automatically label new images. While requiring a substantial amount of labeled data for training, this method can be highly efficient. Recent research even suggests that ChatGPT is already <a class=link href=https://arxiv.org/abs/2303.15056 target=_blank rel=noopener>outperforming crowdworkers</a> for text annotation tasks.</p></li></ul><div data-testid=image-container class="X3Bg-O9c _1xIzGpI7"><figure class=_1sK7TguO><a href=https://bs-uploads.toptal.io/blackfish-uploads/public_files/AI-image-labeling-Labeling-flow-030b5d123995b98613be3a9c24c7b641.png target=_blank rel="noopener noreferrer" class=_5xZOBTsv><picture class=!contents data-testid=picture><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FAI-image-labeling-Labeling-flow-030b5d123995b98613be3a9c24c7b641.png&amp;width=360, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FAI-image-labeling-Labeling-flow-030b5d123995b98613be3a9c24c7b641.png&amp;width=360&amp;dpr=2 2x" media="(max-width: 360px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FAI-image-labeling-Labeling-flow-030b5d123995b98613be3a9c24c7b641.png&amp;width=480, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FAI-image-labeling-Labeling-flow-030b5d123995b98613be3a9c24c7b641.png&amp;width=480&amp;dpr=2 2x" media="(min-width: 360.1px) and (max-width: 480px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FAI-image-labeling-Labeling-flow-030b5d123995b98613be3a9c24c7b641.png&amp;width=768, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FAI-image-labeling-Labeling-flow-030b5d123995b98613be3a9c24c7b641.png&amp;width=768&amp;dpr=2 2x" media="(min-width: 480.1px) and (max-width: 768px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FAI-image-labeling-Labeling-flow-030b5d123995b98613be3a9c24c7b641.png&amp;width=1024, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FAI-image-labeling-Labeling-flow-030b5d123995b98613be3a9c24c7b641.png&amp;width=1024&amp;dpr=2 2x" media="(min-width: 768.1px) and (max-width: 1024px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FAI-image-labeling-Labeling-flow-030b5d123995b98613be3a9c24c7b641.png&amp;width=1440, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FAI-image-labeling-Labeling-flow-030b5d123995b98613be3a9c24c7b641.png&amp;width=1440&amp;dpr=2 2x" media="(min-width: 1024.1px) and (max-width: 1440px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FAI-image-labeling-Labeling-flow-030b5d123995b98613be3a9c24c7b641.png&amp;width=1920, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FAI-image-labeling-Labeling-flow-030b5d123995b98613be3a9c24c7b641.png&amp;width=1920&amp;dpr=2 2x" media="(min-width: 1440.1px) and (max-width: 1920px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FAI-image-labeling-Labeling-flow-030b5d123995b98613be3a9c24c7b641.png" media="(min-width: 1920.1px)"><img alt="The quality assurance flowchart shows that the database relies on public, private, and in-house models, as well as human annotators." src="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FAI-image-labeling-Labeling-flow-030b5d123995b98613be3a9c24c7b641.png" loading=lazy decoding=async class=Djd3YO_2></picture></a></figure></div><p>The optimal labeling method depends on factors like data complexity and resource availability. Selecting and implementing the appropriate method allows researchers and practitioners to create high-quality labeled data sets for training increasingly sophisticated AI models.</p><h3 id=quality-assurance>Quality Assurance</h3><p>Quality assurance ensures that the data and labels used for training are accurate, consistent, and relevant to the task. Common QA methods mirror data labeling methods:</p><ul><li><p><strong>Manual QA:</strong> This involves manually inspecting data and labels for accuracy and relevance.</p></li><li><p><strong>Rule-based QA:</strong> This method uses predefined rules to check data and labels for accuracy and consistency.</p></li><li><p><strong>ML-based QA:</strong> This approach leverages machine learning algorithms to automatically detect errors or inconsistencies in data and labels.</p></li></ul><p><a class=link href=https://voxel51.com/fiftyone/ target=_blank rel=noopener>FiftyOne</a>, an open-source toolkit for building high-quality data sets and computer vision models, is one such ML-based QA tool. For manual QA, tools like <a class=link href=https://www.cvat.ai/ target=_blank rel=noopener>CVAT</a> can enhance the efficiency of human annotators. Human annotation, being the most expensive and least desirable option, should only be employed when automatic annotation fails to yield high-quality labels.</p><div data-testid=image-container class="X3Bg-O9c _1xIzGpI7"><figure class=_1sK7TguO><a href=https://bs-uploads.toptal.io/blackfish-uploads/public_files/cvat-026456f29b04793e61838f3f5349de87.png target=_blank rel="noopener noreferrer" class=_5xZOBTsv><picture class=!contents data-testid=picture><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fcvat-026456f29b04793e61838f3f5349de87.png&amp;width=360, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fcvat-026456f29b04793e61838f3f5349de87.png&amp;width=360&amp;dpr=2 2x" media="(max-width: 360px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fcvat-026456f29b04793e61838f3f5349de87.png&amp;width=480, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fcvat-026456f29b04793e61838f3f5349de87.png&amp;width=480&amp;dpr=2 2x" media="(min-width: 360.1px) and (max-width: 480px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fcvat-026456f29b04793e61838f3f5349de87.png&amp;width=768, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fcvat-026456f29b04793e61838f3f5349de87.png&amp;width=768&amp;dpr=2 2x" media="(min-width: 480.1px) and (max-width: 768px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fcvat-026456f29b04793e61838f3f5349de87.png&amp;width=1024, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fcvat-026456f29b04793e61838f3f5349de87.png&amp;width=1024&amp;dpr=2 2x" media="(min-width: 768.1px) and (max-width: 1024px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fcvat-026456f29b04793e61838f3f5349de87.png&amp;width=1440, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fcvat-026456f29b04793e61838f3f5349de87.png&amp;width=1440&amp;dpr=2 2x" media="(min-width: 1024.1px) and (max-width: 1440px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fcvat-026456f29b04793e61838f3f5349de87.png&amp;width=1920, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fcvat-026456f29b04793e61838f3f5349de87.png&amp;width=1920&amp;dpr=2 2x" media="(min-width: 1440.1px) and (max-width: 1920px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fcvat-026456f29b04793e61838f3f5349de87.png" media="(min-width: 1920.1px)"><img alt="CVAT being used for manual annotation of an image of a cat." src="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fcvat-026456f29b04793e61838f3f5349de87.png" loading=lazy decoding=async class=Djd3YO_2></picture></a><figcaption class=_2tKCaBqq>Cat Bounding Box Annotation Done Manually Using CVAT</figcaption></figure></div><p>When validating data processing efforts, the level of labeling detail should align with the task&rsquo;s requirements. While some applications demand pixel-level precision, others may be more forgiving.</p><p>QA is a critical step in ensuring the efficacy and reliability of high-quality neural network models. Whether manual, rule-based, or ML-based, diligence and thoroughness in QA are essential for achieving the best outcomes.</p><h2 id=cortex-walkthrough-from-url-to-labeled-image>Cortex Walkthrough: From URL to Labeled Image</h2><p>Cortex employs a combination of manual and automated processes for data collection, labeling, and QA. The objective is to minimize manual effort by feeding human outputs into rule-based and ML algorithms.</p><p>Cortex samples consist of URLs referencing original images scraped from the <a class=link href=https://commoncrawl.org/ target=_blank rel=noopener>Common Crawl database</a>. Data points are labeled with object bounding boxes. Object classes adhere to the MS COCO classification system, including categories like &ldquo;person,&rdquo; &ldquo;car,&rdquo; and &ldquo;traffic light.&rdquo; Users can download their desired images from the provided URLs using <a class=link href=https://github.com/rom1504/img2dataset target=_blank rel=noopener>img2dataset</a>. Within Cortex, labels are referred to as semantic metadata, as they impart meaning to the data and unveil <a class=link href=https://ieeexplore.ieee.org/abstract/document/9899778 target=_blank rel=noopener>expose useful knowledge</a> embedded within each data sample (e.g., image dimensions).</p><p>The Cortex data set also incorporates a filtering feature, enabling users to search the database for specific images. An interactive image labeling feature allows users to submit links to unindexed images. The system dynamically annotates these images and presents their semantic metadata and structural attributes.</p><h3 id=code-examples-and-implementation>Code Examples and Implementation</h3><p>Cortex <a class=link href=https://rapidapi.com/ target=_blank rel=noopener>lives on RapidAPI</a> and offers free semantic metadata and structural attribute extraction for any URL. The paid version grants users access to batches of scraped, labeled data from the Internet, utilizing filters for bulk image labeling.</p><div data-testid=image-container class="X3Bg-O9c _1xIzGpI7"><figure class=_1sK7TguO><a href=https://bs-uploads.toptal.io/blackfish-uploads/public_files/Cat_November_2010-1a-b51793ebf13af3cb1fe0f13414670a77.jpg target=_blank rel="noopener noreferrer" class=_5xZOBTsv><picture class=!contents data-testid=picture><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FCat_November_2010-1a-b51793ebf13af3cb1fe0f13414670a77.jpg&amp;width=360, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FCat_November_2010-1a-b51793ebf13af3cb1fe0f13414670a77.jpg&amp;width=360&amp;dpr=2 2x" media="(max-width: 360px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FCat_November_2010-1a-b51793ebf13af3cb1fe0f13414670a77.jpg&amp;width=480, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FCat_November_2010-1a-b51793ebf13af3cb1fe0f13414670a77.jpg&amp;width=480&amp;dpr=2 2x" media="(min-width: 360.1px) and (max-width: 480px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FCat_November_2010-1a-b51793ebf13af3cb1fe0f13414670a77.jpg&amp;width=768, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FCat_November_2010-1a-b51793ebf13af3cb1fe0f13414670a77.jpg&amp;width=768&amp;dpr=2 2x" media="(min-width: 480.1px) and (max-width: 768px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FCat_November_2010-1a-b51793ebf13af3cb1fe0f13414670a77.jpg&amp;width=1024, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FCat_November_2010-1a-b51793ebf13af3cb1fe0f13414670a77.jpg&amp;width=1024&amp;dpr=2 2x" media="(min-width: 768.1px) and (max-width: 1024px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FCat_November_2010-1a-b51793ebf13af3cb1fe0f13414670a77.jpg&amp;width=1440, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FCat_November_2010-1a-b51793ebf13af3cb1fe0f13414670a77.jpg&amp;width=1440&amp;dpr=2 2x" media="(min-width: 1024.1px) and (max-width: 1440px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FCat_November_2010-1a-b51793ebf13af3cb1fe0f13414670a77.jpg&amp;width=1920, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FCat_November_2010-1a-b51793ebf13af3cb1fe0f13414670a77.jpg&amp;width=1920&amp;dpr=2 2x" media="(min-width: 1440.1px) and (max-width: 1920px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FCat_November_2010-1a-b51793ebf13af3cb1fe0f13414670a77.jpg" media="(min-width: 1920.1px)"><img alt="A cat sitting on a wall." src="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2FCat_November_2010-1a-b51793ebf13af3cb1fe0f13414670a77.jpg" loading=lazy decoding=async class=Djd3YO_2></picture></a><figcaption class=_2tKCaBqq>An Example Image From the Internet</figcaption></figure></div><p>This section&rsquo;s Python code example demonstrates using Cortex to retrieve semantic metadata and structural attributes for <a class=link href=https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Cat_November_2010-1a.jpg/1200px-Cat_November_2010-1a.jpg target=_blank rel=noopener>a given URL</a> and generate bounding boxes for object detection. As the system evolves, its functionality will expand to include additional attributes like histograms, pose estimation data, and more. Each new attribute enriches the processed data, broadening its applicability to diverse use cases.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=kn>import</span> <span class=nn>cv2</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>json</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>requests</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>cortex_url</span> <span class=o>=</span> <span class=s1>&#39;https://cortex-api.piculjantechnologies.ai/upload&#39;</span>
</span></span><span class=line><span class=cl><span class=n>img_url</span> <span class=o>=</span> \
</span></span><span class=line><span class=cl>   <span class=s1>&#39;https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Cat_November_2010-1a.jpg/1200px-Cat_November_2010-1a.jpg&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>req</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>img_url</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>png_as_np</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>frombuffer</span><span class=p>(</span><span class=n>req</span><span class=o>.</span><span class=n>content</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>uint8</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>img</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>imdecode</span><span class=p>(</span><span class=n>png_as_np</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>data</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;url_or_id&#39;</span><span class=p>:</span> <span class=n>img_url</span><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>response</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>post</span><span class=p>(</span><span class=n>cortex_url</span><span class=p>,</span> <span class=n>data</span><span class=o>=</span><span class=n>json</span><span class=o>.</span><span class=n>dumps</span><span class=p>(</span><span class=n>data</span><span class=p>),</span> <span class=n>headers</span><span class=o>=</span><span class=p>{</span><span class=s1>&#39;Content-Type&#39;</span><span class=p>:</span> <span class=s1>&#39;application/json&#39;</span><span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>content</span> <span class=o>=</span> <span class=n>json</span><span class=o>.</span><span class=n>loads</span><span class=p>(</span><span class=n>response</span><span class=o>.</span><span class=n>content</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>object_analysis</span> <span class=o>=</span> <span class=n>content</span><span class=p>[</span><span class=s1>&#39;object_analysis&#39;</span><span class=p>][</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>object_analysis</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>   <span class=n>x1</span> <span class=o>=</span> <span class=n>object_analysis</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=s1>&#39;x1&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>   <span class=n>y1</span> <span class=o>=</span> <span class=n>object_analysis</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=s1>&#39;y1&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>   <span class=n>x2</span> <span class=o>=</span> <span class=n>object_analysis</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=s1>&#39;x2&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>   <span class=n>y2</span> <span class=o>=</span> <span class=n>object_analysis</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=s1>&#39;y2&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>   <span class=n>classname</span> <span class=o>=</span> <span class=n>object_analysis</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=s1>&#39;classname&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>   <span class=n>cv2</span><span class=o>.</span><span class=n>rectangle</span><span class=p>(</span><span class=n>img</span><span class=p>,</span> <span class=p>(</span><span class=n>x1</span><span class=p>,</span> <span class=n>y1</span><span class=p>),</span> <span class=p>(</span><span class=n>x2</span><span class=p>,</span> <span class=n>y2</span><span class=p>),</span> <span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>255</span><span class=p>,</span> <span class=mi>0</span><span class=p>),</span> <span class=mi>5</span><span class=p>)</span>
</span></span><span class=line><span class=cl>   <span class=n>cv2</span><span class=o>.</span><span class=n>putText</span><span class=p>(</span><span class=n>img</span><span class=p>,</span> <span class=n>classname</span><span class=p>,</span>
</span></span><span class=line><span class=cl>               <span class=p>(</span><span class=n>x1</span><span class=p>,</span> <span class=n>y1</span> <span class=o>-</span> <span class=mi>10</span><span class=p>),</span>
</span></span><span class=line><span class=cl>               <span class=n>cv2</span><span class=o>.</span><span class=n>FONT_HERSHEY_SIMPLEX</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>255</span><span class=p>,</span> <span class=mi>0</span><span class=p>),</span> <span class=mi>5</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>cv2</span><span class=o>.</span><span class=n>imwrite</span><span class=p>(</span><span class=s1>&#39;visualization.png&#39;</span><span class=p>,</span> <span class=n>img</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>The response structure resembles the following:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-gdscript3 data-lang=gdscript3><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>   <span class=s2>&#34;_id&#34;</span><span class=p>:</span><span class=s2>&#34;PT::63b54db5e6ca4c53498bb4e5&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   <span class=s2>&#34;url&#34;</span><span class=p>:</span><span class=s2>&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Cat_November_2010-1a.jpg/1200px-Cat_November_2010-1a.jpg&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   <span class=s2>&#34;datetime&#34;</span><span class=p>:</span><span class=s2>&#34;2023-01-04 09:58:14.082248&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   <span class=s2>&#34;object_analysis_processed&#34;</span><span class=p>:</span><span class=s2>&#34;true&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   <span class=s2>&#34;pose_estimation_processed&#34;</span><span class=p>:</span><span class=s2>&#34;false&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   <span class=s2>&#34;face_analysis_processed&#34;</span><span class=p>:</span><span class=s2>&#34;false&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   <span class=s2>&#34;type&#34;</span><span class=p>:</span><span class=s2>&#34;image&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   <span class=s2>&#34;height&#34;</span><span class=p>:</span><span class=mi>1602</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   <span class=s2>&#34;width&#34;</span><span class=p>:</span><span class=mi>1200</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   <span class=s2>&#34;hash&#34;</span><span class=p>:</span><span class=s2>&#34;d0ad50c952a9a153fd7b0f9765dec721f24c814dbe2ca1010d0b28f0f74a2def&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   <span class=s2>&#34;object_analysis&#34;</span><span class=p>:[</span>
</span></span><span class=line><span class=cl>      <span class=p>[</span>
</span></span><span class=line><span class=cl>         <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;classname&#34;</span><span class=p>:</span><span class=s2>&#34;cat&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;conf&#34;</span><span class=p>:</span><span class=mf>0.9876543879508972</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;x1&#34;</span><span class=p>:</span><span class=mi>276</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;y1&#34;</span><span class=p>:</span><span class=mi>218</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;x2&#34;</span><span class=p>:</span><span class=mi>1092</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;y2&#34;</span><span class=p>:</span><span class=mi>1539</span>
</span></span><span class=line><span class=cl>         <span class=p>}</span>
</span></span><span class=line><span class=cl>      <span class=p>]</span>
</span></span><span class=line><span class=cl>   <span class=p>],</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;label_quality_estimation&#34;</span><span class=p>:</span><span class=mf>2.561230587616592e-7</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div><p>Let&rsquo;s break down each piece of information and its potential uses:</p><ul><li><code>_id</code>: This self-explanatory identifier is used internally for data indexing.</li><li><code>url</code>: This field contains the image URL, revealing its origin and enabling filtering based on source.</li><li><code>datetime</code>: Displaying the date and time of the image&rsquo;s initial processing, this data proves crucial for time-sensitive applications, such as those processing real-time data streams.</li><li><code>object_analysis_processed</code>, <code>pose_estimation_processed</code>, and <code>face_analysis_processed</code>: These flags indicate whether labels for object analysis, pose estimation, and face analysis have been generated.</li><li><code>type</code>: Denoting the data type (e.g., image, audio, video), this flag will expand to encompass other data types beyond Cortex&rsquo;s current image-centric focus.</li><li><code>height</code> and <code>width</code>: These self-explanatory structural attributes provide the sample&rsquo;s dimensions.</li><li><code>hash</code>: This field displays the hashed key.</li><li><code>object_analysis</code>: This section contains object analysis label information, including crucial semantic metadata like class name and confidence level.</li><li><code>label_quality_estimation</code>: Ranging from 0 (poor quality) to 1 (good quality), this score reflects the label quality assessment calculated using ML-based QA.</li></ul><p>The visualization.png image generated by the Python code snippet appears as follows:</p><div data-testid=image-container class="X3Bg-O9c _1xIzGpI7"><figure class=_1sK7TguO><a href=https://bs-uploads.toptal.io/blackfish-uploads/public_files/visualization-ccf322a44eb79a3a693d162057f2458a.png target=_blank rel="noopener noreferrer" class=_5xZOBTsv><picture class=!contents data-testid=picture><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fvisualization-ccf322a44eb79a3a693d162057f2458a.png&amp;width=360, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fvisualization-ccf322a44eb79a3a693d162057f2458a.png&amp;width=360&amp;dpr=2 2x" media="(max-width: 360px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fvisualization-ccf322a44eb79a3a693d162057f2458a.png&amp;width=480, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fvisualization-ccf322a44eb79a3a693d162057f2458a.png&amp;width=480&amp;dpr=2 2x" media="(min-width: 360.1px) and (max-width: 480px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fvisualization-ccf322a44eb79a3a693d162057f2458a.png&amp;width=768, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fvisualization-ccf322a44eb79a3a693d162057f2458a.png&amp;width=768&amp;dpr=2 2x" media="(min-width: 480.1px) and (max-width: 768px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fvisualization-ccf322a44eb79a3a693d162057f2458a.png&amp;width=1024, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fvisualization-ccf322a44eb79a3a693d162057f2458a.png&amp;width=1024&amp;dpr=2 2x" media="(min-width: 768.1px) and (max-width: 1024px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fvisualization-ccf322a44eb79a3a693d162057f2458a.png&amp;width=1440, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fvisualization-ccf322a44eb79a3a693d162057f2458a.png&amp;width=1440&amp;dpr=2 2x" media="(min-width: 1024.1px) and (max-width: 1440px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fvisualization-ccf322a44eb79a3a693d162057f2458a.png&amp;width=1920, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fvisualization-ccf322a44eb79a3a693d162057f2458a.png&amp;width=1920&amp;dpr=2 2x" media="(min-width: 1440.1px) and (max-width: 1920px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fvisualization-ccf322a44eb79a3a693d162057f2458a.png" media="(min-width: 1920.1px)"><img alt="A cat sitting on a wall with a green bounding box applied to the bitmap. The bounding box is labeled â€œcat.â€" src="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fvisualization-ccf322a44eb79a3a693d162057f2458a.png" loading=lazy decoding=async class=Djd3YO_2></picture></a><figcaption class=_2tKCaBqq>Visualization of Object Detection Semantic Metadata</figcaption></figure></div><p>The next code snippet illustrates the use of Cortex&rsquo;s <a class=link href=https://rapidapi.com/nevenp/api/cortex4/ target=_blank rel=noopener>paid version</a> to filter and retrieve URLs of scraped images:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=cl><span class=kn>import</span> <span class=nn>json</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>requests</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>url</span> <span class=o>=</span> <span class=s1>&#39;https://cortex4.p.rapidapi.com/get-labeled-data&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>querystring</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;page&#39;</span><span class=p>:</span> <span class=s1>&#39;1&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>              <span class=s1>&#39;q&#39;</span><span class=p>:</span> <span class=s1>&#39;{&#34;object_analysis&#34;: {&#34;$elemMatch&#34;: {&#34;$elemMatch&#34;: {&#34;classname&#34;: &#34;cat&#34;}}}, &#34;width&#34;: {&#34;$gt&#34;: 100}}&#39;</span><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>headers</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>   <span class=s1>&#39;X-RapidAPI-Key&#39;</span><span class=p>:</span> <span class=s1>&#39;SIGN-UP-FOR-KEY&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>   <span class=s1>&#39;X-RapidAPI-Host&#39;</span><span class=p>:</span> <span class=s1>&#39;cortex4.p.rapidapi.com&#39;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>response</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>request</span><span class=p>(</span><span class=s2>&#34;GET&#34;</span><span class=p>,</span> <span class=n>url</span><span class=p>,</span> <span class=n>headers</span><span class=o>=</span><span class=n>headers</span><span class=p>,</span> <span class=n>params</span><span class=o>=</span><span class=n>querystring</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>content</span> <span class=o>=</span> <span class=n>json</span><span class=o>.</span><span class=n>loads</span><span class=p>(</span><span class=n>response</span><span class=o>.</span><span class=n>content</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>This endpoint employs a <a class=link href=https://www.mongodb.com/docs/manual/tutorial/query-documents/ target=_blank rel=noopener>MongoDB Query Language query</a> (<code>q</code>) to filter the database based on semantic metadata and retrieves data based on the page number provided in the <code>page</code> body parameter.</p><p>The example query returns images tagged with the &ldquo;cat&rdquo; object analysis semantic metadata and having a width exceeding 100 pixels. The response content is structured as follows:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>{
</span></span><span class=line><span class=cl>   &#34;output&#34;:[
</span></span><span class=line><span class=cl>      {
</span></span><span class=line><span class=cl>         &#34;_id&#34;:&#34;PT::639339ad4552ef52aba0b372&#34;,
</span></span><span class=line><span class=cl>         &#34;url&#34;:&#34;https://teamglobalasset.com/rtp/PP/31.png&#34;,
</span></span><span class=line><span class=cl>         &#34;datetime&#34;:&#34;2022-12-09 13:35:41.733010&#34;,
</span></span><span class=line><span class=cl>         &#34;object_analysis_processed&#34;:&#34;true&#34;,
</span></span><span class=line><span class=cl>         &#34;pose_estimation_processed&#34;:&#34;false&#34;,
</span></span><span class=line><span class=cl>         &#34;face_analysis_processed&#34;:&#34;false&#34;,
</span></span><span class=line><span class=cl>         &#34;source&#34;:&#34;commoncrawl&#34;,
</span></span><span class=line><span class=cl>         &#34;type&#34;:&#34;image&#34;,
</span></span><span class=line><span class=cl>         &#34;height&#34;:234,
</span></span><span class=line><span class=cl>         &#34;width&#34;:325,
</span></span><span class=line><span class=cl>         &#34;hash&#34;:&#34;bf2f1a63ecb221262676c2650de5a9c667ef431c7d2350620e487b029541cf7a&#34;,
</span></span><span class=line><span class=cl>         &#34;object_analysis&#34;:[
</span></span><span class=line><span class=cl>            [
</span></span><span class=line><span class=cl>               {
</span></span><span class=line><span class=cl>                  &#34;classname&#34;:&#34;cat&#34;,
</span></span><span class=line><span class=cl>                  &#34;conf&#34;:0.9602264761924744,
</span></span><span class=line><span class=cl>                  &#34;x1&#34;:245,
</span></span><span class=line><span class=cl>                  &#34;y1&#34;:65,
</span></span><span class=line><span class=cl>                  &#34;x2&#34;:323,
</span></span><span class=line><span class=cl>                  &#34;y2&#34;:176
</span></span><span class=line><span class=cl>               },
</span></span><span class=line><span class=cl>               {
</span></span><span class=line><span class=cl>                  &#34;classname&#34;:&#34;dog&#34;,
</span></span><span class=line><span class=cl>                  &#34;conf&#34;:0.8493766188621521,
</span></span><span class=line><span class=cl>                  &#34;x1&#34;:68,
</span></span><span class=line><span class=cl>                  &#34;y1&#34;:18,
</span></span><span class=line><span class=cl>                  &#34;x2&#34;:255,
</span></span><span class=line><span class=cl>                  &#34;y2&#34;:170
</span></span><span class=line><span class=cl>               }
</span></span><span class=line><span class=cl>            ]
</span></span><span class=line><span class=cl>         ],
</span></span><span class=line><span class=cl>         â€œlabel_quality_estimationâ€:3.492028982676312e-18
</span></span><span class=line><span class=cl>      }, â€¦ &lt;up to 25 data points in total&gt;
</span></span><span class=line><span class=cl>   ]
</span></span><span class=line><span class=cl>   &#34;length&#34;:1454
</span></span><span class=line><span class=cl>}
</span></span></code></pre></td></tr></table></div></div><p>Each page of the output contains up to 25 data points, including semantic metadata, structural attributes, and source information (e.g., &ldquo;commoncrawl&rdquo;). The total number of query results is indicated by the <code>length</code> key.</p><h3 id=foundation-models-and-chatgpt-integration>Foundation Models and ChatGPT Integration</h3><p><a class=link href=https://crfm.stanford.edu/ target=_blank rel=noopener>Foundation models</a>, or AI models pretrained on vast amounts of unlabeled data using self-supervised learning, have revolutionized AI since their emergence in 2018. These models can be further fine-tuned for specific tasks (e.g., mimicking a particular writing style) using smaller, labeled data sets, making them adaptable to a wide range of applications.</p><p>Cortex&rsquo;s labeled data sets can serve as a reliable data source to enhance the starting point provided by pretrained models, surpassing even foundation models that still rely on labels for self-supervised pretraining. By harnessing the power of Cortex&rsquo;s extensive labeled data, AI models can achieve higher pretraining effectiveness and, consequently, greater accuracy when fine-tuned. Cortex differentiates itself through its scale and diversity, with the data set continuously expanding and incorporating new data points and diverse labels. At the time of publication, it housed over 20 million data points.</p><p>Furthermore, Cortex offers a customized ChatGPT chatbot, granting users unparalleled access to and utilization of its meticulously labeled data repository. This user-friendly feature augments ChatGPT&rsquo;s capabilities by providing deep access to both semantic and structural metadata for images, with plans to extend this functionality beyond images in the future.</p><div data-testid=image-container class="X3Bg-O9c _1xIzGpI7"><figure class=_1sK7TguO><a href=https://bs-uploads.toptal.io/blackfish-uploads/public_files/chatgpt-757f4ddeb1648bc6281a76b335ed12f9.png target=_blank rel="noopener noreferrer" class=_5xZOBTsv><picture class=!contents data-testid=picture><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fchatgpt-757f4ddeb1648bc6281a76b335ed12f9.png&amp;width=360, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fchatgpt-757f4ddeb1648bc6281a76b335ed12f9.png&amp;width=360&amp;dpr=2 2x" media="(max-width: 360px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fchatgpt-757f4ddeb1648bc6281a76b335ed12f9.png&amp;width=480, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fchatgpt-757f4ddeb1648bc6281a76b335ed12f9.png&amp;width=480&amp;dpr=2 2x" media="(min-width: 360.1px) and (max-width: 480px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fchatgpt-757f4ddeb1648bc6281a76b335ed12f9.png&amp;width=768, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fchatgpt-757f4ddeb1648bc6281a76b335ed12f9.png&amp;width=768&amp;dpr=2 2x" media="(min-width: 480.1px) and (max-width: 768px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fchatgpt-757f4ddeb1648bc6281a76b335ed12f9.png&amp;width=1024, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fchatgpt-757f4ddeb1648bc6281a76b335ed12f9.png&amp;width=1024&amp;dpr=2 2x" media="(min-width: 768.1px) and (max-width: 1024px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fchatgpt-757f4ddeb1648bc6281a76b335ed12f9.png&amp;width=1440, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fchatgpt-757f4ddeb1648bc6281a76b335ed12f9.png&amp;width=1440&amp;dpr=2 2x" media="(min-width: 1024.1px) and (max-width: 1440px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fchatgpt-757f4ddeb1648bc6281a76b335ed12f9.png&amp;width=1920, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fchatgpt-757f4ddeb1648bc6281a76b335ed12f9.png&amp;width=1920&amp;dpr=2 2x" media="(min-width: 1440.1px) and (max-width: 1920px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fchatgpt-757f4ddeb1648bc6281a76b335ed12f9.png" media="(min-width: 1920.1px)"><img alt="A Cortex ChatGPT demonstration displays a prompt asking it to find images with â€œcatâ€ labels and other parameters; the chatbotâ€™s reply displays two matching cat images." src="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fpublic_files%2Fchatgpt-757f4ddeb1648bc6281a76b335ed12f9.png" loading=lazy decoding=async class=Djd3YO_2></picture></a><figcaption class=_2tKCaBqq>Customized ChatGPT Chatbot</figcaption></figure></div><p>In its current state, Cortex allows users to task the customized ChatGPT chatbot with retrieving images containing specific items occupying most of the image space or images featuring multiple items. This customized ChatGPT comprehends deep semantics and can search for particular image types based on simple prompts. Future refinements incorporating diverse object classes will transform this custom GPT into a powerful image search chatbot.</p><h2 id=image-data-labeling-the-backbone-of-ai-systems>Image Data Labeling: The Backbone of AI Systems</h2><p>We are inundated with data, yet most unprocessed raw data holds little value for training purposes and requires refinement for building successful AI systems. Cortex addresses this challenge by facilitating the transformation of vast raw data quantities into valuable data sets. By enabling the rapid refinement of raw data, Cortex reduces reliance on external data sources and services, accelerates training, and empowers the creation of more accurate and tailored AI models.</p><p>While the system currently provides semantic metadata for object analysis with quality estimations, it will eventually encompass face analysis, pose estimation, and visual embeddings. Plans are also underway to incorporate modalities beyond images, including video, audio, and text data. While currently returning <code>width</code> and <code>height</code> structural attributes, the system will expand to include pixel histograms as well.</p><p>As AI systems become increasingly ubiquitous, the demand for high-quality data will continue to soar, prompting an evolution in data collection and processing methods. Current AI solutions are only as good as the data they learn from. Meticulous training on large, high-quality data sets is crucial for unlocking their full potential. Ultimately, the goal is to utilize Cortex to index and annotate as much publicly available data as possible, creating an invaluable repository of high-quality labeled data for training the next generation of AI systems.</p><p><em>The editorial team of the Toptal Engineering Blog extends its sincere appreciation to Shanglun Wang for reviewing the code samples and technical content presented in this article.</em></p><p><em>All data set images and sample images are courtesy of <a class=link href=https://www.piculjantechnologies.ai/ target=_blank rel=noopener><em>PiÄuljan Technologies</em></a></em>._</p></section><footer class=article-footer><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section></footer></article><footer class=site-footer><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3987358164777632" crossorigin=anonymous></script><script>(function(e,t,n,s,o){e[s]=e[s]||[],e[s].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var a=t.getElementsByTagName(n)[0],i=t.createElement(n),r=s!="dataLayer"?"&l="+s:"";i.async=!0,i.src="https://www.googletagmanager.com/gtm.js?id="+o+r,a.parentNode.insertBefore(i,a)})(window,document,"script","dataLayer","GTM-5X67X4Q4")</script><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5X67X4Q4" height=0 width=0 style=display:none;visibility:hidden></iframe></noscript></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>