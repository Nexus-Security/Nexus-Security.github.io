<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="TensorFlow, a leading deep learning tool developed by Google, excels at training and deploying complex neural networks. Its ability to optimize architectures with millions of parameters and its extensive toolkit for hardware acceleration, distributed training, and production workflows make it a powerful option. While these features might seem daunting for tasks outside deep learning, TensorFlow offers accessibility and usability for simpler problems as well. At its core, TensorFlow is an optimized library for tensor operations (vectors, matrices) and calculus operations for gradient descent on any sequence of calculations. Gradient descent, a cornerstone of computational mathematics, traditionally demanded application-specific code and equations. However, TensorFlow&rsquo;s &ldquo;automatic differentiation&rdquo; architecture streamlines this process, as we will explore.\n"><title>The Various Uses of Gradient Descent in TensorFlow</title>
<link rel=canonical href=https://Nexus-Security.github.io/the-various-uses-of-gradient-descent-in-tensorflow/><link rel=stylesheet href=/scss/style.min.0304c6baf04e01a8fe70693791cb744d56a3578a3120a8796cefc66825aa39c7.css><meta property='og:title' content="The Various Uses of Gradient Descent in TensorFlow"><meta property='og:description' content="TensorFlow, a leading deep learning tool developed by Google, excels at training and deploying complex neural networks. Its ability to optimize architectures with millions of parameters and its extensive toolkit for hardware acceleration, distributed training, and production workflows make it a powerful option. While these features might seem daunting for tasks outside deep learning, TensorFlow offers accessibility and usability for simpler problems as well. At its core, TensorFlow is an optimized library for tensor operations (vectors, matrices) and calculus operations for gradient descent on any sequence of calculations. Gradient descent, a cornerstone of computational mathematics, traditionally demanded application-specific code and equations. However, TensorFlow&rsquo;s &ldquo;automatic differentiation&rdquo; architecture streamlines this process, as we will explore.\n"><meta property='og:url' content='https://Nexus-Security.github.io/the-various-uses-of-gradient-descent-in-tensorflow/'><meta property='og:site_name' content='Nexus Security'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:published_time' content='2023-04-23T00:00:00+00:00'><meta property='article:modified_time' content='2023-04-23T00:00:00+00:00'><meta name=twitter:title content="The Various Uses of Gradient Descent in TensorFlow"><meta name=twitter:description content="TensorFlow, a leading deep learning tool developed by Google, excels at training and deploying complex neural networks. Its ability to optimize architectures with millions of parameters and its extensive toolkit for hardware acceleration, distributed training, and production workflows make it a powerful option. While these features might seem daunting for tasks outside deep learning, TensorFlow offers accessibility and usability for simpler problems as well. At its core, TensorFlow is an optimized library for tensor operations (vectors, matrices) and calculus operations for gradient descent on any sequence of calculations. Gradient descent, a cornerstone of computational mathematics, traditionally demanded application-specific code and equations. However, TensorFlow&rsquo;s &ldquo;automatic differentiation&rdquo; architecture streamlines this process, as we will explore.\n"><link rel="shortcut icon" href=/fav.ico></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"light")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><ol class=menu-social><li><a href=https://github.com/Nexus-Security target=_blank title=GitHub rel=me><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="150" height="150" viewBox="0 0 150 150"><defs><filter id="alpha" filterUnits="objectBoundingBox" x="0" y="0" width="100%" height="100%"><feColorMatrix type="matrix" in="SourceGraphic" values="0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0"/></filter><mask id="mask0"><g filter="url(#alpha)"><rect x="0" y="0" width="150" height="150" style="fill:#000;fill-opacity:.2;stroke:none"/></g></mask><clipPath id="clip1"><rect x="0" y="0" width="150" height="150"/></clipPath><g id="surface5" clip-path="url(#clip1)"><path style="stroke:none;fill-rule:nonzero;fill:#fff;fill-opacity:1" d="M10.9375 83.867188c0-12.109376 3.46875-21.816407 10.925781-30.535157.71875-.875.925781000000001-2.058593.550781000000001-3.125C21.6875 48.125 21.40625 33.070312 26.488281 17.675781c4.78125 1.207031 16.300781 5.050781 31.65625 16.398438C58.9375 34.65625 59.957031 34.84375 60.894531 34.554688 64.824219 33.382812 71.851562 32.6875 79.6875 32.6875S94.550781 33.386719 98.476562 34.554688C99.417969 34.835938 100.433594 34.65625 101.226562 34.074219 113.96875 24.65625 124.011719 20.445312 129.8125 18.582031c-.476562000000001-1.882812-1.019531-3.746093-1.625-5.589843-4.78125 1.207031-16.300781 5.050781-31.648438 16.394531C95.746094 29.96875 94.730469 30.144531 93.789062 29.867188c-3.925781-1.171876-10.953124-1.875-18.789062-1.875-7.832031.0-14.855469.703124000000003-18.792969 1.871093C55.265625 30.144531 54.246094 29.964844 53.457031 29.382812c-15.355469-11.34375-26.875-15.1875-31.65625-16.402343C16.71875 28.382812 17 43.4375 17.726562 45.523438 18.101562 46.589844 17.890625 47.777344 17.175781 48.648438 9.71875 57.367188 6.25 67.070312 6.25 79.179688c0 23.515624 7.175781 37.921874 17.417969 46.550781C16.007812 116.851562 10.9375 103.582031 10.9375 83.867188zm0 0"/></g><mask id="mask1"><g filter="url(#alpha)"><rect x="0" y="0" width="150" height="150" style="fill:#000;fill-opacity:.101961;stroke:none"/></g></mask><clipPath id="clip2"><rect x="0" y="0" width="150" height="150"/></clipPath><g id="surface8" clip-path="url(#clip2)"><path style="stroke:none;fill-rule:nonzero;fill:#000;fill-opacity:1" d="M32.34375 78.5c3.945312-4 9.382812-5.074219 16.039062-5.074219C51.925781 73.425781 55.824219 73.730469 60.023438 74.054688c4.71875.375 9.589843.71875 14.84375.746093000000002C80.335938 74.917969 85.210938 74.425781 89.976562 74.054688 102.070312 73.125 111.605469 72.367188 117.648438 78.492188c4.527343 4.601562 6.890624 10.328124 7.21875 16.945312C124.925781 94.398438 125 93.382812 125 92.261719c0-7.285157-2.476562-13.492188-7.351562-18.449219-6.042969-6.117188-15.578126-5.367188-27.671876-4.4375C85.210938 69.742188 80.34375 70.238281 74.867188 70.117188 69.914062 70.0625 64.960938 69.8125 60.023438 69.375 55.824219 69.050781 51.929688 68.742188 48.382812 68.742188c-6.65625.0-12.09375 1.070312-16.039062 5.078124C27.476562 78.769531 25 84.976562 25 92.261719 25 93.375 25.074219 94.398438 25.132812 95.445312 25.460938 88.820312 27.820312 83.101562 32.34375 78.5zm0 0"/></g><linearGradient id="linear0" gradientUnits="userSpaceOnUse" x1="10.768" y1="13.86" x2="18.633" y2="21.724" gradientTransform="matrix(6.25,0,0,6.25,0,0)"><stop offset="0" style="stop-color:#000;stop-opacity:.101961"/><stop offset="1" style="stop-color:#000;stop-opacity:0"/></linearGradient><linearGradient id="linear1" gradientUnits="userSpaceOnUse" x1="4.004" y1="18.529" x2="4.047" y2="18.573" gradientTransform="matrix(6.25,0,0,6.25,0,0)"><stop offset="0" style="stop-color:#000;stop-opacity:.101961"/><stop offset="1" style="stop-color:#000;stop-opacity:0"/></linearGradient><linearGradient id="linear2" gradientUnits="userSpaceOnUse" x1=".617" y1="5.771" x2="23.69" y2="16.53" gradientTransform="matrix(6.25,0,0,6.25,0,0)"><stop offset="0" style="stop-color:#fff;stop-opacity:.2"/><stop offset="1" style="stop-color:#fff;stop-opacity:0"/></linearGradient></defs><g id="surface1"><path style="stroke:none;fill-rule:nonzero;fill:#303c42;fill-opacity:1" d="M138.570312 45.789062C139.492188 39.613281 138.867188 23.738281 133.167969 8.292969 132.660156 6.945312 131.300781 6.113281 129.867188 6.273438 129.269531 6.34375 115.1875 8.164062 94.039062 23.46875 89.445312 22.363281 82.632812 21.742188 75 21.742188s-14.4375.625-19.042969 1.726562C34.800781 8.15625 20.71875 6.34375 20.117188 6.273438 18.6875 6.117188 17.332031 6.949219 16.820312 8.292969 11.117188 23.738281 10.5 39.613281 11.425781 45.789062 3.742188 55.289062.0 66.230469.0 79.179688c0 41.632812 21.824219 64.558593 61.457031 64.558593L75 143.75 88.539062 143.738281C128.167969 143.738281 150 120.8125 150 79.179688c0-12.949219-3.742188-23.890626-11.429688-33.390626zm0 0"/><path style="stroke:none;fill-rule:nonzero;fill:#5c6671;fill-opacity:1" d="M88.539062 137.488281 75 137.5 61.457031 137.488281C36.273438 137.488281 6.25 127.367188 6.25 79.179688c0-12.109376 3.46875-21.816407 10.925781-30.535157.71875-.875.925781000000001-2.058593.550781000000001-3.125C17 43.4375 16.71875 28.382812 21.800781 12.988281c4.78125 1.207031 16.300781 5.050781 31.65625 16.398438C54.25 29.96875 55.269531 30.15625 56.207031 29.867188c3.9375-1.171876 10.960938-1.875 18.792969-1.875 7.835938.0 14.863281.703124000000003 18.789062 1.871093C94.730469 30.140625 95.746094 29.964844 96.539062 29.382812c15.347657-11.34375 26.867188-15.1875 31.648438-16.394531 5.082031 15.394531 4.804688 30.449219 4.082031 32.53125C131.867188 46.585938 132.078125 47.785156 132.820312 48.648438 140.273438 57.367188 143.75 67.070312 143.75 79.179688c0 48.1875-30.023438 58.308593-55.210938 58.308593zm0 0"/><use xlink:href="#surface5" mask="url(#mask0)"/><path style="stroke:none;fill-rule:nonzero;fill:#303c42;fill-opacity:1" d="M89.488281 63.144531C84.886719 63.507812 80.125 63.875 75.226562 63.875H74.78125C69.875 63.875 65.117188 63.5 60.519531 63.144531 47.898438 62.164062 35.988281 61.230469 27.894531 69.429688 21.824219 75.59375 18.75 83.28125 18.75 92.261719 18.75 128.238281 46.429688 131.25 75.226562 131.25c28.34375.0 56.023438-3.011719 56.023438-38.988281.0-8.988281-3.074219-16.667969-9.144531-22.835938-8.085938-8.195312-20.003907-7.269531-32.617188-6.28125zm0 0"/><path style="stroke:none;fill-rule:nonzero;fill:#d9cfcc;fill-opacity:1" d="M74.773438 125C42.492188 125 25 119.78125 25 92.261719c0-7.285157 2.476562-13.492188 7.34375-18.449219 3.945312-4 9.382812-5.074219 16.039062-5.074219C51.925781 68.738281 55.824219 69.042969 60.023438 69.367188c4.71875.375 9.589843.71875 14.84375.746093000000002C80.335938 70.230469 85.210938 69.738281 89.976562 69.367188c12.09375-.929687999999999 21.628907-1.6875 27.671876 4.4375C122.523438 78.769531 125 84.976562 125 92.261719 125 119.78125 107.507812 125 74.773438 125zm0 0"/><use xlink:href="#surface8" mask="url(#mask1)"/><path style="stroke:none;fill-rule:nonzero;fill:#303c42;fill-opacity:1" d="M50 75c-7.125.0-12.5 9.40625-12.5 21.875S42.875 118.75 50 118.75s12.5-9.40625 12.5-21.875S57.125 75 50 75zm0 0"/><path style="stroke:none;fill-rule:nonzero;fill:#6d4c41;fill-opacity:1" d="M50 112.5c-2.550781.0-6.25-6.085938-6.25-15.625S47.449219 81.25 50 81.25s6.25 6.085938 6.25 15.625S52.550781 112.5 50 112.5zm0 0"/><path style="stroke:none;fill-rule:nonzero;fill:#303c42;fill-opacity:1" d="M1e2 75c-7.125.0-12.5 9.40625-12.5 21.875S92.875 118.75 1e2 118.75s12.5-9.40625 12.5-21.875S107.125 75 1e2 75zm0 0"/><path style="stroke:none;fill-rule:nonzero;fill:#6d4c41;fill-opacity:1" d="M1e2 112.5c-2.550781.0-6.25-6.085938-6.25-15.625S97.449219 81.25 1e2 81.25s6.25 6.085938 6.25 15.625S102.550781 112.5 1e2 112.5zm0 0"/><path style="stroke:none;fill-rule:nonzero;fill:#a1887f;fill-opacity:1" d="M52.21875 90.511719c0 1.539062-1.246094 2.789062-2.789062 2.789062-1.539063.0-2.785157-1.25-2.785157-2.789062.0-1.539063 1.246094-2.785157 2.785157-2.785157 1.542968.0 2.789062 1.246094 2.789062 2.785157zm0 0"/><path style="stroke:none;fill-rule:nonzero;fill:#a1887f;fill-opacity:1" d="M102.21875 90.511719c0 1.539062-1.246094 2.789062-2.789062 2.789062-1.539063.0-2.785157-1.25-2.785157-2.789062.0-1.539063 1.246094-2.785157 2.785157-2.785157 1.542968.0 2.789062 1.246094 2.789062 2.785157zm0 0"/><path style="stroke:none;fill-rule:nonzero;fill:url(#linear0)" d="M125 72.8125 124.894531 72.855469C129.039062 78.382812 131.25 84.851562 131.25 92.261719c0 35.976562-27.679688 38.988281-56.023438 38.988281-16.664062.0-32.914062-1.054688-43.683593-8.875l13.386719 13.386719c5.507812 1.207031 11.121093 1.71875 16.527343 1.71875L75 137.5 88.539062 137.488281c22.992188.0 49.941407-8.53125 54.472657-46.664062zm0 0"/><path style="stroke:none;fill-rule:nonzero;fill:url(#linear1)" d="M25.070312 115.800781 25 115.832031 25.269531 116.101562zm0 0"/><path style="stroke:none;fill-rule:nonzero;fill:url(#linear2)" d="M138.570312 45.789062C139.492188 39.613281 138.867188 23.738281 133.167969 8.292969 132.660156 6.945312 131.300781 6.113281 129.867188 6.273438 129.269531 6.34375 115.1875 8.164062 94.039062 23.46875 89.445312 22.363281 82.632812 21.742188 75 21.742188s-14.4375.625-19.042969 1.726562C34.800781 8.15625 20.71875 6.34375 20.117188 6.273438 18.6875 6.117188 17.332031 6.949219 16.820312 8.292969 11.117188 23.738281 10.5 39.613281 11.425781 45.789062 3.742188 55.289062.0 66.230469.0 79.179688c0 41.632812 21.824219 64.558593 61.457031 64.558593L75 143.75 88.539062 143.738281C128.167969 143.738281 150 120.8125 150 79.179688c0-12.949219-3.742188-23.890626-11.429688-33.390626zm0 0"/></g></svg></a></li><li><a href=mailto:0x000216@gmail.com target=_blank title=Email rel=me><svg width="512" height="512" viewBox="0 0 512 512"><path d="M33.994 73.934C27.135 76.021 21.866 80.426 18.364 87 16.567 90.374 16.5 96.438 16.5 256V421.5l2.158 4C21.184 430.18 25.101 434.027 30 436.636 33.003 438.235 36.304 438.546 53.246 438.825L72.993 439.15l.253-137.978L73.5 163.194 90 175.45C99.075 182.191 140.17 212.762 181.321 243.386l74.821 55.68 21.179-15.752C288.97 274.65 330 244.021 368.5 215.248l70-52.312L438.754 301.043 439.007 439.15 458.754 438.825C476.726 438.529 478.859 438.306 482.5 436.342 487.18 433.816 491.027 429.899 493.636 425 495.433 421.626 495.5 415.562 495.5 256 495.5 96.438 495.433 90.374 493.636 87 488.565 77.48 482.099 73.799 469.397 73.202L460.293 72.774 454.397 77.337C439.883 88.566 256.423 221.935 255.772 221.73 254.976 221.479 78.972 93.309 62.177 80.75L51.812 73 44.156 73.086C39.945 73.133 35.372 73.515 33.994 73.934" stroke="none" fill="#d34c3c" fill-rule="evenodd"/><path d="M54.528 74.911C55.612 75.963 74.953 90.25 97.507 106.661c22.555 16.412 67.228 48.964 99.275 72.339s58.594 42.604 58.993 42.731C256.549 221.978 454.147 78.147 457.472 74.916 459.416 73.028 456.501 73 256 73 55.677 73 52.586 73.029 54.528 74.911M73 300.878V439H256 439V300.941C439 190.749 438.748 163.038 437.75 163.654 437.063 164.078 405.45 187.632 367.5 215.994c-37.95 28.363-78.528 58.655-90.173 67.316l-21.173 15.748-66.827-49.716C152.572 221.999 111.925 191.776 99 182.18s-24.062-17.892-24.75-18.436C73.251 162.954 73 190.519 73 300.878" stroke="none" fill="#e5e5e5" fill-rule="evenodd"/></svg></a></li><li><a href=https://nexus-security.github.io/index.xml target=_blank title=RSS rel=me><svg id="Layer_1" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 512 512" style="enable-background:new 0 0 512 512"><path style="fill:#f78c20" d="M78.333 355.334C35.14 355.334.0 390.474.0 433.667S35.14 512 78.333 512s78.333-35.14 78.333-78.333-35.14-78.333-78.333-78.333z"/><g><path style="fill:#ffa929" d="M78.333 381.445c-28.795.0-52.222 23.427-52.222 52.222s23.427 52.222 52.222 52.222 52.222-23.427 52.222-52.222-23.427-52.222-52.222-52.222z"/><path style="fill:#ffa929" d="M477.918 264.861c-21.843-51.641-53.111-98.019-92.936-137.842-39.824-39.824-86.201-71.093-137.843-92.935C193.669 11.468 136.874.0 78.333.0c-4.807.0-8.704 3.897-8.704 8.704v85.519c0 4.807 3.897 8.704 8.704 8.704 182.37.0 330.74 148.369 330.74 330.74.0 4.807 3.897 8.704 8.704 8.704h85.52c4.807.0 8.704-3.897 8.704-8.704C512 375.126 500.533 318.331 477.918 264.861z"/><path style="fill:#ffa929" d="M78.333 163.853c-4.807.0-8.704 3.897-8.704 8.704v95.74c0 4.807 3.897 8.704 8.704 8.704 86.386.0 156.666 70.281 156.666 156.666.0 4.807 3.897 8.704 8.704 8.704h95.74c4.807.0 8.704-3.897 8.704-8.704.0-72.07-28.065-139.826-79.027-190.787-50.961-50.961-118.717-79.027-190.787-79.027z"/></g><g><path style="fill:#f78c20" d="M78.333 242.186c-2.918.0-5.817.076-8.704.206v25.905c0 4.807 3.897 8.704 8.704 8.704 86.386.0 156.666 70.281 156.666 156.666.0 4.807 3.897 8.704 8.704 8.704h25.905c.129-2.886.206-5.786.206-8.704.0-105.752-85.729-191.481-191.481-191.481z"/><path style="fill:#f78c20" d="M78.333 68.113c-2.91.0-5.81.042-8.704.11v26.001c0 4.807 3.897 8.704 8.704 8.704 182.37.0 330.74 148.369 330.74 330.74.0 4.807 3.897 8.704 8.704 8.704h26.001c.067-2.894.11-5.793.11-8.704C443.887 231.777 280.223 68.113 78.333 68.113z"/></g><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/></svg></a></li><li><a href=https://x.com/0x000216 target=_blank title=Twitter rel=me><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="150" height="150" viewBox="0 0 150 150"><g id="surface1"><path style="stroke:none;fill-rule:nonzero;fill:#03a9f4;fill-opacity:1" d="M150 33.179688c-5.640625 2.460937-11.609375 4.09375-17.71875 4.855468 6.4375-3.820312 11.25-9.867187 13.527344-16.996094-6.027344 3.574219-12.621094 6.089844-19.5 7.441407-8.628906-9.210938-22.007813-12.214844-33.746094-7.574219-11.738281 4.636719-19.449219 15.980469-19.445312 28.601562.0 2.4375.203124000000003 4.78125.710937000000001 7.015626C49.085938 55.308594 26.03125 43.609375 10.445312 24.355469 2.25 38.402344 6.386719 56.398438 19.894531 65.457031 15.027344 65.324219 10.261719 64.027344 6 61.667969V62.007812c.015625 14.636719 10.304688 27.25 24.636719 30.214844-2.628907.691406000000001-5.339844 1.03125-8.0625 1.011719C20.621094 93.269531 18.667969 93.09375 16.753906 92.710938c4.070313 12.507812 15.585938 21.089843 28.734375 21.421874-10.886719 8.511719-24.308593 13.128907-38.128906 13.113282C4.835938 127.246094 2.417969 127.132812.0 126.824219c14.0625 9.0625 30.445312 13.855469 47.175781 13.800781 56.585938.0 87.523438-46.875 87.523438-87.507812.0-1.359376-.046875-2.671876-.113281000000001-3.972657C140.652344 44.804688 145.875 39.394531 150 33.179688zm0 0"/></g></svg></a></li><li><a href=https://www.minds.com/0x000216/ target=_blank title=Minds rel=me><svg id="Capa_1" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 512 512" style="enable-background:new 0 0 512 512"><g><g><path style="fill:#ffe1b2" d="M256 33.085C245.078 13.38 224.079.0 2e2.0c-23.781.0-45.57 13.293-56.594 34.184C115.711 41.602 96 66.977 96 96c0 .059.0.113.0.172-9.977 7.512-16 19.301-16 31.828.0 1.316.078 2.637.234 3.992C60.211 145.266 48 167.758 48 192c0 14.07 4.039 27.543 11.719 39.262C57.273 236.512 56 242.207 56 248c0 2.738.281 5.445.828 8.098C36.672 267.308 24 288.539 24 312c0 27.973 18.305 52.34 44.109 60.785C65.398 378.828 64 385.324 64 392c0 21.098 13.805 39.508 33.539 45.727C103.891 466.746 129.828 488 160 488c4.617.0 9.227-.512 13.766-1.527C181.992 502 198.141 512 216 512c16.687.0 31.396-8.567 40-21.523V33.085z"/></g><g><g><path style="fill:#ffb980" d="M264 256c-4.422.0-8-3.582-8-8 0-22.055-17.945-40-40-40-8.008.0-15.734 2.355-22.336 6.812-3.023 2.043-7.055 1.781-9.797-.652-3.156-2.809-8.477-6.16-15.867-6.16-4.422.0-8-3.582-8-8s3.578-8 8-8c7.711.0 15.234 2.293 21.719 6.539C197.773 194.246 206.758 192 216 192c30.875.0 56 25.121 56 56C272 252.418 268.422 256 264 256z"/></g></g><g><g><path style="fill:#ffb980" d="M120 120c18.977.0 36.875 7.312 50.414 20.594 3.141 3.09 8.203 3.047 11.312-.109 3.094-3.152 3.047-8.219-.109-11.312C165.07 112.941 143.187 104 120 104c-13.046.0-25.395 2.93-36.542 8.046C81.253 117.019 80 122.423 80 128c0 1.316.078 2.637.234 3.992-.094.062-.173.139-.267.202C91.423 124.501 105.193 120 120 120z"/></g></g><g><g><path style="fill:#ffb980" d="M216 360c0-4.418-3.578-8-8-8s-8 3.582-8 8c0 17.645-14.352 32-32 32-14.211.0-26.82-9.648-30.664-23.465-.703-2.512-2.578-4.523-5.039-5.395-2.453-.871-5.188-.492-7.305 1.02C114.094 371.906 101.305 376 88 376c-6.948.0-13.625-1.149-19.894-3.207-2.214 4.939-3.501 10.19-3.916 15.586C71.714 390.73 79.711 392 88 392c13.297.0 26.187-3.266 37.773-9.52C133.969 397.894 150.141 408 168 408c26.469.0 48-21.531 48-48z"/></g></g><g><path style="fill:#fdc88e" d="M488 312c0-23.461-12.672-44.691-32.828-55.902.547-2.652.828-5.359.828-8.098.0-5.793-1.273-11.488-3.719-16.738C459.961 219.543 464 206.07 464 192c0-24.242-12.211-46.734-32.234-60.008.156-1.355.234-2.676.234-3.992.0-12.527-6.023-24.316-16-31.828.0-.059.0-.113.0-.172.0-29.023-19.711-54.398-47.406-61.816C357.57 13.293 335.781.0 312 0c-24.08.0-45.078 13.38-56 33.085v457.391C264.604 503.433 279.313 512 296 512c17.859.0 34.008-10 42.234-25.527C342.773 487.488 347.383 488 352 488c30.172.0 56.109-21.254 62.461-50.273C434.195 431.508 448 413.097 448 392c0-6.676-1.398-13.172-4.109-19.215C469.695 364.34 488 339.973 488 312z"/></g><g><path style="fill:#f8ab6b" d="M272.008 151.199C272 151.465 272 151.734 272 152c0 26.469 21.531 48 48 48s48-21.531 48-48c0-4.418-3.578-8-8-8s-8 3.582-8 8c0 17.645-14.352 32-32 32s-32-14.355-32-32c0-2.184.219-4.359.656-6.465.492-2.395-.133-4.883-1.703-6.754-1.57-1.871-4.016-3.066-6.352-2.859-.453.012-.891.059-.602.078-13.234.0-24-10.766-24-24v31.813C260.673 147.348 266.061 149.988 272.008 151.199z"/></g><g><path style="fill:#f8ab6b" d="M296 328c9.242.0 18.219-2.246 26.281-6.539C328.765 325.707 336.289 328 344 328c4.422.0 8-3.582 8-8s-3.578-8-8-8c-7.391.0-12.711-3.352-15.867-6.16-2.742-2.434-6.766-2.695-9.797-.656C311.726 309.644 304 312 296 312c-22.055.0-40-17.945-40-40v39.116C266.174 321.517 280.337 328 296 328z"/></g><g><g><path style="fill:#f8ab6b" d="M431.765 131.992c.156-1.355.234-2.676.234-3.992.0-5.577-1.253-10.981-3.458-15.954C417.395 106.93 405.046 104 392 104c-4.422.0-8 3.582-8 8s3.578 8 8 8c14.807.0 28.577 4.501 40.032 12.194C431.939 132.131 431.859 132.054 431.765 131.992z"/></g></g><g><g><path style="fill:#f8ab6b" d="M447.81 388.38c-.415-5.396-1.702-10.647-3.916-15.586C437.624 374.85 430.948 376 424 376c-13.578.0-26.594-4.266-37.641-12.332-2.07-1.5-4.719-1.93-7.133-1.168-2.43.77-4.344 2.648-5.164 5.059C369.101 382.176 355.414 392 340 392c-4.422.0-8 3.582-8 8s3.578 8 8 8c18.875.0 35.961-10.191 45.094-26.156C396.976 388.512 410.258 392 424 392 432.288 392 440.285 390.73 447.81 388.38z"/></g></g></g><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/></svg></a></li><li><a href=https://www.buymeacoffee.com/0x000216 target=_blank title=Coffee rel=me><svg id="Capa_1" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 340 340" style="enable-background:new 0 0 340 340"><g id="XMLID_18_"><polygon id="XMLID_138_" style="fill:#dedde0" points="76.429,290 80,340 170,340 170,290"/><polygon id="XMLID_169_" style="fill:#dedde0" points="170,80 61.429,80 65,130 170,130"/><polygon id="XMLID_197_" style="fill:#acabb1" points="170,290 170,340 260,340 263.571,290"/><polygon id="XMLID_221_" style="fill:#acabb1" points="170,80 170,130 275,130 278.571,80"/><path id="XMLID_222_" style="fill:#ffda44" d="M170 260c-22.091.0-40-22.386-40-50s17.909-50 40-50v-30H65 50l10 160h16.429H170V260z"/><path id="XMLID_33_" style="fill:#ff9811" d="M170 130v30c22.091.0 40 22.386 40 50s-17.909 50-40 50v30h93.571H280l10-160h-15H170z"/><path id="XMLID_223_" style="fill:#50412e" d="M210 210c0-27.614-17.909-50-40-50v1e2c22.091.0 40-22.386 40-50z"/><path id="XMLID_224_" style="fill:#786145" d="M130 210c0 27.614 17.909 50 40 50V160c-22.091.0-40 22.386-40 50z"/><polygon id="XMLID_225_" style="fill:#50412e" points="278.571,80 300,80 300,40 260,40 260,0 80,0 80,40 40,40 40,80 61.429,80 170,80"/></g><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/about/><svg class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg>
<span>About Us</span></a></li><li><a href=/termsofservice/><svg class="icon icon-tabler icon-tabler-pencil" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 20h4L18.5 9.5a1.5 1.5.0 00-4-4L4 16v4"/><line x1="13.5" y1="6.5" x2="17.5" y2="10.5"/></svg>
<span>Terms Of Service</span></a></li><li><a href=/privacypolicy/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Privacy Policy</span></a></li><li><a href=/disclaimer/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>Disclaimer</span></a></li><li><a href=/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/contact/><svg class="icon icon-tabler icon-tabler-mail" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><rect x="3" y="5" width="18" height="14" rx="2"/><polyline points="3 7 12 13 21 7"/></svg>
<span>Contact Us</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>Dark Mode</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#tensorflow-applications>TensorFlow Applications</a></li><li><a href=#example-1-linear-regression-with-gradient-descent-in-tensorflow-20>Example 1: Linear Regression with Gradient Descent in TensorFlow 2.0</a><ol><li><a href=#understanding-gradient-descent>Understanding Gradient Descent</a></li></ol></li><li><a href=#example-2-maximally-separated-unit-vectors>Example 2: Maximally Separated Unit Vectors</a></li><li><a href=#example-3-creating-adversarial-ai-inputs>Example 3: Creating Adversarial AI Inputs</a></li><li><a href=#concluding-thoughts-gradient-descent-optimization>Concluding Thoughts: Gradient Descent Optimization</a></li><li><a href=#tensorflows-gradient-descent-from-minimums-to-ai-system-attacks>TensorFlow&rsquo;s Gradient Descent: From Minimums to AI System Attacks</a></li></ol></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><div class=article-title-wrapper><h2 class=article-title><a href=/the-various-uses-of-gradient-descent-in-tensorflow/>The Various Uses of Gradient Descent in TensorFlow</a></h2></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Apr 23, 2023</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>15 minute read</time></div></footer></div></header><section class=article-content><p>TensorFlow, a leading deep learning tool developed by Google, excels at training and deploying complex neural networks. Its ability to optimize architectures with millions of parameters and its extensive toolkit for hardware acceleration, distributed training, and production workflows make it a powerful option. While these features might seem daunting for tasks outside deep learning, TensorFlow offers accessibility and usability for simpler problems as well. At its core, TensorFlow is an optimized library for tensor operations (vectors, matrices) and calculus operations for gradient descent on any sequence of calculations. Gradient descent, a cornerstone of computational mathematics, traditionally demanded application-specific code and equations. However, TensorFlow&rsquo;s &ldquo;automatic differentiation&rdquo; architecture streamlines this process, as we will explore.</p><h2 id=tensorflow-applications>TensorFlow Applications</h2><ul><li><p><a class=link href=#example-1-linear-regression-with-gradient-descent-in-tensorflow-20>Example 1: Linear Regression with Gradient Descent in TensorFlow 2.0</a></p></li><li><p><a class=link href=#understanding-gradient-descent>Understanding Gradient Descent</a></p></li><li><p><a class=link href=#example-2-maximally-separated-unit-vectors>Example 2: Maximally Separated Unit Vectors</a></p></li><li><p><a class=link href=#example-3-creating-adversarial-ai-inputs>Example 3: Creating Adversarial AI Inputs</a></p></li><li><p><a class=link href=#concluding-thoughts-gradient-descent-optimization>Concluding Thoughts: Gradient Descent Optimization</a></p></li><li><p><a class=link href=#tensorflows-gradient-descent-from-minimums-to-ai-system-attacks>TensorFlow&rsquo;s Gradient Descent: From Minimums to AI System Attacks</a></p></li></ul><h2 id=example-1-linear-regression-with-gradient-descent-in-tensorflow-20>Example 1: Linear Regression with Gradient Descent in TensorFlow 2.0</h2><p><a class=link href=https://github.com/etotheipi/toptal_tensorflow_blog_post/blob/dev/simple_height_vs_weight/tf_grad_desc_intro.ipynb target=_blank rel=noopener>Example 1 Notebook</a></p><p>Before diving into the TensorFlow code, it&rsquo;s crucial to grasp the concepts of gradient descent and linear regression.</p><h3 id=understanding-gradient-descent>Understanding Gradient Descent</h3><p>In essence, gradient descent is a numerical method for determining the inputs to a system of equations that minimize its output. In the realm of machine learning, this system represents our <strong>model</strong>, the inputs are the unknown <strong>parameters</strong>, and the output is a <strong>loss function</strong> to be minimized, indicating the discrepancy between the model and the data. For certain problems, such as linear regression, equations exist to directly calculate the error-minimizing parameters. However, most practical applications necessitate numerical methods like gradient descent for a suitable solution.</p><p>The key takeaway here is that gradient descent typically involves defining equations and using calculus to derive the relationship between the loss function and parameters. TensorFlow, with its auto-differentiation capabilities, handles the calculus, allowing us to focus on solution design rather than implementation intricacies.</p><p>Let&rsquo;s illustrate this with a simple linear regression problem. Given height (h) and weight (w) data for 150 adult males, we start with an initial estimate of the slope and standard deviation of the relationship. After around 15 iterations of gradient descent, we approach a near-optimal solution.</p><div data-testid=image-container class="X3Bg-O9c _1xIzGpI7"><figure class=_1sK7TguO><img alt="Two synchronized animations. The left side shows a height-weight scatterplot, with a fitted line that starts far from the data, then quickly moves toward it, slowing down before it finds the final fit. The right size shows a graph of loss versus iteration, with each frame adding a new iteration to the graph. The loss starts out above the top of the graph at 2,000, but quickly approaches the minimum loss line within a few iterations in what appears to be a logarithmic curve." src=https://bs-uploads.toptal.io/blackfish-uploads/uploaded_file/file/238279/image-1587548990037-a9dc244b868173eb48df437eedc72910.gif loading=lazy decoding=async class=Djd3YO_2></figure></div><p>Let&rsquo;s break down how this solution was achieved using TensorFlow 2.0.</p><p>In linear regression, we posit that weights can be predicted through a linear equation of heights.</p><div data-testid=image-container class="X3Bg-O9c _1xIzGpI7"><figure class=_1sK7TguO><picture class=!contents data-testid=picture><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238274%2Fimage-1587548990039-962ce6f09654b22b53416a14b192f29f.png&amp;width=360, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238274%2Fimage-1587548990039-962ce6f09654b22b53416a14b192f29f.png&amp;width=360&amp;dpr=2 2x" media="(max-width: 360px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238274%2Fimage-1587548990039-962ce6f09654b22b53416a14b192f29f.png&amp;width=480, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238274%2Fimage-1587548990039-962ce6f09654b22b53416a14b192f29f.png&amp;width=480&amp;dpr=2 2x" media="(min-width: 360.1px) and (max-width: 480px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238274%2Fimage-1587548990039-962ce6f09654b22b53416a14b192f29f.png&amp;width=768, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238274%2Fimage-1587548990039-962ce6f09654b22b53416a14b192f29f.png&amp;width=768&amp;dpr=2 2x" media="(min-width: 480.1px) and (max-width: 768px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238274%2Fimage-1587548990039-962ce6f09654b22b53416a14b192f29f.png&amp;width=1024, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238274%2Fimage-1587548990039-962ce6f09654b22b53416a14b192f29f.png&amp;width=1024&amp;dpr=2 2x" media="(min-width: 768.1px) and (max-width: 1024px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238274%2Fimage-1587548990039-962ce6f09654b22b53416a14b192f29f.png&amp;width=1440, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238274%2Fimage-1587548990039-962ce6f09654b22b53416a14b192f29f.png&amp;width=1440&amp;dpr=2 2x" media="(min-width: 1024.1px) and (max-width: 1440px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238274%2Fimage-1587548990039-962ce6f09654b22b53416a14b192f29f.png&amp;width=1920, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238274%2Fimage-1587548990039-962ce6f09654b22b53416a14b192f29f.png&amp;width=1920&amp;dpr=2 2x" media="(min-width: 1440.1px) and (max-width: 1920px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238274%2Fimage-1587548990039-962ce6f09654b22b53416a14b192f29f.png" media="(min-width: 1920.1px)"><img alt="w-subscript-i,pred equals alpha dot-product h-subscript-i plus beta." src="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238274%2Fimage-1587548990039-962ce6f09654b22b53416a14b192f29f.png" loading=lazy decoding=async class=Djd3YO_2></picture></figure></div><p>Our objective is to find the parameters α and β (slope and intercept) that minimize the average squared error (loss) between predicted and actual values. This <em>loss function</em> (mean squared error, or MSE) is represented as:</p><div data-testid=image-container class="X3Bg-O9c _1xIzGpI7"><figure class=_1sK7TguO><picture class=!contents data-testid=picture><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238275%2Fimage-1587548990040-6deb0b387b85bfc766aa7e2a04cf79f1.png&amp;width=360, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238275%2Fimage-1587548990040-6deb0b387b85bfc766aa7e2a04cf79f1.png&amp;width=360&amp;dpr=2 2x" media="(max-width: 360px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238275%2Fimage-1587548990040-6deb0b387b85bfc766aa7e2a04cf79f1.png&amp;width=480, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238275%2Fimage-1587548990040-6deb0b387b85bfc766aa7e2a04cf79f1.png&amp;width=480&amp;dpr=2 2x" media="(min-width: 360.1px) and (max-width: 480px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238275%2Fimage-1587548990040-6deb0b387b85bfc766aa7e2a04cf79f1.png&amp;width=768, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238275%2Fimage-1587548990040-6deb0b387b85bfc766aa7e2a04cf79f1.png&amp;width=768&amp;dpr=2 2x" media="(min-width: 480.1px) and (max-width: 768px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238275%2Fimage-1587548990040-6deb0b387b85bfc766aa7e2a04cf79f1.png&amp;width=1024, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238275%2Fimage-1587548990040-6deb0b387b85bfc766aa7e2a04cf79f1.png&amp;width=1024&amp;dpr=2 2x" media="(min-width: 768.1px) and (max-width: 1024px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238275%2Fimage-1587548990040-6deb0b387b85bfc766aa7e2a04cf79f1.png&amp;width=1440, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238275%2Fimage-1587548990040-6deb0b387b85bfc766aa7e2a04cf79f1.png&amp;width=1440&amp;dpr=2 2x" media="(min-width: 1024.1px) and (max-width: 1440px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238275%2Fimage-1587548990040-6deb0b387b85bfc766aa7e2a04cf79f1.png&amp;width=1920, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238275%2Fimage-1587548990040-6deb0b387b85bfc766aa7e2a04cf79f1.png&amp;width=1920&amp;dpr=2 2x" media="(min-width: 1440.1px) and (max-width: 1920px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238275%2Fimage-1587548990040-6deb0b387b85bfc766aa7e2a04cf79f1.png" media="(min-width: 1920.1px)"><img alt="MSE equals one over N times the sum from i equals one to N of the square of the difference between w-subscript-i,true and w-subscript-i,pred." src="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238275%2Fimage-1587548990040-6deb0b387b85bfc766aa7e2a04cf79f1.png" loading=lazy decoding=async class=Djd3YO_2></picture></figure></div><p>We can visualize the mean squared error for a couple of inaccurate lines and the exact solution (α=6.04, β=-230.5).</p><div data-testid=image-container class="X3Bg-O9c _1xIzGpI7"><figure class=_1sK7TguO><picture class=!contents data-testid=picture><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238276%2Fimage-1587548990041-4ed13644f161ec903b0834f39e50d720.png&amp;width=360, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238276%2Fimage-1587548990041-4ed13644f161ec903b0834f39e50d720.png&amp;width=360&amp;dpr=2 2x" media="(max-width: 360px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238276%2Fimage-1587548990041-4ed13644f161ec903b0834f39e50d720.png&amp;width=480, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238276%2Fimage-1587548990041-4ed13644f161ec903b0834f39e50d720.png&amp;width=480&amp;dpr=2 2x" media="(min-width: 360.1px) and (max-width: 480px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238276%2Fimage-1587548990041-4ed13644f161ec903b0834f39e50d720.png&amp;width=768, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238276%2Fimage-1587548990041-4ed13644f161ec903b0834f39e50d720.png&amp;width=768&amp;dpr=2 2x" media="(min-width: 480.1px) and (max-width: 768px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238276%2Fimage-1587548990041-4ed13644f161ec903b0834f39e50d720.png&amp;width=1024, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238276%2Fimage-1587548990041-4ed13644f161ec903b0834f39e50d720.png&amp;width=1024&amp;dpr=2 2x" media="(min-width: 768.1px) and (max-width: 1024px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238276%2Fimage-1587548990041-4ed13644f161ec903b0834f39e50d720.png&amp;width=1440, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238276%2Fimage-1587548990041-4ed13644f161ec903b0834f39e50d720.png&amp;width=1440&amp;dpr=2 2x" media="(min-width: 1024.1px) and (max-width: 1440px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238276%2Fimage-1587548990041-4ed13644f161ec903b0834f39e50d720.png&amp;width=1920, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238276%2Fimage-1587548990041-4ed13644f161ec903b0834f39e50d720.png&amp;width=1920&amp;dpr=2 2x" media="(min-width: 1440.1px) and (max-width: 1920px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238276%2Fimage-1587548990041-4ed13644f161ec903b0834f39e50d720.png" media="(min-width: 1920.1px)"><img alt="Three copies of the same height-weight scatterplot, each with a different fitted line. The first has w = 4.00 * h + -120.0 and a loss of 1057.0; the line is below the data and less steep than it. The second has w = 2.00 * h + 70.0 and a loss of 720.8; the line is near the upper part of the data points, and even less steep. The hird has w = 60.4 * h + -230.5 and a loss of 127.1; the line passes through the data points such that they appear evenly clustered around it." src="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238276%2Fimage-1587548990041-4ed13644f161ec903b0834f39e50d720.png" loading=lazy decoding=async class=Djd3YO_2></picture></figure></div><p>Now, let&rsquo;s implement this using TensorFlow. The initial step is to code the loss function using tensors and <code>tf.*</code> functions.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>calc_mean_sq_error</span><span class=p>(</span><span class=n>heights</span><span class=p>,</span> <span class=n>weights</span><span class=p>,</span> <span class=n>slope</span><span class=p>,</span> <span class=n>intercept</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>predicted_wgts</span> <span class=o>=</span> <span class=n>slope</span> <span class=o>*</span> <span class=n>heights</span> <span class=o>+</span> <span class=n>intercept</span>
</span></span><span class=line><span class=cl>    <span class=n>errors</span> <span class=o>=</span> <span class=n>predicted_wgts</span> <span class=o>-</span> <span class=n>weights</span>
</span></span><span class=line><span class=cl>    <span class=n>mse</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>reduce_mean</span><span class=p>(</span><span class=n>errors</span><span class=o>**</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>mse</span>
</span></span></code></pre></td></tr></table></div></div><p>The code is quite straightforward. Standard algebraic operators work with tensors, so we ensure our variables are tensors and employ <code>tf.*</code> methods for other operations.</p><p>Next, we incorporate this into a gradient descent loop:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>run_gradient_descent</span><span class=p>(</span><span class=n>heights</span><span class=p>,</span> <span class=n>weights</span><span class=p>,</span> <span class=n>init_slope</span><span class=p>,</span> <span class=n>init_icept</span><span class=p>,</span> <span class=n>learning_rate</span><span class=p>):</span>
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl>    <span class=c1># Any values to be part of gradient calcs need to be vars/tensors</span>
</span></span><span class=line><span class=cl>    <span class=n>tf_slope</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>Variable</span><span class=p>(</span><span class=n>init_slope</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=s1>&#39;float32&#39;</span><span class=p>)</span> 
</span></span><span class=line><span class=cl>    <span class=n>tf_icept</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>Variable</span><span class=p>(</span><span class=n>init_icept</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=s1>&#39;float32&#39;</span><span class=p>)</span> 
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># Hardcoding 25 iterations of gradient descent</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>25</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Do all calculations under a &#34;GradientTape&#34; which tracks all gradients</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>tf</span><span class=o>.</span><span class=n>GradientTape</span><span class=p>()</span> <span class=k>as</span> <span class=n>tape</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>tape</span><span class=o>.</span><span class=n>watch</span><span class=p>((</span><span class=n>tf_slope</span><span class=p>,</span> <span class=n>tf_icept</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># This is the same mean-squared-error calculation as before</span>
</span></span><span class=line><span class=cl>            <span class=n>predictions</span> <span class=o>=</span> <span class=n>tf_slope</span> <span class=o>*</span> <span class=n>heights</span> <span class=o>+</span> <span class=n>tf_icept</span>
</span></span><span class=line><span class=cl>            <span class=n>errors</span> <span class=o>=</span> <span class=n>predictions</span> <span class=o>-</span> <span class=n>weights</span>
</span></span><span class=line><span class=cl>            <span class=n>loss</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>reduce_mean</span><span class=p>(</span><span class=n>errors</span><span class=o>**</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Auto-diff magic!  Calcs gradients between loss calc and params</span>
</span></span><span class=line><span class=cl>        <span class=n>dloss_dparams</span> <span class=o>=</span> <span class=n>tape</span><span class=o>.</span><span class=n>gradient</span><span class=p>(</span><span class=n>loss</span><span class=p>,</span> <span class=p>[</span><span class=n>tf_slope</span><span class=p>,</span> <span class=n>tf_icept</span><span class=p>])</span>
</span></span><span class=line><span class=cl>       
</span></span><span class=line><span class=cl>        <span class=c1># Gradients point towards +loss, so subtract to &#34;descend&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>tf_slope</span> <span class=o>=</span> <span class=n>tf_slope</span> <span class=o>-</span> <span class=n>learning_rate</span> <span class=o>*</span> <span class=n>dloss_dparams</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>tf_icept</span> <span class=o>=</span> <span class=n>tf_icept</span> <span class=o>-</span> <span class=n>learning_rate</span> <span class=o>*</span> <span class=n>dloss_dparams</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span>
</span></span></code></pre></td></tr></table></div></div><p>The elegance of this approach is noteworthy. Gradient descent involves calculating derivatives of the loss function with respect to all variables being optimized. While calculus is inherently involved, we didn&rsquo;t explicitly perform any. The magic lies in:</p><ol><li>TensorFlow constructing a computation graph of all calculations within a <code>tf.GradientTape()</code> scope.</li><li>TensorFlow&rsquo;s ability to compute derivatives (gradients) for every operation, determining how variables within the graph affect each other.</li></ol><p>How does this process behave with different starting points?</p><div data-testid=image-container class="X3Bg-O9c _1xIzGpI7"><figure class=_1sK7TguO><img alt="The same synchronized graphs as before, but also synchronized to a similar pair of graphs beneath them for comparison. The lower pair's loss-iteration graph is similar but seems to converge faster; its corresponding fitted line starts from above the data points rather than below, and closer to its final resting place. " src=https://bs-uploads.toptal.io/blackfish-uploads/uploaded_file/file/238283/image-1587548990042-542862fba846216d3377815baddcea27.gif loading=lazy decoding=async class=Djd3YO_2></figure></div><p>While gradient descent comes close to the optimal MSE, it converges to a significantly different slope and intercept compared to the true optimum in both scenarios. Sometimes, this is attributed to gradient descent settling into local minima. However, linear regression theoretically has a single global minimum. So, why did we arrive at an incorrect slope and intercept?</p><p>The issue lies in our simplification of the code for demonstration purposes. We omitted data normalization, and the slope parameter behaves differently from the intercept. Minute changes in slope can drastically impact the loss, while similar changes in intercept have minimal effect. This scale difference between trainable parameters leads to the slope dominating gradient calculations, rendering the intercept almost irrelevant.</p><p>Consequently, gradient descent primarily optimizes the slope near the initial intercept guess. Since the error is close to the optimum, the gradients are minuscule, resulting in tiny movements with each iteration. Data normalization would have mitigated this issue, but not completely eliminated it.</p><p>This example, though relatively simple, highlights how &ldquo;auto-differentiation&rdquo; handles complexity, as we&rsquo;ll see in subsequent sections.</p><h2 id=example-2-maximally-separated-unit-vectors>Example 2: Maximally Separated Unit Vectors</h2><p><a class=link href=https://github.com/etotheipi/toptal_tensorflow_blog_post/blob/dev/vector_spread_example/vector_spread_example.ipynb target=_blank rel=noopener>Example 2 Notebook</a></p><p>This example stems from an engaging deep learning exercise I encountered last year.</p><p>The premise involves a &ldquo;variational auto-encoder&rdquo; (VAE) capable of generating realistic faces from a set of 32 normally distributed numbers. For suspect identification, the goal is to utilize the VAE to produce a diverse set of (hypothetical) faces for witness selection, subsequently narrowing down the options based on similarity to chosen faces. While random initialization of vectors was suggested, I aimed for an optimal initial state.</p><p>This can be framed as: Given a 32-dimensional space, find a set of X unit vectors that are maximally spread out. In two dimensions, the solution is straightforward. However, for higher dimensions (like 32), there&rsquo;s no easy answer. But, by defining a suitable loss function minimized at our target state, gradient descent might provide a path.</p><div data-testid=image-container class="X3Bg-O9c _1xIzGpI7"><figure class=_1sK7TguO><picture class=!contents data-testid=picture><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238278%2Fimage-1587548990043-29d893f4a90b9c6ba04394d9d7d91075.png&amp;width=360, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238278%2Fimage-1587548990043-29d893f4a90b9c6ba04394d9d7d91075.png&amp;width=360&amp;dpr=2 2x" media="(max-width: 360px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238278%2Fimage-1587548990043-29d893f4a90b9c6ba04394d9d7d91075.png&amp;width=480, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238278%2Fimage-1587548990043-29d893f4a90b9c6ba04394d9d7d91075.png&amp;width=480&amp;dpr=2 2x" media="(min-width: 360.1px) and (max-width: 480px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238278%2Fimage-1587548990043-29d893f4a90b9c6ba04394d9d7d91075.png&amp;width=768, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238278%2Fimage-1587548990043-29d893f4a90b9c6ba04394d9d7d91075.png&amp;width=768&amp;dpr=2 2x" media="(min-width: 480.1px) and (max-width: 768px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238278%2Fimage-1587548990043-29d893f4a90b9c6ba04394d9d7d91075.png&amp;width=1024, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238278%2Fimage-1587548990043-29d893f4a90b9c6ba04394d9d7d91075.png&amp;width=1024&amp;dpr=2 2x" media="(min-width: 768.1px) and (max-width: 1024px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238278%2Fimage-1587548990043-29d893f4a90b9c6ba04394d9d7d91075.png&amp;width=1440, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238278%2Fimage-1587548990043-29d893f4a90b9c6ba04394d9d7d91075.png&amp;width=1440&amp;dpr=2 2x" media="(min-width: 1024.1px) and (max-width: 1440px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238278%2Fimage-1587548990043-29d893f4a90b9c6ba04394d9d7d91075.png&amp;width=1920, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238278%2Fimage-1587548990043-29d893f4a90b9c6ba04394d9d7d91075.png&amp;width=1920&amp;dpr=2 2x" media="(min-width: 1440.1px) and (max-width: 1920px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238278%2Fimage-1587548990043-29d893f4a90b9c6ba04394d9d7d91075.png" media="(min-width: 1920.1px)"><img alt="Two graphs. The left graph, Initial State for All Experiments, has a central point connected to other points, almost all of which form a semi-circle around it; one point stands roughly opposite the semi-circle. The right graph, Target State, is like a wheel, with spokes spread out evenly." src="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238278%2Fimage-1587548990043-29d893f4a90b9c6ba04394d9d7d91075.png" loading=lazy decoding=async class=Djd3YO_2></picture></figure></div><p>Starting with a random set of 20 vectors (as depicted above), we&rsquo;ll experiment with three increasingly complex loss functions to illustrate TensorFlow&rsquo;s capabilities.</p><p>Let&rsquo;s define our training loop, encapsulating the TensorFlow logic within the <code>self.calc_loss()</code> method. By overriding this method for each technique, we can reuse the loop.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Define the framework for trying different loss functions</span>
</span></span><span class=line><span class=cl><span class=c1># Base class implements loop, sub classes override self.calc_loss()</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>VectorSpreadAlgorithm</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># ...</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>calc_loss</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>tensor2d</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>raise</span> <span class=ne>NotImplementedError</span><span class=p>(</span><span class=s2>&#34;Define this in your derived class&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>one_iter</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>i</span><span class=p>,</span> <span class=n>learning_rate</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># self.vecs is an 20x2 tensor, representing twenty 2D vectors</span>
</span></span><span class=line><span class=cl>        <span class=n>tfvecs</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>convert_to_tensor</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>vecs</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>tf</span><span class=o>.</span><span class=n>float32</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>tf</span><span class=o>.</span><span class=n>GradientTape</span><span class=p>()</span> <span class=k>as</span> <span class=n>tape</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>tape</span><span class=o>.</span><span class=n>watch</span><span class=p>(</span><span class=n>tfvecs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>loss</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>calc_loss</span><span class=p>(</span><span class=n>tfvecs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Here&#39;s the magic again. Derivative of spread with respect to</span>
</span></span><span class=line><span class=cl>        <span class=c1># input vectors</span>
</span></span><span class=line><span class=cl>        <span class=n>gradients</span> <span class=o>=</span> <span class=n>tape</span><span class=o>.</span><span class=n>gradient</span><span class=p>(</span><span class=n>loss</span><span class=p>,</span> <span class=n>tfvecs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>vecs</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>vecs</span> <span class=o>-</span> <span class=n>learning_rate</span> <span class=o>*</span> <span class=n>gradients</span>
</span></span></code></pre></td></tr></table></div></div><p>Our first technique is the simplest. We define a spread metric based on the angle between the two closest vectors. Since maximizing spread is our goal, we negate the metric for a minimization problem.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>VectorSpread_Maximize_Min_Angle</span><span class=p>(</span><span class=n>VectorSpreadAlgorithm</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>calc_loss</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>tensor2d</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>angle_pairs</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>acos</span><span class=p>(</span><span class=n>tensor2d</span> <span class=o>@</span> <span class=n>tf</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=n>tensor2d</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>disable_diag</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>eye</span><span class=p>(</span><span class=n>tensor2d</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span> <span class=o>*</span> <span class=mi>2</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>pi</span>
</span></span><span class=line><span class=cl>        <span class=n>spread_metric</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>reduce_min</span><span class=p>(</span><span class=n>angle_pairs</span> <span class=o>+</span> <span class=n>disable_diag</span><span class=p>)</span>    
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># Convention is to return a quantity to be minimized, but we want</span>
</span></span><span class=line><span class=cl>        <span class=c1># to maximize spread. So return negative spread</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=o>-</span><span class=n>spread_metric</span>
</span></span></code></pre></td></tr></table></div></div><p>Matplotlib helps us visualize the results.</p><div data-testid=image-container class="X3Bg-O9c _1xIzGpI7"><figure class=_1sK7TguO><img alt="An animation going from the initial state to the target state. The lone point stays fixed, and the rest of the spokes in the semi-circle take turns jittering back and forth, slowly spreading out and not achieving equidistance even after 1,200 iterations." src=https://bs-uploads.toptal.io/blackfish-uploads/uploaded_file/file/238287/image-1587548990045-92c0aa66a67937ee682aaa968bcdf5f6.gif loading=lazy decoding=async class=Djd3YO_2></figure></div><p>While rudimentary, it works. We update two vectors at a time, increasing their separation until they are no longer the closest, then shifting focus to the next closest pair. The key takeaway is that <em>it works</em>. TensorFlow successfully backpropagates gradients through <code>tf.reduce_min()</code> and <code>tf.acos()</code> to achieve the desired outcome.</p><p>Let&rsquo;s introduce some complexity. Ideally, all vectors should have equal angles to their nearest neighbors at the optimal solution. So, we incorporate the &ldquo;variance of minimum angles&rdquo; into the loss function.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>VectorSpread_MaxMinAngle_w_Variance</span><span class=p>(</span><span class=n>VectorSpreadAlgorithm</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>spread_metric</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>tensor2d</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34; Assumes all rows already normalized &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>angle_pairs</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>acos</span><span class=p>(</span><span class=n>tensor2d</span> <span class=o>@</span> <span class=n>tf</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=n>tensor2d</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>disable_diag</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>eye</span><span class=p>(</span><span class=n>tensor2d</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span> <span class=o>*</span> <span class=mi>2</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>pi</span>
</span></span><span class=line><span class=cl>        <span class=n>all_mins</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>reduce_min</span><span class=p>(</span><span class=n>angle_pairs</span> <span class=o>+</span> <span class=n>disable_diag</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>    
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># Same calculation as before: find the min-min angle</span>
</span></span><span class=line><span class=cl>        <span class=n>min_min</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>reduce_min</span><span class=p>(</span><span class=n>all_mins</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># But now also calculate the variance of the min angles vector</span>
</span></span><span class=line><span class=cl>        <span class=n>avg_min</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>reduce_mean</span><span class=p>(</span><span class=n>all_mins</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>var_min</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>reduce_sum</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>square</span><span class=p>(</span><span class=n>all_mins</span> <span class=o>-</span> <span class=n>avg_min</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># Our spread metric now includes a term to minimize variance</span>
</span></span><span class=line><span class=cl>        <span class=n>spread_metric</span> <span class=o>=</span> <span class=n>min_min</span> <span class=o>-</span> <span class=mf>0.4</span> <span class=o>*</span> <span class=n>var_min</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># As before, want negative spread to keep it a minimization problem</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=o>-</span><span class=n>spread_metric</span>
</span></span></code></pre></td></tr></table></div></div><div data-testid=image-container class="X3Bg-O9c _1xIzGpI7"><figure class=_1sK7TguO><img alt="An animation going from the initial state to the target state. The lone spoke does not stay fixed, quickly moving around toward the rest of the spokes in the semi-circle; instead of closing two gaps either side the lone spoke, the jittering now closes one large gap over time. Equidistance is here also not quite achieved after 1,200 iterations." src=https://bs-uploads.toptal.io/blackfish-uploads/uploaded_file/file/238288/image-1587548990046-0fdf8665f93ca8981d6ebe96e814bdc9.gif loading=lazy decoding=async class=Djd3YO_2></figure></div><p>Now, the outlier vector quickly joins the cluster, as its large angle with its closest neighbor significantly increases the minimized variance. However, the globally-minimum angle still drives the process, albeit slowly. While improvements are possible in this 2D case, they might not generalize to higher dimensions.</p><p>The main point lies in the intricate tensor operations within the mean and variance calculations, and TensorFlow&rsquo;s ability to track and differentiate each computation for every component in the input matrix without manual calculus.</p><p>Finally, let&rsquo;s explore a force-based approach. Imagine each vector as a planet tethered to a central point, repelling each other. A physics simulation should lead us to our desired state.</p><p>My hypothesis is that gradient descent should also work. At the optimal solution, the net force on each planet from others should be zero (otherwise, they&rsquo;d move). We can calculate the magnitude of force on each vector and use gradient descent to minimize it.</p><p>First, we define the force calculation method using <code>tf.*</code> methods:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>VectorSpread_Force</span><span class=p>(</span><span class=n>VectorSpreadAlgorithm</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>force_a_onto_b</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>vec_a</span><span class=p>,</span> <span class=n>vec_b</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># Calc force assuming vec_b is constrained to the unit sphere</span>
</span></span><span class=line><span class=cl>        <span class=n>diff</span> <span class=o>=</span> <span class=n>vec_b</span> <span class=o>-</span> <span class=n>vec_a</span>
</span></span><span class=line><span class=cl>        <span class=n>norm</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>reduce_sum</span><span class=p>(</span><span class=n>diff</span><span class=o>**</span><span class=mi>2</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>unit_force_dir</span> <span class=o>=</span> <span class=n>diff</span> <span class=o>/</span> <span class=n>norm</span>
</span></span><span class=line><span class=cl>        <span class=n>force_magnitude</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>/</span> <span class=n>norm</span><span class=o>**</span><span class=mi>2</span>
</span></span><span class=line><span class=cl>        <span class=n>force_vec</span> <span class=o>=</span> <span class=n>unit_force_dir</span> <span class=o>*</span> <span class=n>force_magnitude</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Project force onto this vec, calculate how much is radial</span>
</span></span><span class=line><span class=cl>        <span class=n>b_dot_f</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>tensordot</span><span class=p>(</span><span class=n>vec_b</span><span class=p>,</span> <span class=n>force_vec</span><span class=p>,</span> <span class=n>axes</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>b_dot_b</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>tensordot</span><span class=p>(</span><span class=n>vec_b</span><span class=p>,</span> <span class=n>vec_b</span><span class=p>,</span> <span class=n>axes</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>radial_component</span> <span class=o>=</span>  <span class=p>(</span><span class=n>b_dot_f</span> <span class=o>/</span> <span class=n>b_dot_b</span><span class=p>)</span> <span class=o>*</span> <span class=n>vec_b</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Subtract radial component and return result</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>force_vec</span> <span class=o>-</span> <span class=n>radial_component</span>
</span></span></code></pre></td></tr></table></div></div><p>Next, we define the loss function using the force function, accumulating the net force on each vector and calculating its magnitude. At the optimum, all forces should cancel out, resulting in zero net force.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>calc_loss</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>tensor2d</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>n_vec</span> <span class=o>=</span> <span class=n>tensor2d</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>all_force_list</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>this_idx</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_vec</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Accumulate force of all other vecs onto this one</span>
</span></span><span class=line><span class=cl>        <span class=n>this_force_list</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>other_idx</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_vec</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>this_idx</span> <span class=o>==</span> <span class=n>other_idx</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=k>continue</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>this_vec</span> <span class=o>=</span> <span class=n>tensor2d</span><span class=p>[</span><span class=n>this_idx</span><span class=p>,</span> <span class=p>:]</span>
</span></span><span class=line><span class=cl>            <span class=n>other_vec</span> <span class=o>=</span> <span class=n>tensor2d</span><span class=p>[</span><span class=n>other_idx</span><span class=p>,</span> <span class=p>:]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>tangent_force_vec</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>force_a_onto_b</span><span class=p>(</span><span class=n>other_vec</span><span class=p>,</span> <span class=n>this_vec</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>this_force_list</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>tangent_force_vec</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Use list of all N-dimensional force vecs. Stack and sum.</span>
</span></span><span class=line><span class=cl>        <span class=n>sum_tangent_forces</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>reduce_sum</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>stack</span><span class=p>(</span><span class=n>this_force_list</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>this_force_mag</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>reduce_sum</span><span class=p>(</span><span class=n>sum_tangent_forces</span><span class=o>**</span><span class=mi>2</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Accumulate all magnitudes, should all be zero at optimal solution</span>
</span></span><span class=line><span class=cl>        <span class=n>all_force_list</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>this_force_mag</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># We want to minimize total force sum, so simply stack, sum, return</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>tf</span><span class=o>.</span><span class=n>reduce_sum</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>stack</span><span class=p>(</span><span class=n>all_force_list</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><div data-testid=image-container class="X3Bg-O9c _1xIzGpI7"><figure class=_1sK7TguO><img alt="An animation going from the initial state to the target state. The first few frames see rapid movement in all spokes, and after only 200 iterations or so, the overall picture is already fairly close to the target. Only 700 iterations are shown in total; after the 300th, angles are changing only minutely with each frame." src=https://bs-uploads.toptal.io/blackfish-uploads/uploaded_file/file/238286/image-1587548990047-7d8c53e803c57a32dbc254a2e14ec126.gif loading=lazy decoding=async class=Djd3YO_2></figure></div><p>Not only does the solution work remarkably well (aside from initial chaos), but the credit goes to TensorFlow. It successfully traced gradients through numerous <code>for</code> loops, an <code>if</code> statement, and a complex web of calculations.</p><h2 id=example-3-creating-adversarial-ai-inputs>Example 3: Creating Adversarial AI Inputs</h2><p><a class=link href=https://github.com/etotheipi/toptal_tensorflow_blog_post/blob/dev/adversarial_example/adversarial_cats_dogs.ipynb target=_blank rel=noopener>Example 3 Notebook</a></p><div class=blog-body-sidenote><p>At this point, readers may be thinking, "Hey! This post wasn't supposed to be about deep learning!" But technically, the introduction refers to going beyond "<i>training</i> deep learning models." In this case, we're not <i>training</i>, but instead exploiting some mathematical properties of a pre-trained deep neural-network to fool it into giving us the wrong results. This turned out to be far easier and more effective than imagined. And all it took was another short blob of TensorFlow 2.0 code.</p></div><p>We begin by selecting an image classifier to target. Our choice is one of the top solutions from the <a class=link href=https://www.kaggle.com/c/dogs-vs-cats target=_blank rel=noopener>Dogs vs. Cats Kaggle Competition</a>, specifically, <a class=link href=https://www.kaggle.com/uysimty/keras-cnn-dog-or-cat-classification target=_blank rel=noopener>the solution</a> by Kaggler &ldquo;uysimty.&rdquo; Kudos to them for the effective cat-vs-dog model and comprehensive documentation. This robust model boasts 13 million parameters across 18 neural network layers (further details in the corresponding notebook).</p><p>Note that our aim isn&rsquo;t to expose flaws in this specific network, but rather to demonstrate the vulnerability of <strong>any standard neural network with numerous inputs</strong>.</p><p>After some adjustments, we successfully loaded the model and implemented the necessary image pre-processing.</p><div data-testid=image-container class="X3Bg-O9c _1xIzGpI7"><figure class=_1sK7TguO><picture class=!contents data-testid=picture><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238284%2Fimage-1587548990048-417c7b476f36d6000b0e81e94ba7a899.png&amp;width=360, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238284%2Fimage-1587548990048-417c7b476f36d6000b0e81e94ba7a899.png&amp;width=360&amp;dpr=2 2x" media="(max-width: 360px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238284%2Fimage-1587548990048-417c7b476f36d6000b0e81e94ba7a899.png&amp;width=480, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238284%2Fimage-1587548990048-417c7b476f36d6000b0e81e94ba7a899.png&amp;width=480&amp;dpr=2 2x" media="(min-width: 360.1px) and (max-width: 480px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238284%2Fimage-1587548990048-417c7b476f36d6000b0e81e94ba7a899.png&amp;width=768, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238284%2Fimage-1587548990048-417c7b476f36d6000b0e81e94ba7a899.png&amp;width=768&amp;dpr=2 2x" media="(min-width: 480.1px) and (max-width: 768px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238284%2Fimage-1587548990048-417c7b476f36d6000b0e81e94ba7a899.png&amp;width=1024, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238284%2Fimage-1587548990048-417c7b476f36d6000b0e81e94ba7a899.png&amp;width=1024&amp;dpr=2 2x" media="(min-width: 768.1px) and (max-width: 1024px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238284%2Fimage-1587548990048-417c7b476f36d6000b0e81e94ba7a899.png&amp;width=1440, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238284%2Fimage-1587548990048-417c7b476f36d6000b0e81e94ba7a899.png&amp;width=1440&amp;dpr=2 2x" media="(min-width: 1024.1px) and (max-width: 1440px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238284%2Fimage-1587548990048-417c7b476f36d6000b0e81e94ba7a899.png&amp;width=1920, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238284%2Fimage-1587548990048-417c7b476f36d6000b0e81e94ba7a899.png&amp;width=1920&amp;dpr=2 2x" media="(min-width: 1440.1px) and (max-width: 1920px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238284%2Fimage-1587548990048-417c7b476f36d6000b0e81e94ba7a899.png" media="(min-width: 1920.1px)"><img alt="Five sample images, each of a dog or a cat, with a corresponding classification and confidence level. Confidence levels shown range from 95 percent to 100 percent." src="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238284%2Fimage-1587548990048-417c7b476f36d6000b0e81e94ba7a899.png" loading=lazy decoding=async class=Djd3YO_2></picture></figure></div><p>The classifier appears quite reliable, with all sample classifications accurate and exceeding 95% confidence. Let&rsquo;s attempt an attack!</p><p>Our objective is to create an image that&rsquo;s clearly a cat but misclassified as a dog with high confidence. How do we achieve this?</p><p>Starting with a correctly classified cat image, we analyze how minute modifications in each color channel (values 0-255) of a pixel affect the classifier&rsquo;s output. While tweaking one pixel might have a negligible impact, the cumulative effect of adjusting all 128x128x3 = 49,152 pixel values might yield the desired outcome.</p><p>But how do we determine the direction of these pixel adjustments? In standard neural network training, we minimize the loss between target and predicted labels, utilizing gradient descent in TensorFlow to update all 13 million parameters. Here, we&rsquo;ll keep those parameters constant and instead adjust the input pixel values.</p><p>Our loss function? The &ldquo;cat-ness&rdquo; of the image! By calculating the derivative of the cat probability with respect to each pixel, we discover how to minimize the cat classification.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>adversarial_modify</span><span class=p>(</span><span class=n>victim_img</span><span class=p>,</span> <span class=n>to_dog</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>to_cat</span><span class=o>=</span><span class=kc>False</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># We only need four gradient descent steps</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>4</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>tf_victim_img</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>convert_to_tensor</span><span class=p>(</span><span class=n>victim_img</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=s1>&#39;float32&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>tf</span><span class=o>.</span><span class=n>GradientTape</span><span class=p>()</span> <span class=k>as</span> <span class=n>tape</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>tape</span><span class=o>.</span><span class=n>watch</span><span class=p>(</span><span class=n>tf_victim_img</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># Run the image through the model</span>
</span></span><span class=line><span class=cl>            <span class=n>model_output</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>tf_victim_img</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># Minimize cat confidence and maximize dog confidence </span>
</span></span><span class=line><span class=cl>            <span class=n>loss</span> <span class=o>=</span> <span class=p>(</span><span class=n>model_output</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>-</span> <span class=n>model_output</span><span class=p>[</span><span class=mi>1</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>dloss_dimg</span> <span class=o>=</span> <span class=n>tape</span><span class=o>.</span><span class=n>gradient</span><span class=p>(</span><span class=n>loss</span><span class=p>,</span> <span class=n>tf_victim_img</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Ignore gradient magnitudes, only care about sign, +1/255 or -1/255</span>
</span></span><span class=line><span class=cl>        <span class=n>pixels_w_pos_grad</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>cast</span><span class=p>(</span><span class=n>dloss_dimg</span> <span class=o>&gt;</span> <span class=mf>0.0</span><span class=p>,</span> <span class=s1>&#39;float32&#39;</span><span class=p>)</span> <span class=o>/</span> <span class=mf>255.</span>
</span></span><span class=line><span class=cl>        <span class=n>pixels_w_neg_grad</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>cast</span><span class=p>(</span><span class=n>dloss_dimg</span> <span class=o>&lt;</span> <span class=mf>0.0</span><span class=p>,</span> <span class=s1>&#39;float32&#39;</span><span class=p>)</span> <span class=o>/</span> <span class=mf>255.</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>victim_img</span> <span class=o>=</span> <span class=n>victim_img</span> <span class=o>-</span> <span class=n>pixels_w_pos_grad</span> <span class=o>+</span> <span class=n>pixels_w_neg_grad</span>
</span></span></code></pre></td></tr></table></div></div><p>Once again, Matplotlib aids in visualizing the results.</p><div data-testid=image-container class="X3Bg-O9c _1xIzGpI7"><figure class=_1sK7TguO><picture class=!contents data-testid=picture><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238280%2Fimage-1587548990049-4025f26114f77d022f4d73613a706c76.png&amp;width=360, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238280%2Fimage-1587548990049-4025f26114f77d022f4d73613a706c76.png&amp;width=360&amp;dpr=2 2x" media="(max-width: 360px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238280%2Fimage-1587548990049-4025f26114f77d022f4d73613a706c76.png&amp;width=480, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238280%2Fimage-1587548990049-4025f26114f77d022f4d73613a706c76.png&amp;width=480&amp;dpr=2 2x" media="(min-width: 360.1px) and (max-width: 480px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238280%2Fimage-1587548990049-4025f26114f77d022f4d73613a706c76.png&amp;width=768, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238280%2Fimage-1587548990049-4025f26114f77d022f4d73613a706c76.png&amp;width=768&amp;dpr=2 2x" media="(min-width: 480.1px) and (max-width: 768px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238280%2Fimage-1587548990049-4025f26114f77d022f4d73613a706c76.png&amp;width=1024, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238280%2Fimage-1587548990049-4025f26114f77d022f4d73613a706c76.png&amp;width=1024&amp;dpr=2 2x" media="(min-width: 768.1px) and (max-width: 1024px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238280%2Fimage-1587548990049-4025f26114f77d022f4d73613a706c76.png&amp;width=1440, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238280%2Fimage-1587548990049-4025f26114f77d022f4d73613a706c76.png&amp;width=1440&amp;dpr=2 2x" media="(min-width: 1024.1px) and (max-width: 1440px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238280%2Fimage-1587548990049-4025f26114f77d022f4d73613a706c76.png&amp;width=1920, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238280%2Fimage-1587548990049-4025f26114f77d022f4d73613a706c76.png&amp;width=1920&amp;dpr=2 2x" media="(min-width: 1440.1px) and (max-width: 1920px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238280%2Fimage-1587548990049-4025f26114f77d022f4d73613a706c76.png" media="(min-width: 1920.1px)"><img alt='An original sample cat image along with 4 iterations, with classifications, "Cat 99.0%," "Cat 67.3%," "Dog 71.7%," "Dog 94.3%," and "Dog 99.4%," respectively.' src="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238280%2Fimage-1587548990049-4025f26114f77d022f4d73613a706c76.png" loading=lazy decoding=async class=Djd3YO_2></picture></figure></div><p>Remarkably, despite appearing identical to the human eye, the images after four iterations successfully fool the classifier into predicting a dog with 99.4% confidence!</p><p>Let&rsquo;s confirm this isn&rsquo;t a fluke by reversing the process.</p><div data-testid=image-container class="X3Bg-O9c _1xIzGpI7"><figure class=_1sK7TguO><picture class=!contents data-testid=picture><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238282%2Fimage-1587548990051-0d895fbec9da1156c3c1b54732f66e83.png&amp;width=360, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238282%2Fimage-1587548990051-0d895fbec9da1156c3c1b54732f66e83.png&amp;width=360&amp;dpr=2 2x" media="(max-width: 360px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238282%2Fimage-1587548990051-0d895fbec9da1156c3c1b54732f66e83.png&amp;width=480, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238282%2Fimage-1587548990051-0d895fbec9da1156c3c1b54732f66e83.png&amp;width=480&amp;dpr=2 2x" media="(min-width: 360.1px) and (max-width: 480px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238282%2Fimage-1587548990051-0d895fbec9da1156c3c1b54732f66e83.png&amp;width=768, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238282%2Fimage-1587548990051-0d895fbec9da1156c3c1b54732f66e83.png&amp;width=768&amp;dpr=2 2x" media="(min-width: 480.1px) and (max-width: 768px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238282%2Fimage-1587548990051-0d895fbec9da1156c3c1b54732f66e83.png&amp;width=1024, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238282%2Fimage-1587548990051-0d895fbec9da1156c3c1b54732f66e83.png&amp;width=1024&amp;dpr=2 2x" media="(min-width: 768.1px) and (max-width: 1024px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238282%2Fimage-1587548990051-0d895fbec9da1156c3c1b54732f66e83.png&amp;width=1440, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238282%2Fimage-1587548990051-0d895fbec9da1156c3c1b54732f66e83.png&amp;width=1440&amp;dpr=2 2x" media="(min-width: 1024.1px) and (max-width: 1440px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238282%2Fimage-1587548990051-0d895fbec9da1156c3c1b54732f66e83.png&amp;width=1920, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238282%2Fimage-1587548990051-0d895fbec9da1156c3c1b54732f66e83.png&amp;width=1920&amp;dpr=2 2x" media="(min-width: 1440.1px) and (max-width: 1920px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238282%2Fimage-1587548990051-0d895fbec9da1156c3c1b54732f66e83.png" media="(min-width: 1920.1px)"><img alt='An original sample dog image along with 4 iterations, with classifications, "Dog 98.4%," "Dog 83.9%," "Dog 54.6%," "Cat 90.4%," and "Cat 99.8%," respectively. As before, the differences are invisible to the naked eye.' src="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238282%2Fimage-1587548990051-0d895fbec9da1156c3c1b54732f66e83.png" loading=lazy decoding=async class=Djd3YO_2></picture></figure></div><p>Success! The initially correctly classified dog (98.4% confidence) is now recognized as a cat with 99.8% confidence.</p><p>Finally, let&rsquo;s examine the changes in a sample image patch.</p><div data-testid=image-container class="X3Bg-O9c _1xIzGpI7"><figure class=_1sK7TguO><picture class=!contents data-testid=picture><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238277%2Fimage-1587548990052-27b4881a6dd494d74458543e7a2cd734.png&amp;width=360, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238277%2Fimage-1587548990052-27b4881a6dd494d74458543e7a2cd734.png&amp;width=360&amp;dpr=2 2x" media="(max-width: 360px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238277%2Fimage-1587548990052-27b4881a6dd494d74458543e7a2cd734.png&amp;width=480, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238277%2Fimage-1587548990052-27b4881a6dd494d74458543e7a2cd734.png&amp;width=480&amp;dpr=2 2x" media="(min-width: 360.1px) and (max-width: 480px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238277%2Fimage-1587548990052-27b4881a6dd494d74458543e7a2cd734.png&amp;width=768, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238277%2Fimage-1587548990052-27b4881a6dd494d74458543e7a2cd734.png&amp;width=768&amp;dpr=2 2x" media="(min-width: 480.1px) and (max-width: 768px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238277%2Fimage-1587548990052-27b4881a6dd494d74458543e7a2cd734.png&amp;width=1024, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238277%2Fimage-1587548990052-27b4881a6dd494d74458543e7a2cd734.png&amp;width=1024&amp;dpr=2 2x" media="(min-width: 768.1px) and (max-width: 1024px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238277%2Fimage-1587548990052-27b4881a6dd494d74458543e7a2cd734.png&amp;width=1440, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238277%2Fimage-1587548990052-27b4881a6dd494d74458543e7a2cd734.png&amp;width=1440&amp;dpr=2 2x" media="(min-width: 1024.1px) and (max-width: 1440px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238277%2Fimage-1587548990052-27b4881a6dd494d74458543e7a2cd734.png&amp;width=1920, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238277%2Fimage-1587548990052-27b4881a6dd494d74458543e7a2cd734.png&amp;width=1920&amp;dpr=2 2x" media="(min-width: 1440.1px) and (max-width: 1920px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238277%2Fimage-1587548990052-27b4881a6dd494d74458543e7a2cd734.png" media="(min-width: 1920.1px)"><img alt='Three grids of pixel rows and columns, showing numeric values for the red channel of each pixel. The left image patch shows mostly bluish squares, highlighting values of 218 or below, with some red squares (219 and above) clustered in the lower-right corner. The middle, "victimized" image page, shows a very similarly colored and numbered layout. The right-hand image patch shows the numerical difference between the other two, with differences ranging only from -4 to +4, and including several zeroes.' src="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F238277%2Fimage-1587548990052-27b4881a6dd494d74458543e7a2cd734.png" loading=lazy decoding=async class=Djd3YO_2></picture></figure></div><p>As anticipated, the final patch closely resembles the original, with each pixel&rsquo;s red channel intensity shifting by -4 to +4. This subtle shift, imperceptible to humans, drastically alters the classifier&rsquo;s output.</p><h2 id=concluding-thoughts-gradient-descent-optimization>Concluding Thoughts: Gradient Descent Optimization</h2><p>For simplicity, we manually applied gradients to trainable parameters. However, in practice, data scientists should leverage <em>optimizers</em> for their superior effectiveness.</p><p>Popular options include RMSprop, Adagrad, and Adadelta, with <em>Adam</em> being arguably the most prevalent. These &ldquo;adaptive learning rate methods&rdquo; dynamically adjust learning rates for each parameter, often incorporating momentum terms and approximating higher-order derivatives to escape local minima and accelerate convergence.</p><p>An animation from Sebastian Ruder illustrates various optimizers navigating a loss surface. Our manual techniques resemble &ldquo;SGD,&rdquo; highlighting the improved performance of advanced optimizers in most scenarios.</p><div data-testid=image-container class="X3Bg-O9c _1xIzGpI7"><figure class=_1sK7TguO><img alt="An animated contour map, showing the path taken by six different methods to converge on a target point. SGD is by far the slowest, taking a steady curve from its starting point. Momentum initially goes away from the target, then criss-crosses its own path twice before heading toward it not entirely directly, and seeming to overshoot it and then backtrack. NAG is similar, but doesn't stray quite as far from the target and criss-crosses itself only once, generally reaching the target faster and overshooting it less. Adagrad starts off in a straight line that's the most off-course, but very quickly does a hair-pin turn toward the hill the target is on, and curving toward it faster than the first three. Adadelta has a similar path, but with a smoother curve; it overtakes Adagrad and stays ahead of it after the first second or so. Finally, Rmsprop follows a very similar path to Adadelta, but leans slightly closer to the target early on; notably, its course is much more steady, making it lag behind Adagrad and Adadelta for most of the animation; unlike the other five, it seems to have two sudden, rapid jumps in two different directions near the end of the animation before ceasing movement, while the others, in the last moment, continue to slowly creep along by the target. " src=https://bs-uploads.toptal.io/blackfish-uploads/uploaded_file/file/238289/image-1587548990053-5d5166a3d3712e7c03af74b1ccacbeac.gif loading=lazy decoding=async class=Djd3YO_2></figure></div><p>However, deep expertise in optimizers isn&rsquo;t always necessary, even for those involved in artificial intelligence development services. Familiarization with a few key optimizers suffices to understand their role in enhancing TensorFlow&rsquo;s gradient descent. In most cases, starting with <em>Adam</em> and experimenting with alternatives only when models struggle to converge is a pragmatic approach.</p><p>For those interested in the intricacies of optimizer functionality, <a class=link href=https://ruder.io/optimizing-gradient-descent/ target=_blank rel=noopener>Ruder’s overview</a> (source of the animation) offers a comprehensive resource.</p><p>Let&rsquo;s enhance our linear regression solution from earlier by incorporating optimizers. Here&rsquo;s the original manual gradient descent code:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Manual gradient descent operations</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>run_gradient_descent</span><span class=p>(</span><span class=n>heights</span><span class=p>,</span> <span class=n>weights</span><span class=p>,</span> <span class=n>init_slope</span><span class=p>,</span> <span class=n>init_icept</span><span class=p>,</span> <span class=n>learning_rate</span><span class=p>):</span>
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl>    <span class=n>tf_slope</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>Variable</span><span class=p>(</span><span class=n>init_slope</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=s1>&#39;float32&#39;</span><span class=p>)</span> 
</span></span><span class=line><span class=cl>    <span class=n>tf_icept</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>Variable</span><span class=p>(</span><span class=n>init_icept</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=s1>&#39;float32&#39;</span><span class=p>)</span> 
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>25</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>tf</span><span class=o>.</span><span class=n>GradientTape</span><span class=p>()</span> <span class=k>as</span> <span class=n>tape</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>tape</span><span class=o>.</span><span class=n>watch</span><span class=p>((</span><span class=n>tf_slope</span><span class=p>,</span> <span class=n>tf_icept</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=n>predictions</span> <span class=o>=</span> <span class=n>tf_slope</span> <span class=o>*</span> <span class=n>heights</span> <span class=o>+</span> <span class=n>tf_icept</span>
</span></span><span class=line><span class=cl>            <span class=n>errors</span> <span class=o>=</span> <span class=n>predictions</span> <span class=o>-</span> <span class=n>weights</span>
</span></span><span class=line><span class=cl>            <span class=n>loss</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>reduce_mean</span><span class=p>(</span><span class=n>errors</span><span class=o>**</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>gradients</span> <span class=o>=</span> <span class=n>tape</span><span class=o>.</span><span class=n>gradient</span><span class=p>(</span><span class=n>loss</span><span class=p>,</span> <span class=p>[</span><span class=n>tf_slope</span><span class=p>,</span> <span class=n>tf_icept</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=n>tf_slope</span> <span class=o>=</span> <span class=n>tf_slope</span> <span class=o>-</span> <span class=n>learning_rate</span> <span class=o>*</span> <span class=n>gradients</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>tf_icept</span> <span class=o>=</span> <span class=n>tf_icept</span> <span class=o>-</span> <span class=n>learning_rate</span> <span class=o>*</span> <span class=n>gradients</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span>
</span></span></code></pre></td></tr></table></div></div><p>Now, the same code using an optimizer (changes highlighted in blue):</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl># Gradient descent with Optimizer (RMSprop)
</span></span><span class=line><span class=cl>    def run_gradient_descent(heights, weights, init_slope, init_icept, learning_rate):
</span></span><span class=line><span class=cl>     
</span></span><span class=line><span class=cl>        tf_slope = tf.Variable(init_slope, dtype=&#39;float32&#39;) 
</span></span><span class=line><span class=cl>        tf_icept = tf.Variable(init_icept, dtype=&#39;float32&#39;)
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>        # Group trainable parameters into a list
</span></span><span class=line><span class=cl>        trainable_params = [tf_slope, tf_icept]
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>        # Define your optimizer (RMSprop) outside of the training loop
</span></span><span class=line><span class=cl>        optimizer = keras.optimizers.RMSprop(learning_rate)
</span></span><span class=line><span class=cl>       
</span></span><span class=line><span class=cl>        for i in range(25):
</span></span><span class=line><span class=cl>            # GradientTape loop is the same
</span></span><span class=line><span class=cl>            with tf.GradientTape() as tape:
</span></span><span class=line><span class=cl>                tape.watch(trainable_params)
</span></span><span class=line><span class=cl>                predictions = tf_slope * heights + tf_icept
</span></span><span class=line><span class=cl>                errors = predictions - weights
</span></span><span class=line><span class=cl>                loss = tf.reduce_mean(errors**2)
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>            # We can use the trainable parameters list directly in gradient calcs
</span></span><span class=line><span class=cl>            gradients = tape.gradient(loss, trainable_params)
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>            # Optimizers always aim to *minimize* the loss function
</span></span><span class=line><span class=cl>            optimizer.apply_gradients(zip(gradients, trainable_params))
</span></span></code></pre></td></tr></table></div></div><p>We define an <code>RMSprop</code> optimizer outside the loop and use <code>optimizer.apply_gradients()</code> after each gradient calculation to update parameters. The optimizer, residing outside the loop, tracks historical gradients for momentum and higher-order derivative calculations.</p><p>Let&rsquo;s observe the outcome with the <strong><em>RMSprop</em></strong> optimizer.</p><div data-testid=image-container class="X3Bg-O9c _1xIzGpI7"><figure class=_1sK7TguO><img alt="Similar to the previous synchronized pairs of animations; the fitted line starts above its resting place. The loss graph shows it nearly converging after a mere five iterations." src=https://bs-uploads.toptal.io/blackfish-uploads/uploaded_file/file/238281/image-1587548990054-dfa7c7292bf568e7d9f1221b82f212b0.gif loading=lazy decoding=async class=Djd3YO_2></figure></div><p>Excellent! Now, let&rsquo;s try the <strong><em>Adam</em></strong> optimizer.</p><div data-testid=image-container class="X3Bg-O9c _1xIzGpI7"><figure class=_1sK7TguO><img alt="Another synchronized scatterplot and corresponding loss graph animation. The loss graph stands out from the others in that it doesn' strictly continue to get closer to the minimum; instead, it resembles the path of a bouncing ball. The corresponding fitted line on the scatterplot starts above the sample points, swings toward the bottom of them, then back up but not as high, and so on, with each change of direction being closer to a central position." src=https://bs-uploads.toptal.io/blackfish-uploads/uploaded_file/file/238285/image-1587548990055-8f4dbcd1f586940605a5aefa76d00577.gif loading=lazy decoding=async class=Djd3YO_2></figure></div><p>Interestingly, Adam&rsquo;s momentum mechanics cause it to overshoot and oscillate around the optimum. While beneficial for complex loss surfaces, it hinders us here. This emphasizes the importance of tuning the optimizer as a hyperparameter.</p><p>This pattern, widely used in custom TensorFlow architectures with complex loss functions, is crucial for deep learning practitioners. While our example involved only two parameters, it underscores the necessity of optimizers when dealing with millions.</p><h2 id=tensorflows-gradient-descent-from-minimums-to-ai-system-attacks>TensorFlow&rsquo;s Gradient Descent: From Minimums to AI System Attacks</h2><p>All code snippets and images originate from notebooks in <a class=link href=https://github.com/etotheipi/toptal_tensorflow_blog_post target=_blank rel=noopener>the corresponding GitHub repo</a>, which also includes a summarized overview with links to individual notebooks for complete code access. For clarity, certain details were omitted but can be found in the inline documentation.</p><p>I hope this article provided valuable insights into leveraging gradient descent in TensorFlow. Even without direct application, it should offer a clearer understanding of modern neural network architectures: define a model, define a loss function, and employ gradient descent (often through optimizers) to fit the model to your data.</p><hr><div data-testid=image-container class="X3Bg-O9c _1xIzGpI7"><figure class=_1sK7TguO><picture class=!contents data-testid=picture><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F191403%2Fimage-1582293344445-6f83e95c27a1bdfb920f04babb33d565.png&amp;width=360, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F191403%2Fimage-1582293344445-6f83e95c27a1bdfb920f04babb33d565.png&amp;width=360&amp;dpr=2 2x" media="(max-width: 360px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F191403%2Fimage-1582293344445-6f83e95c27a1bdfb920f04babb33d565.png&amp;width=480, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F191403%2Fimage-1582293344445-6f83e95c27a1bdfb920f04babb33d565.png&amp;width=480&amp;dpr=2 2x" media="(min-width: 360.1px) and (max-width: 480px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F191403%2Fimage-1582293344445-6f83e95c27a1bdfb920f04babb33d565.png&amp;width=768, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F191403%2Fimage-1582293344445-6f83e95c27a1bdfb920f04babb33d565.png&amp;width=768&amp;dpr=2 2x" media="(min-width: 480.1px) and (max-width: 768px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F191403%2Fimage-1582293344445-6f83e95c27a1bdfb920f04babb33d565.png&amp;width=1024, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F191403%2Fimage-1582293344445-6f83e95c27a1bdfb920f04babb33d565.png&amp;width=1024&amp;dpr=2 2x" media="(min-width: 768.1px) and (max-width: 1024px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F191403%2Fimage-1582293344445-6f83e95c27a1bdfb920f04babb33d565.png&amp;width=1440, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F191403%2Fimage-1582293344445-6f83e95c27a1bdfb920f04babb33d565.png&amp;width=1440&amp;dpr=2 2x" media="(min-width: 1024.1px) and (max-width: 1440px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F191403%2Fimage-1582293344445-6f83e95c27a1bdfb920f04babb33d565.png&amp;width=1920, https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F191403%2Fimage-1582293344445-6f83e95c27a1bdfb920f04babb33d565.png&amp;width=1920&amp;dpr=2 2x" media="(min-width: 1440.1px) and (max-width: 1920px)"><source srcset="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F191403%2Fimage-1582293344445-6f83e95c27a1bdfb920f04babb33d565.png" media="(min-width: 1920.1px)"><img alt="Google Cloud Partner badge." src="https://assets.toptal.io/images?url=https%3A%2F%2Fbs-uploads.toptal.io%2Fblackfish-uploads%2Fuploaded_file%2Ffile%2F191403%2Fimage-1582293344445-6f83e95c27a1bdfb920f04babb33d565.png" loading=lazy decoding=async class=Djd3YO_2></picture></figure></div><p>Toptal, a Google Cloud Partner, offers on-demand access to Google-certified experts for critical projects.</p></section><footer class=article-footer><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section></footer></article><footer class=site-footer><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3987358164777632" crossorigin=anonymous></script><script>(function(e,t,n,s,o){e[s]=e[s]||[],e[s].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var a=t.getElementsByTagName(n)[0],i=t.createElement(n),r=s!="dataLayer"?"&l="+s:"";i.async=!0,i.src="https://www.googletagmanager.com/gtm.js?id="+o+r,a.parentNode.insertBefore(i,a)})(window,document,"script","dataLayer","GTM-5X67X4Q4")</script><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5X67X4Q4" height=0 width=0 style=display:none;visibility:hidden></iframe></noscript></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>