<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Key Takeaways Near the close of 2018, Amazon amped up an already-increasing interest level in the marrying of container and hypervisor technology by announcing Firecracker, a Rust-based Virtual Machine Monitor Around the midpoint of this year, Weaveworks introduced a new project, Ignite, which wraps Amazon‚Äôs Firecracker project with a container-lifecycle UI experience. One clear use case for this new marriage of hypervisor technology and containers is to add a layer of protection and isolation to potentially sensitive (or untrusted) workloads."><title>Containers in 2019: They're Calling It a Hypervisor Comeback</title><link rel=canonical href=https://Nexus-Security.github.io/posts/2016-09-09-containers-in-2019-they-calling-it/><link rel=stylesheet href=/scss/style.min.450926226e724574a6b936335ea06111f8aeb253d932c86cb2cc807341cd2889.css><meta property="og:title" content="Containers in 2019: They're Calling It a Hypervisor Comeback"><meta property="og:description" content="Key Takeaways Near the close of 2018, Amazon amped up an already-increasing interest level in the marrying of container and hypervisor technology by announcing Firecracker, a Rust-based Virtual Machine Monitor Around the midpoint of this year, Weaveworks introduced a new project, Ignite, which wraps Amazon‚Äôs Firecracker project with a container-lifecycle UI experience. One clear use case for this new marriage of hypervisor technology and containers is to add a layer of protection and isolation to potentially sensitive (or untrusted) workloads."><meta property="og:url" content="https://Nexus-Security.github.io/posts/2016-09-09-containers-in-2019-they-calling-it/"><meta property="og:site_name" content="ZYChimne"><meta property="og:type" content="article"><meta property="article:section" content="Posts"><meta property="article:published_time" content="2019-10-26T08:47:00+01:00"><meta property="article:modified_time" content="2019-10-26T08:47:00+01:00"><meta name=twitter:title content="Containers in 2019: They're Calling It a Hypervisor Comeback"><meta name=twitter:description content="Key Takeaways Near the close of 2018, Amazon amped up an already-increasing interest level in the marrying of container and hypervisor technology by announcing Firecracker, a Rust-based Virtual Machine Monitor Around the midpoint of this year, Weaveworks introduced a new project, Ignite, which wraps Amazon‚Äôs Firecracker project with a container-lifecycle UI experience. One clear use case for this new marriage of hypervisor technology and containers is to add a layer of protection and isolation to potentially sensitive (or untrusted) workloads."></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu8b78332b6420dc9affabe23720d11e63_1937019_300x0_resize_q75_box.jpg width=300 height=300 class=site-logo loading=lazy alt=Avatar></a>
<span class=emoji>üçá</span></figure><div class=site-meta><h1 class=site-name><a href=/>ZYChimne</a></h1><h2 class=site-description>Computer Science, Wuhan University</h2></div></header><ol class=social-menu><li><a href=https://github.com/ZYChimne target=_blank title=GitHub><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=https://twitter.com/ZChimne target=_blank title=Twitter><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-twitter" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M22 4.01c-1 .49-1.98.689-3 .99-1.121-1.265-2.783-1.335-4.38-.737S11.977 6.323 12 8v1c-3.245.083-6.135-1.395-8-4 0 0-4.182 7.433 4 11-1.872 1.247-3.739 2.088-6 2 3.308 1.803 6.913 2.423 10.034 1.517 3.58-1.04 6.522-3.723 7.651-7.742a13.84 13.84.0 00.497-3.753C20.18 7.773 21.692 5.25 22 4.009z"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg><span>Home</span></a></li><li><a href=/about-me/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg><span>About Me</span></a></li><div class=menu-bottom-section><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><span>Dark Mode</span></li></div></ol></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><div class=article-title-wrapper><h2 class=article-title><a href=/posts/2016-09-09-containers-in-2019-they-calling-it/>Containers in 2019: They're Calling It a Hypervisor Comeback</a></h2></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg><time class=article-time--published>Oct 26, 2019</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><time class=article-time--reading>13 minute read</time></div></footer></div></header><section class=article-content><h3 id=key-takeaways>Key Takeaways</h3><ul><li>Near the close of 2018, Amazon amped up an already-increasing interest level in the marrying of container and hypervisor technology by announcing Firecracker, a Rust-based Virtual Machine Monitor</li><li>Around the midpoint of this year, Weaveworks introduced a new project, Ignite, which wraps Amazon‚Äôs Firecracker project with a container-lifecycle UI experience.</li><li>One clear use case for this new marriage of hypervisor technology and containers is to add a layer of protection and isolation to potentially sensitive (or untrusted) workloads.</li><li>User experience is also important within the hypervisor/container space: a growing number of companies, developers, and open source projects have become dependent on the simple life-cycle and user experience that Docker brought to the container world.¬†</li><li>Providing ‚Äúisolation flexibility‚Äù within container orchestration frameworks like Kubernetes is becoming increasingly important. Can and will we have a world where clusters can provide dynamic choice based on workload type? The answer is yes!<br>¬†</li></ul><p>The 2019 news cycle here in our cloud native corner of the world has been abuzz with a word previously thought outmoded by the rapid rise of containers: &ldquo;hypervisor.&rdquo; Near the close of 2018, Amazon amped up an already-increasing interest level in the marrying of container and hypervisor technology by announcing <a class=link href=https://www.infoq.com/news/2018/12/aws-firecracker/ target=_blank rel=noopener>Firecracker</a>, a Rust-based Virtual Machine Monitor (VMM) with an associated open source project, as well as integration with the CNCF <a class=link href=https://containerd.io/ target=_blank rel=noopener>containerd</a> runtime project. This news was quickly followed by an announcement from the <a class=link href=https://katacontainers.io/ target=_blank rel=noopener>Kata Containers</a> project ‚Äî an existing open source virtualization-backed container runtime: they would be supporting Firecracker-backed virtualization in addition to their traditional qemu/kvm-based runtime.</p><p>As we rounded the corner into this year, blog posts and 2019 predictions included expectations that this might be the &ldquo;year of the hypervisor.&rdquo; Both <a class=link href=https://thenewstack.io/kubernetes-and-the-return-of-the-virtual-machines/ target=_blank rel=noopener>The New Stack</a> and <a class=link href=https://www.infoq.com/news/2019/05/kubernetes-future/ target=_blank rel=noopener>InfoQ</a> had great roundups on the topic, distilling information from both Paul Czarkowski‚Äôs &ldquo;<a class=link href=https://tech.paulcz.net/blog/future-of-kubernetes-is-virtual-machines/ target=_blank rel=noopener>The Future of Kubernetes is VMs</a>&rdquo; blog post and Chris Short‚Äôs &ldquo;<a class=link href=https://chrisshort.net/2018-learnings-2019-expectations/ target=_blank rel=noopener>Kubernetes Will Start to Replace the Hypervisor</a>&rdquo; section of his 2018 close-out and 2019 predictions post.</p><p>Around the midpoint of this year, Weaveworks, and project creator <a class=link href=https://www.linkedin.com/in/luxas/ target=_blank rel=noopener>Lukas Kaldstrom</a>, introduced a new project, <a class=link href=https://www.infoq.com/news/2019/07/weaveworks-ignite-firecracker/ target=_blank rel=noopener>Ignite</a>, which wraps Amazon‚Äôs Firecracker project with a container-lifecycle UI experience. Ignite generated a significant amount of interest within days ‚Äî and even hours ‚Äî of its announcement, leading to early proof of concepts from an <a class=link href=https://github.com/chanwit/vkignite target=_blank rel=noopener>integration with Virtual Kubelet</a> to a <a class=link href=https://github.com/apache/openwhisk/pull/4556 target=_blank rel=noopener>community pull request</a> to use Ignite within OpenWhisk, an open source serverless platform built on container-native function execution.</p><p>So what does all this mean as we continue with rapid adoption and hyper-ecosystem growth around Kubernetes and containers? Let‚Äôs try and break that down into a few key areas and see what all the excitement is about.</p><h2 id=security>Security</h2><p>At the risk of stating the obvious, the ever-present discussion around security and Linux container isolation has led to strong recommendations for applying &ldquo;defense in depth&rdquo; as developers implement container-based architectures. Many of these walls of defense are present within the orchestration and runtime layers we are using today; everything from <a class=link href=https://en.wikipedia.org/wiki/Seccomp target=_blank rel=noopener>seccomp</a> profiles, to configured and enabled LSMs (<a class=link href=https://wiki.ubuntu.com/AppArmor target=_blank rel=noopener>AppArmor</a> and <a class=link href=https://en.wikipedia.org/wiki/Security-Enhanced_Linux target=_blank rel=noopener>SELinux</a>), along with new focus areas around &ldquo;rootless&rdquo; and least privileged/limited capabilities for containerized processes.</p><p>To draw a picture that helps us understand the argument for additional isolation layers, let‚Äôs think about the shared Linux kernel underneath our containers as a number. We‚Äôll pick the number of system calls available on average in the Linux kernel, which currently is around 340. The Docker engine default seccomp profile blocks <a class=link href=https://docs.docker.com/engine/security/seccomp/ target=_blank rel=noopener>44 system calls today</a>, leaving containers running in this default Docker engine configuration with just around 300 syscalls available. Of course what containers can do with those syscalls is still at the mercy of other layers of defense, like running the container without administrative privilege, removing more Linux capabilities from the process, additional restrictions applied via AppArmor or SELinux, and so on.</p><p><img src=https://res.infoq.com/articles/containers-hypervisors-2019/en/resources/1Containers-in-2019-They-re-calling-it-a-Hypervisor-Comeback-1-1571750182828.jpg loading=lazy></p><p>Returning to the number of syscalls, let‚Äôs describe this as the &ldquo;attack surface&rdquo; available to potentially malicious programs in a container running on our host. As a general rule, we should expect that smaller numbers are better, as that means a smaller attack surface available to containers. By that logic, adding a hypervisor between the host and the containerized process means effectively reducing that number to zero, although of course the software implementing the hypervisor (for example, a KVM-based virtualizer would have complete access to &ldquo;/dev/kvm&rdquo; and the hardware‚Äôs virtualization capabilities) will be using system calls on the host to implement these features. However, the code we run in the container should have no access through this VM barrier back to our protected host. Stepping out of our discussion of purely lightweight virtualization-based isolators for a moment, we observe that Google‚Äôs <a class=link href=https://www.infoq.com/presentations/gvisor-linux-container/ target=_blank rel=noopener>gVisor</a> and IBM Research‚Äôs <a class=link href=https://nabla-containers.github.io/ target=_blank rel=noopener>Nabla</a> projects are also reducing this &ldquo;300-or-so&rdquo; syscall number to single digits. In the case of Nabla this number is specifically seven, and those interested in further investigation can look at <a class=link href=https://github.com/nabla-containers/nabla-measurements target=_blank rel=noopener>this measurements project</a> to see how to compare and determine the use of syscalls for various isolators.</p><p>In that vein, one clear use case for this new marriage of hypervisor technology and containers is to add a layer of protection and isolation to potentially sensitive (or untrusted) workloads for which we clearly want the smallest possible attack surface on our host. While even considering wrapping a container in a fully-booting virtual machine might have been a disastrous thought performance-wise a mere few years ago, this is no longer the case. The work that Intel did with <a class=link href=https://lwn.net/Articles/644675/ target=_blank rel=noopener>Clear Containers</a> ‚Äî as well as <a class=link href=https://github.com/hyperhq target=_blank rel=noopener>Hyper.sh</a> and their now-shuttered offering ‚Äî to drastically reduce boot time and clear some of the historic cobwebs of how we boot virtual computers means boot times for these lightweight virtualized containers dropped within the sub-second expectations to which containers made us accustomed. Firecracker in applying similar streamlining via it‚Äôs Rust-based VMM claims to achieve 125ms boot times, even at significant microVM concurrency, claiming 150 VMs booted per second per host. Clearly if one can achieve an increase in process isolation with nearly similar performance characteristics, lightweight virtualization becomes a viable option for workloads in which this added security layer is a desired property.</p><p>Assuming you have workloads for which this level of isolation is attractive, the Kubernetes 1.12+ (as alpha) and Kubernetes 1.14+ (as beta) API included a new RuntimeClass resource which can be combined with the `runtimeClassName` selector in the Pod specification to point to a specific runtime as the &ldquo;isolator of choice&rdquo; to back a specific pod in Kubernetes. I <a class=link href="https://www.youtube.com/watch?v=FKoVztEQHss" target=_blank rel=noopener>demonstrated a fairly complete list of possible isolation choices</a> using this feature at KubeCon EU in May 2019 including gVisor, Kata, Nabla, and Firecracker. While two of those are not lightweight hypervisors, all of them are providing an approach to answer the question &ldquo;how can I get more isolation for my pods than Linux kernel namespaces and cgroups?&rdquo; As public clouds provide more customization within their managed Kubernetes offerings, you can expect that registering and installing specific RuntimeClass options within your cluster will be an expected capability. Today, this can be achieved in a brute force way by directly accessing worker nodes, installing required pieces like the Kata or Firecracker components, and then using the RuntimeClass features within the existing Kubernetes API to select specific runtimes.</p><p>Public clouds, however, are unlikely to sit back and leave the usage of these additional isolation features to users to figure out how to configure and operate. Google Cloud has <a class=link href=https://cloud.google.com/blog/products/containers-kubernetes/gke-sandbox-bring-defense-in-depth-to-your-pods target=_blank rel=noopener>already announced</a> that GKE Sandbox, Google Cloud Run, and Google Cloud Functions utilize gVisor today. When Google announced Cloud Run, the use of gVisor as an isolator received some significant interest, and various engineers from Google, including Ahmet Balkan, <a class=link href=https://twitter.com/ahmetb/status/1116041166359654400 target=_blank rel=noopener>provided valuable details</a> on how Google utilizes these capabilities within their platform.</p><h2 id=user-experience>User Experience</h2><p>Security may not be the whole story for this new-found love of lightweight virtualization in the container ecosystem. While there are still detractors, <a class=link href=https://containerjournal.com/topics/container-ecosystems/survey-finds-container-adoption-more-pervasive/ target=_blank rel=noopener>container adoption data</a> shows that a consistently growing number of companies, developers, and open source projects have become dependent on the simple life-cycle and user experience that Docker brought to the container world.</p><p>For the most part, the Dockerfile as a standard for defining our images, added to a growing mixture of available build tooling to assemble these into immutable and easily deployable units, has taken hold in our modern day DevOps culture. But what if users still have use cases for the capabilities provided via VMs within our brave new world ‚Äî and specifically, with the ease and simplicity of the container image and runtime model? This is where Weave‚Äôs Ignite project seems to have captured the imagination of a hybrid model combining VMs and containers. With Ignite, you get a &ldquo;Docker-like&rdquo; user experience with a booted VM as the end result. Given your VM is still sourced ‚Äî the user space file system to be specific ‚Äî from a standard container image you can keep your CI/CD-driven build steps to produce a container image, but with Ignite, that container image easily becomes a VM, booted and managed with Firecracker‚Äôs Rust-based VMM, with the security and performance promises via that underlying project. Along the way Ignite marries your container image &ldquo;user space&rdquo; to a Linux kernel and init process ‚Äî optionally one of your choosing ‚Äî to create a fully bootable virtual machine. To quote the <a class=link href=https://www.weave.works/blog/fire-up-your-vms-with-weave-ignite target=_blank rel=noopener>announcement blog post</a> directly, with Ignite and the existing landscape of tooling you can imagine that &ldquo;<em>we can run a cloud of VMs ‚Äòanywhere‚Äô using Kubernetes for orchestration, Ignite for virtualization, GitOps for management, and supporting cloud native tools and APIs</em>.&rdquo;</p><p>Given Ignite‚Äôs flexibility ‚Äî for example, optionally providing your own kernel and/or kernel modules, packaged as a container image of course ‚Äî this opens up opportunities for many interesting use cases, all accessible from modern container-native tooling: everything from traditional VM packaged workloads to edge computing to special test and ephemeral setups that can be spun up on-demand with none of the overhead and complexity of traditional VM image creation tools and processes. To be explicit, there are no vmdk files involved. There are no qcow or raw image tools required to work with Ignite. You are always working with container images, and Weave has already provided a default Ubuntu and CentOS image with some VM-friendly additions like sshd and systemd, for example. Networking is handled for you via CNI plugin, giving you the same networking capabilities that exist in any standard Kubernetes deployment. Ignite‚Äôs current implementation allows for port-forwarding to your VMs based on command-line flags or configuration file-defined parameters.</p><h2 id=isolation-flexibility>Isolation Flexibility</h2><p>We‚Äôve seen that &ldquo;defense in depth&rdquo; security initiatives and a container-native user experience for VMs are both elements leading to an increased interest in lightweight virtualization. But for the Kubernetes world where core container runtime choice is fairly static ‚Äî nodes in your cluster are probably using Docker, maybe containerd, and optionally <a class=link href=https://cri-o.io/ target=_blank rel=noopener>cri-o</a>, but not multiples at the same time ‚Äî can and will we have a world where clusters can provide dynamic choice based on workload type? The answer is yes!</p><p>I‚Äôve already covered the recent RuntimeClass feature, added within the past few Kubernetes releases, which provides for a pod-level selection of registered runtimes. This replaces a deprecated and less flexible &ldquo;untrusted workload&rdquo; feature which could only be on or off for any given pod. On a properly installed and configured cluster, you can imagine within the same Kubernetes environment the ability to select ‚Äî according to any self-defined criteria ‚Äî various levels of workload isolation preferred from standard Linux containers to gVisor to unikernel-backed Nabla to either of the popular virtualization runtimes: Kata and Firecracker.</p><p>The CNCF containerd project has enabled this flexibility to an even greater degree by formalizing a <a class=link href=https://github.com/containerd/containerd/blob/master/runtime/v2/README.md target=_blank rel=noopener>shim API</a>, allowing for 3rd party shim implementations to plug into a standard containerd installation, allowing the shim to drive the actual container lifecycle operations directly with an isolator‚Äôs technology-of-choice framework. For example, this means a shim specific to Kata can handle Kata‚Äôs management of boot-time VM parameterization when containerd asks the shim to &ldquo;start a container.&rdquo; The main containerd daemon is not required to know anything about these details and therefore can remain simple and unaware of the actual containerization primitives in use. Open source project shims exist for gVisor, Kata, and Firecracker today, as well as the included containerd project v2 shim for Linux and Microsoft‚Äôs new shim implementation which arrived in the containerd 1.3 release last month.</p><p><img src=https://res.infoq.com/articles/containers-hypervisors-2019/en/resources/1Containers-in-2019-They-re-calling-it-a-Hypervisor-Comeback-2-1571750183287.jpg loading=lazy></p><p>While these features within Kubernetes and containerd are orthogonal to the actual capabilities of hypervisor-based isolators, providing a way for these isolation methods to be easily integrated at the container runtime and container orchestration layers will clearly be beneficial to broad adoption of lightweight virtualization as a technology. Marrying this ease of integration with the security and container user experience tenets already discussed provides three clear signposts pointing us to potential realization of the late 2018 and early 2019 predictions as &ldquo;the year of the hypervisor.&rdquo; Production usage and cloud platform integration are also valuable markers for any technology, and the fact that AWS clearly expects Firecracker to be the underpinnings of their popular Lambda service, and the aforementioned gVisor usage across several Google Cloud properties seem to point in positive directions as well.</p><h2 id=summary>Summary</h2><p>So far our treatment of this topic has heavily leaned towards the positive characteristics of this new containers-as-microVMs era. What isn‚Äôt there to like? Well, for operators/admins, developers looking for application debug tools, performance tuning experts, and associated roles, there are still characteristics of a running, booted virtual machines that reintroduce complications we had happily dismissed in our rush to the simplicity of a Linux process-as-container.</p><p>More concretely, with hypervisor-wrapped containers an additional Linux kernel is being provided by these new runtimes (or the user), and that kernel require patching and maintenance, and has all the usual exposures of running a Linux kernel. Additionally, we re-introduce a hypervisor boundary between our running application and the host-side networking and storage hardware. These are problems that have been worked on and improved for decades with special virtual IO drivers, utilizing PCI pass-through and other techniques, that now are relevant again in our lightweight virtualization-wrapped containers. To be clear, smart and capable minds are already working on these problems ‚Äî case in point, see <a class=link href=https://vmsplice.net/~stefan/stefanha-virtio-fs-kata.pdf target=_blank rel=noopener>this presentation</a> from Red Hat discussing the state of the <a class=link href=https://virtio-fs.gitlab.io/ target=_blank rel=noopener>virtio-fs project</a> for Kata containers. We also have to be aware of the security threat model and potentially required hardening for our new hypervisor stack itself; knowing that by adding isolation we aren‚Äôt allowed to simply ignore the large codebase we have just inserted into our software stack.</p><p>That said, I think we can all agree that hypervisors are back, and they are married to containers! There‚Äôs a growing and significant level of excitement for how these pieces will play a role in specific use cases and we are already seeing public cloud platforms create and adopt some of these new isolation techniques. What will 2020 bring to this exciting space? We only have a few months left of 2019 before we find out, and for sure it doesn‚Äôt look like anyone will have to eat their words about the rise of the significance and use of the hypervisor in 2019.</p><h2 id=about-the-author>About the Author</h2><p><strong><img src=https://res.infoq.com/articles/containers-hypervisors-2019/en/resources/1Phil-Estes-1571750426034.jpg loading=lazy>Phil Estes</strong> is a Distinguished Engineer & CTO, Container and Linux OS Architecture Strategy for the IBM Watson and Cloud Platform division. Phil is currently an OSS maintainer in the Docker (now Moby) engine project, the CNCF containerd project, and is a member of both the Open Container Initiative (OCI) Technical Oversight Board and the Moby Technical Steering Committee. Phil is a member of the CNCF Ambassadors program and has broad experience in open source and the container ecosystem. Phil speaks worldwide at industry and developer conferences as well as meetups on topics related to open source, Docker, and Linux container technology. Phil <a class=link href=https://integratedcode.us/ target=_blank rel=noopener>blogs</a> regularly on these topics and can be found on Twitter as @estesp.</p><p>from Hacker News <a class=link href=https://ift.tt/2BGM7QI target=_blank rel=noopener>https://ift.tt/2BGM7QI</a></p></section><footer class=article-footer><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg><span>Licensed under CC BY-NC-SA 4.0</span></section></footer></article><footer class=site-footer><section class=copyright>&copy;
2020 -
2022 ZYChimne</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.11.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css integrity="sha256-c0uckgykQ9v5k+IqViZOZKc47Jn7KQil4/MP3ySA3F8=" crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.css integrity="sha256-SBLU4vv6CA6lHsZ1XyTdhyjJxCjPif/TRkjnsyGAGnE=" crossorigin=anonymous></main><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><ol><li><a href=#key-takeaways>Key Takeaways</a></li></ol></li><li><a href=#security>Security</a></li><li><a href=#user-experience>User Experience</a></li><li><a href=#isolation-flexibility>Isolation Flexibility</a></li><li><a href=#summary>Summary</a></li><li><a href=#about-the-author>About the Author</a></li></ol></nav></div></section></aside></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.5/dist/vibrant.min.js integrity="sha256-5NovOZc4iwiAWTYIFiIM7DxKUXKWvpVEuMEPLzcm5/g=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script>
<script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>