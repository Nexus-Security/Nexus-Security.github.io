<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Frequencies of observed values over time from load ports. Here we‚Äôre seeing the processor internally performing a microcode-assisted page table walk to update accessed and dirty bits. Only one load was performed by the user, these are all ‚Äúinvisible‚Äù loads done behind the scenes
Twitter Follow me at @gamozolabs on Twitter if you want notifications when new blogs come up. I often will post data and graphs from data as it comes in and I learn!"><title>CPU Introspection: Intel Load Port Snooping</title><link rel=canonical href=https://Nexus-Security.github.io/posts/2016-09-09-cpu-introspection-intel-load-port/><link rel=stylesheet href=/scss/style.min.450926226e724574a6b936335ea06111f8aeb253d932c86cb2cc807341cd2889.css><meta property="og:title" content="CPU Introspection: Intel Load Port Snooping"><meta property="og:description" content="Frequencies of observed values over time from load ports. Here we‚Äôre seeing the processor internally performing a microcode-assisted page table walk to update accessed and dirty bits. Only one load was performed by the user, these are all ‚Äúinvisible‚Äù loads done behind the scenes
Twitter Follow me at @gamozolabs on Twitter if you want notifications when new blogs come up. I often will post data and graphs from data as it comes in and I learn!"><meta property="og:url" content="https://Nexus-Security.github.io/posts/2016-09-09-cpu-introspection-intel-load-port/"><meta property="og:site_name" content="ZYChimne"><meta property="og:type" content="article"><meta property="article:section" content="Posts"><meta property="article:published_time" content="2019-12-30T07:55:00+01:00"><meta property="article:modified_time" content="2019-12-30T07:55:00+01:00"><meta name=twitter:title content="CPU Introspection: Intel Load Port Snooping"><meta name=twitter:description content="Frequencies of observed values over time from load ports. Here we‚Äôre seeing the processor internally performing a microcode-assisted page table walk to update accessed and dirty bits. Only one load was performed by the user, these are all ‚Äúinvisible‚Äù loads done behind the scenes
Twitter Follow me at @gamozolabs on Twitter if you want notifications when new blogs come up. I often will post data and graphs from data as it comes in and I learn!"></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu8b78332b6420dc9affabe23720d11e63_1937019_300x0_resize_q75_box.jpg width=300 height=300 class=site-logo loading=lazy alt=Avatar></a>
<span class=emoji>üçá</span></figure><div class=site-meta><h1 class=site-name><a href=/>ZYChimne</a></h1><h2 class=site-description>Computer Science, Wuhan University</h2></div></header><ol class=social-menu><li><a href=https://github.com/ZYChimne target=_blank title=GitHub><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=https://twitter.com/ZChimne target=_blank title=Twitter><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-twitter" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M22 4.01c-1 .49-1.98.689-3 .99-1.121-1.265-2.783-1.335-4.38-.737S11.977 6.323 12 8v1c-3.245.083-6.135-1.395-8-4 0 0-4.182 7.433 4 11-1.872 1.247-3.739 2.088-6 2 3.308 1.803 6.913 2.423 10.034 1.517 3.58-1.04 6.522-3.723 7.651-7.742a13.84 13.84.0 00.497-3.753C20.18 7.773 21.692 5.25 22 4.009z"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg><span>Home</span></a></li><li><a href=/about-me/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg><span>About Me</span></a></li><li><a href=/archives/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg><span>Archives</span></a></li><li><a href=/search/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg><span>Search</span></a></li><div class=menu-bottom-section><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><span>Dark Mode</span></li></div></ol></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><div class=article-title-wrapper><h2 class=article-title><a href=/posts/2016-09-09-cpu-introspection-intel-load-port/>CPU Introspection: Intel Load Port Snooping</a></h2></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg><time class=article-time--published>Dec 30, 2019</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><time class=article-time--reading>24 minute read</time></div></footer></div></header><section class=article-content><p><img src=https://gamozolabs.github.io/assets/loadseq_example.png loading=lazy alt="Load sequence example"></p><p><em>Frequencies of observed values over time from load ports. Here we‚Äôre seeing the processor internally performing a microcode-assisted page table walk to update accessed and dirty bits. Only one load was performed by the user, these are all ‚Äúinvisible‚Äù loads done behind the scenes</em></p><h1 id=twitter>Twitter</h1><p>Follow me at <a class=link href=https://twitter.com/gamozolabs target=_blank rel=noopener>@gamozolabs</a> on Twitter if you want notifications when new blogs come up. I often will post data and graphs from data as it comes in and I learn!</p><hr><h1 id=foreward>Foreward</h1><p>First of all, I‚Äôd like to say that I‚Äôm super excited to write up this blog. This is an idea I‚Äôve had for over a year and I only recently got to working on. The initial implementation and proof-of-concept of this idea was actually implemented live on my <a class=link href=https://twitch.tv/gamozo target=_blank rel=noopener>Twitch</a>! This proof-of-concept went from nothing at all to a fully-working-as-predicted implementation in just about 3 hours! Not only did the implementation go much smoother than expected, the results are by far higher resolution and signal-to-noise than I expected!</p><p>This blog is fairly technical, and thus I highly recommend that you read my <a class=link href=https://gamozolabs.github.io/metrology/2019/08/19/sushi_roll.html target=_blank rel=noopener>previous blog on Sushi Roll</a>, my CPU research kernel where this technique was implemented. In the Sushi Roll blog I go a little bit more into the high-level details of Intel micro-architecture and it‚Äôs a great introduction to the topic if you‚Äôre not familiar.</p><p><a class=link href="https://www.youtube.com/watch?v=_oE4_ShKQL8" target=_blank rel=noopener><img src=https://img.youtube.com/vi/_oE4_ShKQL8/0.jpg loading=lazy alt="YouTube video for PoC implementation"></a></p><p><em>Recording of the stream where we implemented this idea as a proof-of-concept. Click for the YouTube video!</em></p><hr><h1 id=summary>Summary</h1><p>We‚Äôre going to go into a unique technique for observing and sequencing all load port traffic on Intel processors. By using a CPU vulnerability from the MDS set of vulnerabilities, specifically multi-architectural load port data sampling (MLPDS, CVE-2018-12127), we are able to observe values which fly by on the load ports. Since (to my knowledge) all loads must end up going through load ports, regardless of requestor, origin, or caching, this means in theory, all contents of loads ever performed can be observed. By using a creative scanning technique we‚Äôre able to not only view ‚Äúrandom‚Äù loads as they go by, but sequence loads to determine the ordering and timing of them.</p><p>We‚Äôll go through some examples demonstrating that this technique can be used to view all loads as they are performed on a cycle-by-cycle basis. We‚Äôll look into an interesting case of the micro-architecture updating accessed and dirty bits using a microcode assist. These are invisible loads dispatched on the CPU on behalf of the user when a page is accessed for the first time.</p><h1 id=why>Why</h1><p>As you may be familiar, x86 is quite a complex architecture with many nooks and crannies. As time has passed it has only gotten more complex, leading to fewer known behaviors of the inner workings. There are many instructions with complex microcode invocations which access memory as were seen through my work on Sushi Roll. This led to me being curious as to what is actually going on with load ports during some of these operations.</p><p><img src=https://gamozolabs.github.io/assets/graph_write_nodirtyupdate.png loading=lazy alt="Intel CPU traffic during a normal write"></p><p><em>Intel CPU traffic on load ports (ports 2 and 3) and store ports (port 4) during a traditional memory write</em></p><p><img src=https://gamozolabs.github.io/assets/graph_write_dirtyupdate.png loading=lazy alt="Intel CPU traffic during a write requiring dirty/accessed updates"></p><p><em>Intel CPU traffic on load ports (ports 2 and 3) and store ports (port 4) during the same memory write as above, but this time where the page table entries need an accessed/dirty bit update</em></p><p>Beyond just directly invoked microcode due to instructions being executed, microcode also gets executed on the processor during ‚Äúmicrocode assists‚Äù. These operations, while often undocumented, are referenced a few times throughout Intel manuals. Specifically in the Intel Optimization Manual there are references to microcode assists during accessed and dirty bit updates. Further, there is a restriction on TSX sections such that they may abort when accessed and dirty bits need to be updated. These microcode assists are fascinating to me, as while I have no evidence for it, I suspect they may be subject to different levels of permissions and validations compared to traditional operations. Whenever I see code executing on a processor as a side-effect to user operations, all I think is: ‚Äúhere be dragons‚Äù.</p><hr><h1 id=a-playground-for-cpu-bugs>A playground for CPU bugs</h1><p>When I start auditing a target, the first thing that I try to do is get introspection into what is going on. If the target is an obscure device then I‚Äôll likely try to find some bug that allows me to image the entire device, and load it up in an emulator. If it‚Äôs some source code I have that is partial, then I‚Äôll try to get some sort of mocking of the external calls it‚Äôs making and implement them as I come by them. Once I have the target running on <em>my</em> terms, and not the terms of some locked down device or environment, then I‚Äôll start trying to learn as much about it as possible‚Ä¶</p><p>This is no different from what I did when I got into CPU research. Starting with when Meltdown and Spectre came out I started to be the go-to person for writing PoCs for CPU bugs. I developed a few custom OSes early on that were just designed to give a pass/fail indicator if a CPU bug were able to be exploited in a given environment. This was critical in helping test the mitigations that went in place for each CPU bug as they were reported, as testing if these mitigations worked is a surprisingly hard problem.</p><p>This led to me having some cleanly made OS-level CPU exploits written up. The custom OS proved to be a great way to test the mitigations, especially as the signal was much higher compared to a traditional OS. In fact, the signal was almost just a bit too strong‚Ä¶</p><p>When in a custom operating system it‚Äôs a lot easier to play around with weird behaviors of the CPU, without worrying about it affecting the system‚Äôs stability. I can easily turn off interrupts, overwrite exception handlers with specialized ones, change MSRs to weird CPU states, and so on. This led to me ending up with almost a playground for CPU vulnerability testing with some pretty standard primitives.</p><p>As the number of primitives I had grew, I was able to PoC out a new CPU bug in typically under a day. But then I had to wonder‚Ä¶ what would happen if I tried to get the most information out of the processor as possible.</p><hr><h1 id=sushi-roll>Sushi Roll</h1><p>And that was the starting of Sushi Roll, my CPU research kernel. I have a whole <a class=link href=https://gamozolabs.github.io/metrology/2019/08/19/sushi_roll.html target=_blank rel=noopener>blog about the Sushi Roll research kernel</a>, and I strongly recommend you read it! Effectively Sushi Roll is a custom kernel with message passing between cores rather than memory sharing. This means that each core has a complete copy of the kernel with no shared accesses. For attacks which need to observe the faintest signal in memory behaviors, this lead to a great amount of isolation.</p><p>When looking for a behavior you already understand on a processor, it‚Äôs pretty easy to get a signal. But, when doing initial CPU research into the unknowns and undefined behavior, getting this signal out takes every advantage as you can get. Thus in this low-noise CPU research environment, even the faintest leak would cause a pretty large disruption in determinism, which would likely show up as a measurable result earlier than traditional blind CPU research would allow.</p><h4 id=performance-counter-monitoring>Performance Counter Monitoring</h4><p>In Sushi Roll I implemented a creative technique for monitoring the values in performance counters along with time-stamping them in cycles. Some of the performance counters in Intel processors count things like the number of micro-ops dispatched to each of the execution units on the core. Some of these counters increase during speculation, and with this data and time-stamping I was able to get some of the first-ever insights into what processor behavior was actually occurring during speculation!</p><p><img src=https://gamozolabs.github.io/assets/example_profiling.png loading=lazy alt="Example uarch activity"><em>Example cycle-by-cycle profiling of the Kaby Lake micro-architecture, warning: log-scale y-axis</em></p><p>Being able to collect this sort of data immediately made unexpected CPU behaviors easier to catalog, measure, and eventually make determinstic. The more understanding we can get of the internals of the CPU, the better!</p><hr><h1 id=the-ultimate-goal>The Ultimate Goal</h1><p>The ultimate goal of my CPU research is to understand so thoroughly how the Intel micro-architecture works that I can predict it with emulation models. This means that I would like to run code through an emulated environment and it would tell me exactly how many internal CPU resources would be used, which lines from caches and buffers would be evicted and what contents they would hold. There‚Äôs something beautiful to me to understanding something so well that you can predict how it will behave. And so the journey begins‚Ä¶</p><h1 id=past-progress>Past Progress</h1><p>So far with the work in Sushi Roll we‚Äôve been able to observe how the CPU dispatches uops during specific portions of code. This allows us to see which CPU resources are used to fulfill certain requests, and thus can provide us with a rough outline of what is happening. With simple CPU operations this is often all we need, as there are only so many ways to perform a certain operation, the complete picture can usually be drawn just from guessing ‚Äúhow they might have done it‚Äù. However, when more complex operations are involved, all of that goes out the window.</p><p>When reading through Intel manuals I saw many references to microcode assists. These are ‚Äúsituations‚Äù in your processor which may require microcode to be dispatched to execution units to perform some complex-ish logic. These are typically edge cases which don‚Äôt occur frequently enough for the processor to worry about handling them in hardware, rather just needing to detect them and cause some assist code to run. We know of one microcode assist which is relatively easy to trigger, updating the accessed and dirty bits in the page tables.</p><h4 id=accessed-and-dirty-bits>Accessed and dirty bits</h4><p>In the Intel page table (and honestly most other architectures) there‚Äôs a concept of accessed and dirty bits. These bits indicate whether or not a page has ever been translated (accessed), or if it has been written to (dirtied). On Intel it‚Äôs a little strange as there is only a dirty bit on the final page table entry. However, the accessed bits are present on each level of the page table during the walk. I‚Äôm quite familiar with these bits from my work with hypervisor-based fuzzing as it allows high performance differential resetting of VMs by simply walking the page tables and restoring pages that were dirtied to their original state of a snapshot.</p><p>But this leads to an curiosity‚Ä¶ what is the mechanic responsible for setting these bits? Does the internal page table silicon set these during a page table walk? Are they set after the fact? Are they atomically set? Are they set during speculation or faulting loads?</p><p>From Intel manuals and some restrictions with TSX it‚Äôs pretty obvious that accessed and dirty bits are a bit of an anomaly. TSX regions will abort when memory is touched that does not have the respective accessed or dirty bits set. Which is strange, why would this be a limitation of the processor?</p><p><img src=https://gamozolabs.github.io/assets/tsx_intel_manual.png loading=lazy alt="TSX aborts during accessed and dirty bit updates"></p><p><em>Accessed and dirty bits causing TSX aborts from the Intel¬Æ 64 and IA-32 architectures optimization reference manual</em></p><p>‚Ä¶ weird huh? Testing it out yields exactly what the manual says. If I write up some sample code which accesses memory which doesn‚Äôt have the respective accessed or dirty bits set, it aborts <em>every time</em>!</p><h1 id=whats-next>What‚Äôs next?</h1><p>So now we have an ability to view what operation types are being performed on the processor. However this doesn‚Äôt tell us a huge amount of information. What we would really benefit from would be knowing the data contents that are being operated on. We can pretty easily log the data we are fetching in our own code, but that won‚Äôt give us access to the internal loads that happen as side effects on the processor, nor would it tell us about the contents of loads which happen during speculation.</p><p>Surely there‚Äôs no way to view all loads which happen on the processor right? Almost anything during speculation is a pain to observe, and even if we could observe the data it‚Äôd be quite noisy.</p><p>Or maybe there is a way‚Ä¶</p><h1 id=-a-way>‚Ä¶ a way?</h1><p>Fortunately there may indeed be a way! A while back I found a CPU vulnerability which allowed for random values to be sampled off of the load ports. While this vulnerability is initially thought to only allow for random values to be sampled from the load ports, perhaps we can get a bit more creative about leaking‚Ä¶</p><hr><h1 id=multi-architectural-load-port-data-sampling-mlpds>Multi-Architectural Load Port Data Sampling (MLPDS)</h1><p>Multi-architectural load port data sampling sounds like an overly complex name, but it‚Äôs actually quite simple in the end. It‚Äôs a set of CPU flaws in Intel processors which allow a user to potentially get access to stale data recently transferred through load ports. This was actually a bug that I reported to Intel a while back and they ended up finding a few similar issues with different instruction combinations, this is ultimately what comprises MLPDS.</p><p><img src=https://gamozolabs.github.io/assets/mlpds_intel_desc.png loading=lazy alt="MLPDS Intel Description"></p><p><em>Description of MLPDS from <a class=link href=https://software.intel.com/security-software-guidance/insights/deep-dive-intel-analysis-microarchitectural-data-sampling target=_blank rel=noopener>Intel‚Äôs MDS DeepDive</a></em></p><p>The specific bug that I found was initially called ‚Äúcache line split‚Äù or ‚Äúcache line split load‚Äù and it‚Äôs exactly what you might expect. When a data access straddles a cache line (multi-byte load containing some bytes on one cache line and the remaining bytes on another). Cache lines are 64-bytes in size so any multi-byte memory access to an address with the bottom 6 bits set would cause this behavior. These accesses must also cause a fault or an assist, but by using TSX it‚Äôs pretty easy to get whatever behavior you would like.</p><p>This bug is largely an issue when hyper-threading is enabled as this allows a sibling thread to be executing protected/privileged code while another thread uses this attack to observe recently loaded data.</p><p>I found this bug when working on early PoCs of L1TF when we were assessing the impact it had. In my L1TF PoC (which was using random virtual addresses each attempt) I ended up disabling the page table modification. This ultimately is the root requirement for L1TF to work, and to my surprise, I was still seeing a signal. I initially thought it was some sort of CPU bug leaking registers as the value I was leaking was never actually read in my code. It turns out what I ended up observing was the hypervisor itself context switching my VM. What I was leaking was the contents of the registers as they were loaded during the context switch!</p><p>Unfortunately MLPDS has a <em>really</em> complex PoC‚Ä¶</p><p>After this instruction executes and it faults or aborts, the contents of <code>rax</code> during a small speculative window will potentially contain stale data from load ports. That‚Äôs all it takes!</p><p>From this point it‚Äôs just some trickery to get the 64-bit value leaked during the speculative window!</p><hr><h1 id=its-all-too-random>It‚Äôs all too random</h1><p>Okay, so MLPDS allows us to sample a ‚Äúrandom‚Äù value which was recently loaded on the load ports. This is a great start as we could probably run this attack over and over and see what data is observed on a sample piece of code. Using hyper-threading for this attack will be ideal because we can have one thread running some sample code in an infinite loop, while the other code observes the values seen on the load port.</p><h1 id=an-mlpds-exploit>An MLPDS exploit</h1><p>Since there isn‚Äôt yet a public exploit for MLPDS, especially with the data rates we‚Äôre going to use here, I‚Äôm just going to go over the high-level details and not show how it‚Äôs implemented under the hood.</p><p>For this MLPDS exploit I use a couple different primitives. One is a pretty basic exploit which simply attempts to leak the raw contents of the value which was leaked. This value that we leak is always 64-bits, but we can chose to only leak a few of the bytes from it (or even bit-level granularity). There‚Äôs a performance increase for the fewer bytes that we leak as it decreases the number of cache lines we need to prime-and-probe each attempt.</p><p>There‚Äôs also another exploit type that I use that allows me to look for a specific value in memory, which turns the leak from a multi-byte leak to just a boolean ‚Äúwas value/wasn‚Äôt value‚Äù. This is the highest performance version due to how little information has to be leaked past the speculative window.</p><p>All of these leaks will leak a specific value from a single speculative run. For example if we were to leak a 64-bit value, the 64-bit value will be from one MLPDS exploit and one speculative window. Getting an entire 64-bit value out during a single speculative window is a surprisingly hard problem, and I‚Äôm going to keep that as my own special sauce for a while. Compared to many public CPU leak exploits, this attack does not loop multiple times using masks to slowly reveal a value, it will get revealed from a single attempt. This is critical to us as otherwise we wouldn‚Äôt be able to observe values which are loaded once.</p><p>Here‚Äôs some of the leak rate numbers for the current version of MLPDS that I‚Äôm using:</p><p>Leak type</p><p>Leaks/second</p><p>Known 64-bit value</p><p>5,979,278</p><p>8-bit any value</p><p>228,479</p><p>16-bit any value</p><p>116,023</p><p>24-bit any value</p><p>25,175</p><p>32-bit any value</p><p>13,726</p><p>40-bit any value</p><p>12,713</p><p>48-bit any value</p><p>10,297</p><p>56-bit any value</p><p>9,521</p><p>64-bit any value</p><p>8,234</p><p>It‚Äôs important to note that the known 64-bit value search is much faster than all of the others. We‚Äôll make some good use of this later!</p><h4 id=test>Test</h4><p>Let‚Äôs try out a simple MLPDS attack on a small piece of code which loops forever fetching 2 values from memory.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>mov rax, 0x12345678f00dfeed mov [0x1000], rax mov rax, 0x1337133713371337 mov [0x1008], rax 2: mov rax, [0x1000] mov rax, [0x1008] jmp 2b 
</span></span></code></pre></td></tr></table></div></div><p>This code should in theory just causes two loads. One of a value <code>0x12345678f00dfeed</code> and another of a value <code>0x1337133713371337</code>. Lets spin this up on a hardware thread and have the sibling thread perform MLPDS in a loop! We‚Äôll use our 64-bit any value MLPDS attack and just histogram all of the different values we observe get leaked.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>Sampling done: 0x12345678f00dfeed : 100532 0x1337133713371337 : 99217 
</span></span></code></pre></td></tr></table></div></div><p>Viola! Here we see the two different secret values on the attacking thread, at a pretty much comparable frequency.</p><p>Cool‚Ä¶ so now we have a technique that will allow us to see the contents of all loads on load ports, but randomly sampled only. Let‚Äôs take a look at the weird behaviors during accessed bit updates by clearing the accessed bit on the final level page tables every loop in the same code above.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>Sampling done: 0x0000000000000008 : 559 0x0000000000000009 : 2316 0x000000000000000a : 142 0x000000000000000e : 251 0x0000000000000010 : 825 0x0000000000000100 : 19 0x0000000000000200 : 3 0x0000000000010006 : 438 0x000000002cc8c000 : 3796 0x000000002cc8c027 : 225 0x000000002cc8d000 : 112 0x000000002cc8d027 : 57 0x000000002cc8e000 : 1 0x000000002cc8e027 : 35 0x00000000ffff8bc2 : 302 0x00002da0ea6a5b78 : 1456 0x00002da0ea6a5ba0 : 2034 0x0000700dfeed0000 : 246 0x0000700dfeed0008 : 5081 0x0000930000000000 : 4097 0x00209b0000000000 : 15101 0x1337133713371337 : 2028 0xfc91ee000008b7a6 : 677 0xffff8bc2fc91b7c4 : 2658 0xffff8bc2fc9209ed : 4565 0xffff8bc2fc934019 : 2 
</span></span></code></pre></td></tr></table></div></div><p>Whoa! That‚Äôs a lot more values than we saw before. They weren‚Äôt from just the two values we‚Äôre loading in a loop, to many other values. Strangely the <code>0x1234...</code> value is missing as well. Interesting. Well since we know these are accessed bit updates, perhaps some of these are entries from the page table walk. Let‚Äôs look at the addresses of the page table entry we‚Äôre hitting.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>CR3 0x630000 PML4E 0x2cc8e007 PDPE 0x2cc8d007 PDE 0x2cc8c007 PTE 0x13370003 
</span></span></code></pre></td></tr></table></div></div><p>Oh! How cool is that!? In the loads we‚Äôre leaking we see the raw page table entries with various versions of the accessed and dirty bits set! Here are the loads which stand out to me:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>Leaked values: 0x000000002cc8c000 : 3796 0x000000002cc8c027 : 225 0x000000002cc8d000 : 112 0x000000002cc8d027 : 57 0x000000002cc8e000 : 1 0x000000002cc8e027 : 35 Actual page table entries for the page we&#39;re accessing: CR3 0x630000 PML4E 0x2cc8e007 PDPE 0x2cc8d007 PDE 0x2cc8c007 PTE 0x13370003 
</span></span></code></pre></td></tr></table></div></div><p>The entries are being observed as <code>0x...27</code> as the <code>0x20</code> bit is the accessed bit for page table entries.</p><p>Other notable entries are <code>0x0000930000000000</code> and <code>0x00209b0000000000</code> which look like the GDT entries for the code and data segments. <code>0x0000700dfeed0000</code> and <code>0x0000700dfeed0008</code> which are the 2 virtual addresses I‚Äôm accessing the un-accessed memory from. Who knows about the rest of the values? Probably some stack addresses in there‚Ä¶</p><p>So clearly as we expected, the processor is dispatching uops which are performing a page table walk. Sadly we have no idea what the order of this walk is, maybe we can find a creative technique for sequencing these loads‚Ä¶</p><hr><h1 id=sequencing-the-loads>Sequencing the Loads</h1><p>Sequencing the loads that we are leaking with MLPDS is going to be critical to getting meaningful information. Without knowing the ordering of the loads we simply know contents of loads. Which is a pretty awesome amount of information, I‚Äôm definitely not complaining‚Ä¶ but come on, it‚Äôs not perfect!</p><p>But perhaps we can limit the timing of our attack to a specific window, and infer ordering based on that. If we can find some trigger point where we can synchronize time between the attacker thread and the thread with secrets, we could change the delay between this synchronization and the leak attempt. By scanning this leak we should hopefully get to see a cycle-by-cycle view of observed values.</p><h4 id=a-trigger-point>A trigger point</h4><p>We can perform an MLPDS attack on a delay, however we need a reference point to delay from. I‚Äôll steal the oscilloscope terminology of a trigger, or a reference location to synchronize with. Similar to an oscilloscope this trigger will synchronize our on the time domain each time we attempt.</p><p>The easiest trigger we can use works only in an environment where we control both the leaking and secret threads, but in our case we have that control.</p><p>What we can do is simply have semaphores at each stage of the leak. We‚Äôll have 2 hardware threads running with the following logic:</p><ol><li>(Thread A running) (Thread B paused)</li><li>(Thread A) Prepare to do a CPU attack, request thread B execute code</li><li>(Thread A) Delay for a fixed amount of cycles with a spin loop</li><li>(Thread B) Execute sample code</li><li>(Thread A) At some ‚Äúrandom‚Äù point during Thread B executing sample code, perform MLPDS attack to leak a value</li><li>(Thread B) Complete sample code execution, wait for thread A to request another execution</li><li>(Thread A) Log the observed value and the number of cycles in the delay loop</li><li>goto 0 and do this many times until significant data is collected</li></ol><h4 id=uncontrolled-target-code>Uncontrolled target code</h4><p>If needed a trigger could be set on a ‚Äúknown value‚Äù at some point during execution if target code is not controllable. For example, if you‚Äôre attacking a kernel, you could identify a magic value or known user pointer which gets accessed close to the code under test. An MLPDS attack can be performed until this magic value is seen, then a delay can start, and another attack can be used to leak a value. This allows an uncontrolled target code to be sampled in a similar way. If the trigger ‚Äúmisses‚Äù it‚Äôs fine, just try again in another loop.</p><h4 id=did-it-work>Did it work?</h4><p>So we put all of these things together, but does it actually work? Lets try our 2 load example, and we‚Äôll make sure they depend on each other to ensure they don‚Äôt get re-ordered by the processor.</p><p>Prep code:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>core::ptr::write_volatile(vaddr as *mut u64, 0x12341337cafefeed); core::ptr::write_volatile((vaddr as *mut u64).offset(1), 0x1337133713371337); 
</span></span></code></pre></td></tr></table></div></div><p>Test code:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>let ptr = core::ptr::read_volatile(vaddr as *mut usize); core::ptr::read_volatile((vaddr as usize + (ptr &amp; 0x8)) as *mut usize); 
</span></span></code></pre></td></tr></table></div></div><p>In this code we set up 2 dependant loads. One which reads a value, and then another which masks the value to get the 8th bit, which is used as an offset to a subsequent access. Since the values are constants, we know that the second access will always access at offset 8, thus we expect to see a load of <code>0x1234...</code> followed by <code>0x1337...</code>.</p><h4 id=graphing-the-data>Graphing the data</h4><p>To graph the data we have collected, we want to collect the frequencies each value was seen for every cycle offset. We‚Äôll plot these with an x axis in cycles, and a y axis in frequency the value was observed at that cycle count. Then we‚Äôll overlay multiple graphs for the different values we‚Äôve seen. Let‚Äôs check it out in our simple case test code!</p><p><img src=https://gamozolabs.github.io/assets/leak_seq_example.png loading=lazy alt="Sequenced leak example data"><em>Sequenced leak example data</em></p><p>Here we also introduce a normal distribution best-fit for each value type, and a vertical line through the mean frequency-weighted value.</p><p>And look at that! We see the first access (in light blue) indicating that the value <code>0x12341337cafefeed</code> was read, and slightly after we see (in orange) the value <code>0x1337133713371337</code> was read! Exactly what we would have expected. How cool is that!? There‚Äôs some other noise on here from the testing harness, but they‚Äôre pretty easy to ignore in this case.</p><hr><h1 id=a-real-data-case>A real-data case</h1><p>Let‚Äôs put it all together and take a look at what a load looks like on pages which have not yet been marked as accessed.</p><p><img src=https://gamozolabs.github.io/assets/loadseq_example.png loading=lazy alt="Load sequence example"></p><p><em>Frequencies of observed values over time from load ports. Here we‚Äôre seeing the processor internally performing a microcode-assisted page table walk to update accessed and dirty bits. Only one load was performed by the user, these are all ‚Äúinvisible‚Äù loads done behind the scenes</em></p><p>Hmmm, this is a bit too noisy. Let‚Äôs re-collect the data but this time only look at the page table entry values and the value contained on the page we‚Äôre accessing.</p><p>Here are the page table entries for the memory we‚Äôre accessing in our example:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>CR3 0x630000 PML4E 0x2cc7c007 PDPE 0x2cc7b007 PDE 0x2cc7a007 PTE 0x13370003 Data 0x12341337cafefeed 
</span></span></code></pre></td></tr></table></div></div><p>We‚Äôre going to reset all page table entries to their non-dirty, non-accessed states, invalidate the TLB for the page via <code>invlpg</code>, and then read from the memory once. This will cause all accessed bits to be updated in the page tables! Here‚Äôs what we get‚Ä¶</p><p><img src=https://gamozolabs.github.io/assets/annotated_ucode_page_walk.png loading=lazy alt="Annotated ucode page walk"><em>Annotated ucode-assist page walk as observed with this technique</em></p><p>Here it‚Äôs hard to say why we see the 3rd and 4th levels of the page table get hit, as well as the page contents, prior to the accessed bit updates. Perhaps the processor tries the access first, and when it realizes the accessed bits are not set it goes through and sets them all. We can see fairly clearly that after this page data is read ~300 cycles in, that it performs a page-by-page walk through each level. Presumably this is where the processor is reading the original values from pages, <code>or</code>ing in the accessed bit, and moving to the next level!</p><hr><h1 id=speeding-it-up>Speeding it up</h1><p>So far using our 64-bit MLPDS leak we can get about 8,000 leaks per second. This is a decent data rate, but when we‚Äôre wanting to sample data and draw statistical significance, more is always better. For each different value we want to log, and for each cycle count, we likely want about ~100 points of data. So lets assume we want to sample 10 values over a 1000 cycle range, and we‚Äôll likely want 1 million data points. This means we‚Äôll need about 2 minutes worth of runtime to collect this data.</p><p>Luckily, there‚Äôs a relatively simple technique we can use to speed up the data rates. Instead of using the full arbitrary 64-bit leak for the whole test, we can use the arbitrary leak early on to determine the values of interest. We just want to use the arbitrary leak for long enough to determine the values which we know are accessed during our test case.</p><p>Once we know the values we actually want to leak, we can switch to using our known-value leak which allows for about 6 million leaks per second. Since this can only look for one value at a time, we‚Äôll also have to cycle through the values in our ‚Äúknown value‚Äù list, but the speedup is still worth it until the known value list gets incredibly large.</p><p>With this technique, collecting the 1 million data points for something with 5-6 values to sample only takes about a second. A speedup of two orders of magnitude! This is the technique that I‚Äôm currently using, although I have a fallback to arbitrary value mode if needed for some future use.</p><hr><h1 id=conclusion>Conclusion</h1><p>We introduced an interesting technique for monitoring Intel load port traffic cycle-by-cycle and demonstrated that it can be used to get meaningful data to learn how Intel micro-architecture works. While there is much more for us to poke around in, this was a simple example to show this technique!</p><h1 id=future>Future</h1><p>There is so much more I want to do with this work. First of all, this will just be polished in my toolbox and used for future CPU research. It‚Äôll just be a good go-to tool for when I need a little bit more introspection. But, I‚Äôm sure as time goes on I‚Äôll come up with new interesting things to monitor. Getting logging of store-port activity would be useful such that we could see the other side of memory transactions.</p><p>As with anything I do, performance is always an opportunity for improvement. Getting a higher-fidelity MLPDS exploit, potentially with higher throughput, would always help make collecting data easier. I‚Äôve also got some fun ideas for filtering this data to remove ‚Äúdeterministic noise‚Äù. Since we‚Äôre attacking from a sibling hyperthread I suspect we‚Äôd see some deterministic sliding and interleaving of core usage. If I could isolate these down and remove the noise that‚Äôd help a lot.</p><p>I hope you enjoyed this blog! See you next time!</p><hr><p>from Hacker News <a class=link href=https://ift.tt/36cQkJq target=_blank rel=noopener>https://ift.tt/36cQkJq</a></p></section><footer class=article-footer><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg><span>Licensed under CC BY-NC-SA 4.0</span></section></footer></article><footer class=site-footer><section class=copyright>&copy;
2020 -
2022 ZYChimne</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.11.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css integrity="sha256-c0uckgykQ9v5k+IqViZOZKc47Jn7KQil4/MP3ySA3F8=" crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.css integrity="sha256-SBLU4vv6CA6lHsZ1XyTdhyjJxCjPif/TRkjnsyGAGnE=" crossorigin=anonymous></main><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><ol><li><ol><li><a href=#performance-counter-monitoring>Performance Counter Monitoring</a></li></ol></li></ol></li></ol><ol><li><ol><li><ol><li><a href=#accessed-and-dirty-bits>Accessed and dirty bits</a></li></ol></li></ol></li></ol><ol><li><ol><li><ol><li><a href=#test>Test</a></li></ol></li></ol></li></ol><ol><li><ol><li><ol><li><a href=#a-trigger-point>A trigger point</a></li><li><a href=#uncontrolled-target-code>Uncontrolled target code</a></li><li><a href=#did-it-work>Did it work?</a></li><li><a href=#graphing-the-data>Graphing the data</a></li></ol></li></ol></li></ol></nav></div></section></aside></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.5/dist/vibrant.min.js integrity="sha256-5NovOZc4iwiAWTYIFiIM7DxKUXKWvpVEuMEPLzcm5/g=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script>
<script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>