<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Kang Asu
AVCLASS++ - Yet Another Massive Malware Labeling Tool
AVCLASS++ is an appealing complement toÂ AVCLASSÂ [1], a state-of-the-art malware labeling tool.
Overview
AVCLASS++ is a labeling tool for creating a malware dataset. Addressing malware threats requires constant efforts to create and maintain a dataset. Especially, labelingÂ malware samplesÂ is a vital part of shepherding a dataset. AVCLASS, a tool developed for this purpose, takes as inputÂ VirusTotalÂ reports and returns labels that aggregates scan results of multiple anti-viruses."><title>AVCLASS++</title><link rel=canonical href=https://Nexus-Security.github.io/posts/2016-09-09-avclass/><link rel=stylesheet href=/scss/style.min.7dbfdd4b0c439bdacf631096fda79b869b5850a9d35a3f67b9a557f3010f3972.css><meta property="og:title" content="AVCLASS++"><meta property="og:description" content="Kang Asu
AVCLASS++ - Yet Another Massive Malware Labeling Tool
AVCLASS++ is an appealing complement toÂ AVCLASSÂ [1], a state-of-the-art malware labeling tool.
Overview
AVCLASS++ is a labeling tool for creating a malware dataset. Addressing malware threats requires constant efforts to create and maintain a dataset. Especially, labelingÂ malware samplesÂ is a vital part of shepherding a dataset. AVCLASS, a tool developed for this purpose, takes as inputÂ VirusTotalÂ reports and returns labels that aggregates scan results of multiple anti-viruses."><meta property="og:url" content="https://Nexus-Security.github.io/posts/2016-09-09-avclass/"><meta property="og:site_name" content="0x000216"><meta property="og:type" content="article"><meta property="article:section" content="Posts"><meta property="article:published_time" content="2020-01-12T03:46:00+01:00"><meta property="article:modified_time" content="2020-01-12T03:46:00+01:00"><meta name=twitter:title content="AVCLASS++"><meta name=twitter:description content="Kang Asu
AVCLASS++ - Yet Another Massive Malware Labeling Tool
AVCLASS++ is an appealing complement toÂ AVCLASSÂ [1], a state-of-the-art malware labeling tool.
Overview
AVCLASS++ is a labeling tool for creating a malware dataset. Addressing malware threats requires constant efforts to create and maintain a dataset. Especially, labelingÂ malware samplesÂ is a vital part of shepherding a dataset. AVCLASS, a tool developed for this purpose, takes as inputÂ VirusTotalÂ reports and returns labels that aggregates scan results of multiple anti-viruses."></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hue825486955cd7c56d95e38b4bd2a8e3c_229979_300x0_resize_box_3.png width=300 height=300 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>0x000216</a></h1><h2 class=site-description>Where Do Russian Hackers Store Their Exploits? ðŸ¤“ /ussr/bin/ ðŸ˜‹</h2></div></header><ol class=social-menu><li><a href=https://github.com/Nexus-Security target=_blank title=GitHub><svg width="72" height="72" viewBox="0 0 72 72" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="M36 72c19.882251.0 36-16.117749 36-36 0-19.882251-16.117749-36-36-36-19.882251 365231026e-23-36 16.117749-36 36C24348735e-22 55.882251 16.117749 72 36 72z" fill="#3e75c3"/><path d="M35.9985 12C22.746 12 12 22.7870921 12 36.096644c0 10.6440272 6.876 19.6751861 16.4145 22.8617681C29.6145 59.1797862 30.0525 58.4358488 30.0525 57.7973276 30.0525 57.2250681 30.0315 55.7100863 30.0195 53.6996482c-6.6765 1.4562499-8.085-3.2302544-8.085-3.2302544-1.0905-2.7829884-2.664-3.5239139-2.664-3.5239139C17.091 45.4500754 19.4355 45.4801943 19.4355 45.4801943c2.4075.1701719 3.675 2.4833051 3.675 2.4833051 2.142 3.6820383 5.6175 2.6188404 6.9855 2.0014024C30.3135 48.4077535 30.9345 47.3460615 31.62 46.7436831 26.2905 46.1352808 20.688 44.0691228 20.688 34.8361671c0-2.6308879.9345-4.781379 2.4705-6.4665327C22.911 27.7597262 22.0875 25.3110578 23.3925 21.9934585c0 0 2.016-.6475568 6.6 2.4697516C31.908 23.9285993 33.96 23.6620468 36.0015 23.6515052 38.04 23.6620468 40.0935 23.9285993 42.0105 24.4632101c4.581-3.1173084 6.5925-2.4697516 6.5925-2.4697516C49.9125 25.3110578 49.089 27.7597262 48.8415 28.3696344 50.3805 30.0547881 51.309 32.2052792 51.309 34.8361671c0 9.2555448-5.6115 11.29309-10.9575 11.8894446.860999999999997.7439374 1.629 2.2137408 1.629 4.4621184C41.9805 54.4089489 41.9505 57.0067059 41.9505 57.7973276 41.9505 58.4418726 42.3825 59.1918338 43.6005 58.9554002 53.13 55.7627944 60 46.7376593 60 36.096644 60 22.7870921 49.254 12 35.9985 12" fill="#fff"/></g></svg></a></li><li><a href=mailto:0x000216@gmail.com target=_blank title=Email><svg id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 512 512" style="enable-background:new 0 0 512 512"><path style="fill:#e6f3ff" d="M512 105.739v300.522c0 27.715-22.372 50.087-50.087 50.087H50.087C22.372 456.348.0 433.976.0 406.261V105.739c0-.89.0-1.781.111-2.671 1.336-25.6 21.704-45.969 47.304-47.304.89-.111 1.781-.111 2.671-.111h411.826c.89.0 1.892.0 2.783.111 25.489 1.336 45.857 21.704 47.193 47.193C512 103.847 512 104.849 512 105.739z"/><path style="fill:#cfdbe6" d="M464.696 55.763c-.892-.111-1.891-.111-2.783-.111H256v400.696h205.913c27.715.0 50.087-22.372 50.087-50.087V105.739c0-.89.0-1.892-.111-2.783C510.553 77.468 490.184 57.099 464.696 55.763z"/><path style="fill:#ff4b26" d="M511.889 102.957c-1.336-25.489-21.704-45.857-47.193-47.193C382.89 137.569 336.951 183.509 256 264.459 225.291 233.732 77.61 85.958 47.416 55.763c-25.6 1.336-45.969 21.704-47.304 47.304C0 103.958.0 104.849.0 105.739v300.522c0 27.715 22.372 50.087 50.087 50.087h16.696V169.739l165.621 165.51c6.456 6.567 15.026 9.795 23.597 9.795 8.57.0 17.141-3.228 23.597-9.795l165.621-165.621v286.72h16.696c27.715.0 50.087-22.372 50.087-50.087V105.739C512 104.849 512 103.847 511.889 102.957z"/><path style="fill:#d93f21" d="M279.596 335.249l165.621-165.621v286.72h16.696c27.715.0 50.087-22.372 50.087-50.087V105.739c0-.89.0-1.892-.111-2.783-1.336-25.489-21.704-45.857-47.193-47.193C382.891 137.569 336.951 183.509 256 264.459v80.584C264.57 345.043 273.141 341.816 279.596 335.249z"/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/></svg></a></li><li><a href=https://www.buymeacoffee.com/0x000216 target=_blank title=RSS><svg id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 512 512" style="enable-background:new 0 0 512 512"><path style="fill:#f78c20" d="M78.333 355.334C35.14 355.334.0 390.474.0 433.667S35.14 512 78.333 512s78.333-35.14 78.333-78.333-35.14-78.333-78.333-78.333z"/><g><path style="fill:#ffa929" d="M78.333 381.445c-28.795.0-52.222 23.427-52.222 52.222s23.427 52.222 52.222 52.222 52.222-23.427 52.222-52.222-23.427-52.222-52.222-52.222z"/><path style="fill:#ffa929" d="M477.918 264.861c-21.843-51.641-53.111-98.019-92.936-137.842-39.824-39.824-86.201-71.093-137.843-92.935C193.669 11.468 136.874.0 78.333.0c-4.807.0-8.704 3.897-8.704 8.704v85.519c0 4.807 3.897 8.704 8.704 8.704 182.37.0 330.74 148.369 330.74 330.74.0 4.807 3.897 8.704 8.704 8.704h85.52c4.807.0 8.704-3.897 8.704-8.704C512 375.126 500.533 318.331 477.918 264.861z"/><path style="fill:#ffa929" d="M78.333 163.853c-4.807.0-8.704 3.897-8.704 8.704v95.74c0 4.807 3.897 8.704 8.704 8.704 86.386.0 156.666 70.281 156.666 156.666.0 4.807 3.897 8.704 8.704 8.704h95.74c4.807.0 8.704-3.897 8.704-8.704.0-72.07-28.065-139.826-79.027-190.787-50.961-50.961-118.717-79.027-190.787-79.027z"/></g><g><path style="fill:#f78c20" d="M78.333 242.186c-2.918.0-5.817.076-8.704.206v25.905c0 4.807 3.897 8.704 8.704 8.704 86.386.0 156.666 70.281 156.666 156.666.0 4.807 3.897 8.704 8.704 8.704h25.905c.129-2.886.206-5.786.206-8.704.0-105.752-85.729-191.481-191.481-191.481z"/><path style="fill:#f78c20" d="M78.333 68.113c-2.91.0-5.81.042-8.704.11v26.001c0 4.807 3.897 8.704 8.704 8.704 182.37.0 330.74 148.369 330.74 330.74.0 4.807 3.897 8.704 8.704 8.704h26.001c.067-2.894.11-5.793.11-8.704C443.887 231.777 280.223 68.113 78.333 68.113z"/></g><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/></svg></a></li><li><a href target=_blank title=Slack><svg width="256" height="256" viewBox="0 0 256 256" xmlns="http://www.w3.org/2000/svg" preserveAspectRatio="xMidYMid"><path d="M165.964 15.838c-3.89-11.975-16.752-18.528-28.725-14.636-11.975 3.89-18.528 16.752-14.636 28.725l58.947 181.365c4.048 11.187 16.132 17.473 27.732 14.135 12.1-3.483 19.475-16.334 15.614-28.217L165.964 15.838" fill="#dfa22f"/><path d="M74.626 45.516C70.734 33.542 57.873 26.989 45.9 30.879 33.924 34.77 27.37 47.631 31.263 59.606l58.948 181.366c4.047 11.186 16.132 17.473 27.732 14.132 12.099-3.481 19.474-16.332 15.613-28.217L74.626 45.516" fill="#3cb187"/><path d="M240.162 166.045c11.975-3.89 18.526-16.75 14.636-28.726-3.89-11.973-16.752-18.527-28.725-14.636L44.708 181.632c-11.187 4.046-17.473 16.13-14.135 27.73 3.483 12.099 16.334 19.475 28.217 15.614l181.372-58.93" fill="#ce1e5b"/><path d="M82.508 217.27l43.347-14.084-14.086-43.352-43.35 14.09 14.089 43.347" fill="#392538"/><path d="M173.847 187.591c16.388-5.323 31.62-10.273 43.348-14.084l-14.088-43.36-43.35 14.09 14.09 43.354" fill="#bb242a"/><path d="M210.484 74.706c11.974-3.89 18.527-16.751 14.637-28.727-3.89-11.973-16.752-18.526-28.727-14.636L15.028 90.293C3.842 94.337-2.445 106.422.896 118.022c3.481 12.098 16.332 19.474 28.217 15.613l181.371-58.93" fill="#72c5cd"/><path d="M52.822 125.933c11.805-3.836 27.025-8.782 43.354-14.086-5.323-16.39-10.273-31.622-14.084-43.352l-43.36 14.092 14.09 43.346" fill="#248c73"/><path d="M144.16 96.256l43.356-14.088a546179.21 546179.21.0 00-14.089-43.36L130.07 52.9l14.09 43.356" fill="#62803a"/></svg></a></li><li><a href=https://www.buymeacoffee.com/0x000216 target=_blank title=Minds><svg id="Capa_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 512 512" style="enable-background:new 0 0 512 512"><g><g><path style="fill:#ffe1b2" d="M256 33.085C245.078 13.38 224.079.0 2e2.0c-23.781.0-45.57 13.293-56.594 34.184C115.711 41.602 96 66.977 96 96c0 .059.0.113.0.172-9.977 7.512-16 19.301-16 31.828.0 1.316.078 2.637.234 3.992C60.211 145.266 48 167.758 48 192c0 14.07 4.039 27.543 11.719 39.262C57.273 236.512 56 242.207 56 248c0 2.738.281 5.445.828 8.098C36.672 267.308 24 288.539 24 312c0 27.973 18.305 52.34 44.109 60.785C65.398 378.828 64 385.324 64 392c0 21.098 13.805 39.508 33.539 45.727C103.891 466.746 129.828 488 160 488c4.617.0 9.227-.512 13.766-1.527C181.992 502 198.141 512 216 512c16.687.0 31.396-8.567 40-21.523V33.085z"/></g><g><g><path style="fill:#ffb980" d="M264 256c-4.422.0-8-3.582-8-8 0-22.055-17.945-40-40-40-8.008.0-15.734 2.355-22.336 6.812-3.023 2.043-7.055 1.781-9.797-.652-3.156-2.809-8.477-6.16-15.867-6.16-4.422.0-8-3.582-8-8s3.578-8 8-8c7.711.0 15.234 2.293 21.719 6.539C197.773 194.246 206.758 192 216 192c30.875.0 56 25.121 56 56C272 252.418 268.422 256 264 256z"/></g></g><g><g><path style="fill:#ffb980" d="M120 120c18.977.0 36.875 7.312 50.414 20.594 3.141 3.09 8.203 3.047 11.312-.109 3.094-3.152 3.047-8.219-.109-11.312C165.07 112.941 143.187 104 120 104c-13.046.0-25.395 2.93-36.542 8.046C81.253 117.019 80 122.423 80 128c0 1.316.078 2.637.234 3.992-.094.062-.173.139-.267.202C91.423 124.501 105.193 120 120 120z"/></g></g><g><g><path style="fill:#ffb980" d="M216 360c0-4.418-3.578-8-8-8s-8 3.582-8 8c0 17.645-14.352 32-32 32-14.211.0-26.82-9.648-30.664-23.465-.703-2.512-2.578-4.523-5.039-5.395-2.453-.871-5.188-.492-7.305 1.02C114.094 371.906 101.305 376 88 376c-6.948.0-13.625-1.149-19.894-3.207-2.214 4.939-3.501 10.19-3.916 15.586C71.714 390.73 79.711 392 88 392c13.297.0 26.187-3.266 37.773-9.52C133.969 397.894 150.141 408 168 408c26.469.0 48-21.531 48-48z"/></g></g><g><path style="fill:#fdc88e" d="M488 312c0-23.461-12.672-44.691-32.828-55.902.547-2.652.828-5.359.828-8.098.0-5.793-1.273-11.488-3.719-16.738C459.961 219.543 464 206.07 464 192c0-24.242-12.211-46.734-32.234-60.008.156-1.355.234-2.676.234-3.992.0-12.527-6.023-24.316-16-31.828.0-.059.0-.113.0-.172.0-29.023-19.711-54.398-47.406-61.816C357.57 13.293 335.781.0 312 0c-24.08.0-45.078 13.38-56 33.085v457.391C264.604 503.433 279.313 512 296 512c17.859.0 34.008-10 42.234-25.527C342.773 487.488 347.383 488 352 488c30.172.0 56.109-21.254 62.461-50.273C434.195 431.508 448 413.097 448 392c0-6.676-1.398-13.172-4.109-19.215C469.695 364.34 488 339.973 488 312z"/></g><g><path style="fill:#f8ab6b" d="M272.008 151.199C272 151.465 272 151.734 272 152c0 26.469 21.531 48 48 48s48-21.531 48-48c0-4.418-3.578-8-8-8s-8 3.582-8 8c0 17.645-14.352 32-32 32s-32-14.355-32-32c0-2.184.219-4.359.656-6.465.492-2.395-.133-4.883-1.703-6.754-1.57-1.871-4.016-3.066-6.352-2.859-.453.012-.891.059-.602.078-13.234.0-24-10.766-24-24v31.813C260.673 147.348 266.061 149.988 272.008 151.199z"/></g><g><path style="fill:#f8ab6b" d="M296 328c9.242.0 18.219-2.246 26.281-6.539C328.765 325.707 336.289 328 344 328c4.422.0 8-3.582 8-8s-3.578-8-8-8c-7.391.0-12.711-3.352-15.867-6.16-2.742-2.434-6.766-2.695-9.797-.656C311.726 309.644 304 312 296 312c-22.055.0-40-17.945-40-40v39.116C266.174 321.517 280.337 328 296 328z"/></g><g><g><path style="fill:#f8ab6b" d="M431.765 131.992c.156-1.355.234-2.676.234-3.992.0-5.577-1.253-10.981-3.458-15.954C417.395 106.93 405.046 104 392 104c-4.422.0-8 3.582-8 8s3.578 8 8 8c14.807.0 28.577 4.501 40.032 12.194C431.939 132.131 431.859 132.054 431.765 131.992z"/></g></g><g><g><path style="fill:#f8ab6b" d="M447.81 388.38c-.415-5.396-1.702-10.647-3.916-15.586C437.624 374.85 430.948 376 424 376c-13.578.0-26.594-4.266-37.641-12.332-2.07-1.5-4.719-1.93-7.133-1.168-2.43.77-4.344 2.648-5.164 5.059C369.101 382.176 355.414 392 340 392c-4.422.0-8 3.582-8 8s3.578 8 8 8c18.875.0 35.961-10.191 45.094-26.156C396.976 388.512 410.258 392 424 392 432.288 392 440.285 390.73 447.81 388.38z"/></g></g></g><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/></svg></a></li><li><a href=https://www.buymeacoffee.com/0x000216 target=_blank title=Coffee><svg id="Capa_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 340 340" style="enable-background:new 0 0 340 340"><g id="XMLID_18_"><polygon id="XMLID_138_" style="fill:#dedde0" points="76.429,290 80,340 170,340 170,290"/><polygon id="XMLID_169_" style="fill:#dedde0" points="170,80 61.429,80 65,130 170,130"/><polygon id="XMLID_197_" style="fill:#acabb1" points="170,290 170,340 260,340 263.571,290"/><polygon id="XMLID_221_" style="fill:#acabb1" points="170,80 170,130 275,130 278.571,80"/><path id="XMLID_222_" style="fill:#ffda44" d="M170 260c-22.091.0-40-22.386-40-50s17.909-50 40-50v-30H65 50l10 160h16.429H170V260z"/><path id="XMLID_33_" style="fill:#ff9811" d="M170 130v30c22.091.0 40 22.386 40 50s-17.909 50-40 50v30h93.571H280l10-160h-15H170z"/><path id="XMLID_223_" style="fill:#50412e" d="M210 210c0-27.614-17.909-50-40-50v1e2c22.091.0 40-22.386 40-50z"/><path id="XMLID_224_" style="fill:#786145" d="M130 210c0 27.614 17.909 50 40 50V160c-22.091.0-40 22.386-40 50z"/><polygon id="XMLID_225_" style="fill:#50412e" points="278.571,80 300,80 300,40 260,40 260,0 80,0 80,40 40,40 40,80 61.429,80 170,80"/></g><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg><span>Home</span></a></li><li><a href=/about/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg><span>About Us</span></a></li><li><a href=/termsofservice/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-pencil" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 20h4L18.5 9.5a1.5 1.5.0 00-4-4L4 16v4"/><line x1="13.5" y1="6.5" x2="17.5" y2="10.5"/></svg><span>Terms Of Service</span></a></li><li><a href=/privacypolicy/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg><span>Privacy Policy</span></a></li><li><a href=/disclaimer/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg><span>Disclaimer</span></a></li><div class=menu-bottom-section><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><span>Dark Mode</span></li></div></ol></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><div class=article-title-wrapper><h2 class=article-title><a href=/posts/2016-09-09-avclass/>AVCLASS++</a></h2></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg><time class=article-time--published>Jan 12, 2020</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><time class=article-time--reading>17 minute read</time></div></footer></div></header><section class=article-content><p><strong>Kang Asu</strong></p><p><a class=link href=https://1.bp.blogspot.com/-atM8FSBrtEk/XgJ-JrwfVII/AAAAAAAARSw/Z7TmdZp3fbYdreYGgynv3zA1EkQmBIY3ACNcBGAsYHQ/s1600/malware.jpeg target=_blank rel=noopener><img src=https://1.bp.blogspot.com/-atM8FSBrtEk/XgJ-JrwfVII/AAAAAAAARSw/Z7TmdZp3fbYdreYGgynv3zA1EkQmBIY3ACNcBGAsYHQ/s640/malware.jpeg loading=lazy></a></p><p><strong>AVCLASS++ - Yet Another Massive Malware Labeling Tool</strong></p><p>AVCLASS++ is an appealing complement toÂ <a class=link href=https://github.com/malicialab/avclass title=AVCLASS target=_blank rel=noopener>AVCLASS</a>Â [1], a state-of-the-art malware labeling tool.</p><p><strong>Overview</strong><br>AVCLASS++ is a labeling tool for creating a malware dataset. Addressing malware threats requires constant efforts to create and maintain a dataset. Especially, labelingÂ <a class=link href=https://www.kitploit.com/search/label/Malware%20Samples title="malware samples" target=_blank rel=noopener>malware samples</a>Â is a vital part of shepherding a dataset. AVCLASS, a tool developed for this purpose, takes as inputÂ <a class=link href=https://www.kitploit.com/search/label/VirusTotal title=VirusTotal target=_blank rel=noopener>VirusTotal</a>Â reports and returns labels that aggregates scan results of multiple anti-viruses. And now, AVCLASS++ is shipped with the brand-new capacities!<br>In a nutshell, AVCLASS++ enables the following operation:</p><ul><li>Input:<ul><li>VirusTotal report(s)</li><li>Malware binar(y|ies) (optional)</li></ul></li><li>Output:<ul><li>Malware label(s) (family name)</li></ul></li></ul><p><strong>Features</strong><br>AVCLASS++ is developed for freeing you from the task of worrying about what families malware samples are. The salient features of AVCLASS++ are as follows:</p><ul><li><em>Automatic.</em>Â AVCLASS++ removes manual analysis limitations on the size of the input dataset.</li><li><em>Vendor-agnostic.</em>Â AVCLASS++ operates on the labels of any available set of AV engines, which can vary from sample to sample.</li><li><em>Cross-platform.</em>Â AVCLASS++ can be used for any platforms supported by AV engines, e.g., Windows or Android malware.</li><li><em>Does not require executables.</em>Â AV labels can be obtained from online services like VirusTotal using a sample&rsquo;s hash, even when the executable is not available.Â <em>Yet, AVCLASS++ has also a potential that can improve label accuracy if there is an executable.</em></li><li><em>Quantified accuracy.</em>Â The original AVCLASS had evaluated [1] on five publicly available malware datasets with ground truth.Â <em>AVCLASS++ is further tuned to perform under adverse conditions.</em></li><li><em>Open source.</em>Â We are happy to release AVCLASS++ to the community. Prithee, use it for the further development of prompt security operation and reproducible security research!</li></ul><p><strong>Step Forward</strong><br>The following limitation was pointed out in the original AVCLASS paper:</p><blockquote><p>Â The main limitation of AVClass is that its output depends on the input AV labels. It tries to compensate for the noise on those labels, but cannot identify the family of a sample if AV engines do not provide non-generic family names to that sample. In particular, it cannot label samples if at least 2 AV engines do not agree on a non-generic family name. Results on 8 million samples showed that AVClass could label 81% of the samples. In other words, it could not label 19% of the samples because their labels contained only generic tokens.</p></blockquote><p>We have organized such pitfalls into two factors.</p><ul><li><em>First,</em>Â AVCLASS is prone to fail labeling samples that have just been posted to VirusTotal because only a few anti-viruses give labels to such samples. Such a sample will be labeled SINGLETON.Â <em>An inconvenient truth: when we provided AVCLASS with 20,000 VirusTotal reports, half of them were labeled SINGLETON.</em></li><li><em>Second,</em>Â AVCLASS cannot determine if the label is randomly generated (as with domain generation algorithms of malware) or not. Some anti-viruses that VirusTotal has worked with after AVCLASS released were labeled with the DGA, resulting in a biased label.</li></ul><p>Because of them, we are forced to make a lot of manual, tedious intervention in malware labeling; otherwise, we need to drop samples with inconsistent labels from the dataset; since there was no alternative.<br>For the reason, AVCLASS++ is designed to address these drawbacks by arming with the following:</p><ul><li><em>Label propagation.</em>Â AVCLASS++ accepts not only VirusTotal reports but also binary executable files of samples as input, and measures the similarity between them, thereby propagating [3] a malware label to the one labeled SINGLETON. Here, AVCLASS++ exploits hashed features based on various perspective [4] e.g, byte histogram, printable strings, file size, PE headers, sections, imports, exports, and more! Then it calculates the similarity of the samples through deriving an affinity matrix and re-labels SINGLETONs as a result of the propagation from a similar sample. This enables us to reduce SINGLETONs.</li><li><em>DGA detection.</em>Â AVCLASS++ determines if labels were generated by DGA and removes such ones from the candidates. This technique is based on the meaningful characters ratio and $N$-gram normality score [5]. In other words, AVCLASS + + verifies that the label presented by AV is meaningful and easy to pronounce, and then determines if the label is generated by DGA. This enables us to unbiased labeling.</li></ul><p>Besides, unlike AVCLASS, AVCLASS++ is Python 3 compatible!</p><p><strong>How To Use</strong></p><p><strong>Installation</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>git clone git@github.com:malrev/avclassplusplus.git  
</span></span><span class=line><span class=cl>./setup.sh
</span></span></code></pre></td></tr></table></div></div><p><strong>Labeling</strong><br>The labeler takes as input a JSON file with the AV labels of malware samples (<code>-vt</code>Â orÂ <code>-lb</code>Â switches), a file with generic tokens (<code>-gen</code>Â switch), and a file with aliases (<code>-alias</code>Â switch). It outputs the most likely family name for each sample. If you do not provide alias or generic tokens files, the default ones in theÂ <em>data</em>Â folder are used.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>python avclass_labeler.py -lb data/malheurReference_lb.json -v &gt; malheurReference.labels
</span></span></code></pre></td></tr></table></div></div><p>The above command labels the samples whose AV labels are in theÂ <em><code>data/malheurReference_lb.json</code></em>Â file. It prints the results to stdout, which we redirect to theÂ <em><code>malheurReference.labels</code></em>Â file. The output looks like this:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>aca2d12934935b070df8f50e06a20539 adrotator  
</span></span><span class=line><span class=cl>67d15459e1f85898851148511c86d88d adultbrowser
</span></span></code></pre></td></tr></table></div></div><p>which means sample aca2d12934935b070df8f50e06a20539 is most likely from theÂ <em>adrotator</em>Â family and 67d15459e1f85898851148511c86d88d from theÂ <em>adultbrowser</em>Â family.<br>The verbose (<code>-v</code>) switch makes it output an extraÂ <em><code>malheurReference_lb.verbose</code></em>Â file with all families extracted for each sample ranked by the number of AV engines that use that family. The file looks like this:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>aca2d12934935b070df8f50e06a20539  [(&#39;adrotator&#39;, 8), (&#39;zlob&#39;, 2)]  
</span></span><span class=line><span class=cl>ee90a64fcfaa54a314a7b5bfe9b57357  [(&#39;swizzor&#39;, 19)]  
</span></span><span class=line><span class=cl>f465a2c1b852373c72a1ccd161fbe94c  SINGLETON:f465a2c1b852373c72a1ccd161fbe94c
</span></span></code></pre></td></tr></table></div></div><p>which means that for sample aca2d12934935b070df8f50e06a20539 there are 8 AV engines assigningÂ <em>adrotator</em>Â as the family and another 2 assigningÂ <em>zlob</em>. Thus,Â <em>adrotator</em>Â is the most likely family. On the other hand, for ee90a64fcfaa54a314a7b5bfe9b57357 there are 19 AV engines assigningÂ <em>swizzor</em>Â as family, and no other family was found. The last line means that for sample f465a2c1b852373c72a1ccd161fbe94c no family name was found in the AV labels. Thus, the sample is placed by himself in a singleton cluster with the name of the cluster being the sample&rsquo;s hash.<br>Note that the sum of the number of AV engines may not equal the number of AV engines with a label for that sample in the input file because the labels of some AV engines may only include generic tokens that are removed by AVCLASS++.Â <em>In such a case, the propagater described later comes to rescue.</em></p><p><strong>Input JSON Format</strong><br>AVCLASS++ supports two input JSON formats:</p><ol><li>VirusTotal JSON reports (<em><code>-vt</code>Â file</em>), where each line inÂ <em>file</em>Â should be the full JSON of a VirusTotal report as fetched through the VirusTotal API.</li><li>Simplified JSON (<em><code>-lb</code>Â file</em>), where each line inÂ <em>file</em>Â should be a JSON with (at least) these fields:Â <code>{md5, sha1, sha256, scan_date, av_labels}</code>. There is an example of such input file inÂ <em><code>data/malheurReference_lb.json</code></em>Â This option works well if you want to use label candidates from a source other than VirusTotal or from a self-made engine.</li></ol><p>AVCLASS++ can handle multiple input files putting the results in the same output files (if you want results in separate files, process each input file separately).<br>You can provide theÂ <code>-vt</code>Â andÂ <code>-lb</code>Â input options multiple times.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>python avclass_labeler.py -vt  -vt  &gt; all.labels
</span></span></code></pre></td></tr></table></div></div><p>python avclass_labeler.py -lb -lb > all.labels</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>There are alsoÂ `-vtdir`Â andÂ `-lbdir`Â options that can be used to provide an input directory where all files are VT (`-vtdir`) or simplified (`-lbdir`) JSON reports.
</span></span></code></pre></td></tr></table></div></div><p>python avclass_labeler.py -vtdir > all.labels</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>You can also combineÂ `-vt`Â withÂ `-vtdir`Â andÂ `-lb`Â withÂ `-lbdir`, but you cannot combine input files of different format. Thus, this command works:
</span></span></code></pre></td></tr></table></div></div><p>python avclass_labeler.py -vt -vtdir > all.labels</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>But, this one throws an error:
</span></span></code></pre></td></tr></table></div></div><p>python avclass_labeler.py -vt -lb > all.labels</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>At this point you have read the most important information on how to use AVCLASS++. The following sections describe optional steps.  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>**Label Propagation**  
</span></span><span class=line><span class=cl>When a sample has just been uploaded to VirusTotal, the original AVCLASS often gives you a SINGLETON label because of the lack of AVs signatures. In such a case, we usually try to disassemble and execute the sample, compare the results to past ones, and then give it the appropriate label.  
</span></span><span class=line><span class=cl>Therefore, We introduce a function that automates this task. AVCLASS++ retrieves and compares byte histogram, printable strings, file size, PE headers, sections, imports, exports, and so on from the given executable files. Then, it gives the label to SINGLETONs from similar samples. An affinity matrix is derived to compute the similarities here. For label propagation, literally the label propagation algorithm \[3\] is used.  
</span></span><span class=line><span class=cl>To use this function, run the following command:
</span></span></code></pre></td></tr></table></div></div><p>python avclass_propagator.py -labels -sampledir -results</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>The input file passed withÂ `-labels`Â must be created in advance byÂ `avclass_labeler.py`Â in advance. The directory passed withÂ `-sampledir`Â must contain samples with the hash values contained in the labels file. The optionÂ `-results`Â is optional. By default, the propagator createsÂ `_pr.labels`Â file based on aÂ `.labels`Â file passed as an argument. AVCLASS++ overwrites only SINGLETON labels with predicted labels by default. You can overwrite all original labels with predicted labels by enabling theÂ `-force`Â option. In addition, you can automatically optimize hyperparameter values by enablingÂ `-opt`.
</span></span></code></pre></td></tr></table></div></div><p>python avclass_propagator.py -labels input.labels -sampledir samples -results output.labels -opt</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>This feature is contrary to the original AVCLASS manner of &#34;does not require executables&#34;, but it is really helpful in practice.  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>**DGA Detection**  
</span></span><span class=line><span class=cl>AVs such as BitDefender, AegisLab, Emsisoft, eScan, GData, Ad-Aware, MAX, K7Antivirus, K7GW, Cybereason, and Cyren will output pseudo-randomly generated labels in a similar vein as DGA of malware. You can see an example at VirusTotal:Â [f315be41d9765d69ad60f0b4d29e4300](https://www.virustotal.com/gui/file/d216c14c218251c3e9e25a8041f5011e9fbd9fc6212a9592ba99d8ed6435a535/detection &#34;f315be41d9765d69ad60f0b4d29e4300&#34;). This leads the original AVCLASS would be confused.  
</span></span><span class=line><span class=cl>Therefore, we present a function that removes the label that seems to be generated by DGA. To this end, we employ the following heuristics \[5\]:
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>*   Meaningful characters ratio. This score indicates how many meaningful words within a label (the higher the better). Specifically, we split the label string $p$ into $k$ subwords $|w\_i| â‰¥ 3$, then compute $R(p) = max(\\frac{(\\sum\_{i=1 \\in k}) |w\_{i}|)}{|p|}$.
</span></span><span class=line><span class=cl>*   $N$-gram normality score. This score indicates how many words which are easy to pronounce within a label (the higher the better). Specifically, we compute $N$-gram $t$ of the label string $p$, count the occurrence $count(t)$ in the dictionary, and calculate the average of them. That is, $S\_n(p) = \\frac{\\sum\_{n-gram;t \\in p} count(t)}{|p|-n+1}$ where $N$ is given. From our experience, we highly recommend setting $N &gt; 3$.
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>The key insight of these scores is that the appropriate label contains a string that is meaningful and easy to pronounce. AVCLASS++ calculates a harmonic mean of these scores and determine if the label is generated by DGA based on a threshold. This function is enabled by default now, but you can configure it with:
</span></span></code></pre></td></tr></table></div></div><p>python avclass_labeler.py -vtdir -dgadetect > all.labels</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>An example is below:
</span></span></code></pre></td></tr></table></div></div><p>python avclass_labeler.py -vtdir -dgadetect data/top10000en.txt 4 2 > all.labels</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>**Family Ranking**  
</span></span><span class=line><span class=cl>AVCLASS++ has aÂ `-fam`Â switch to output a file with a ranking of the families assigned to the input samples.
</span></span></code></pre></td></tr></table></div></div><p>python avclass_labeler.py -lb data/malheurReference_lb.json -v -fam > malheurReference.labels</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>This will produce a file calledÂ _`malheurReference_lb.families`_Â with two columns:
</span></span></code></pre></td></tr></table></div></div><p>virut 441<br>allaple 301<br>podnuha 300</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>The file indicates that 441 samples were classified in the virut family, 301 as allaple, and 300 as podnuha.  
</span></span><span class=line><span class=cl>This switch is very similar to using the following shell command:
</span></span></code></pre></td></tr></table></div></div><p>cut -f 2 malheurReference.labels | sort | uniq -c | sort -nr</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>The main difference is that using theÂ `-fam`Â switch all SINGLETON samples, i.e., those for which no label was found, are grouped into a fakeÂ _SINGLETONS_Â family, while the shell command would leave each singleton as a separate family.  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>**PUP Classification**  
</span></span><span class=line><span class=cl>AVCLASS++ also has aÂ `-pup`Â switch to classify a sample as Potentially Unwanted Program (PUP) or malware. This classification looks for PUP-related keywords (e.g., pup, pua, unwanted, adware) in the AV labels.
</span></span></code></pre></td></tr></table></div></div><p>python avclass_labeler.py -lb data/malheurReference_lb.json -v -pup > malheurReference.labels</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>With theÂ `-pup`Â switch the output of theÂ _`malheurReference.labels`_Â file looks like this:
</span></span></code></pre></td></tr></table></div></div><p>aca2d12934935b070df8f50e06a20539 adrotator 1<br>67d15459e1f85898851148511c86d88d adultbrowser 0</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>The digit at the end is a Boolean flag that indicates sample aca2d12934935b070df8f50e06a20539 is (likely) PUP, but sample 67d15459e1f85898851148511c86d88d is (likely) not.Â _This enables us to focus on PUP research \[2\] or non-PUP research!_  
</span></span><span class=line><span class=cl>The PUP classification tends to be conservative, i.e., if it says the sample is PUP, it most likely is. But, if it says that it is not PUP, it could still be PUP if the AV labels do not contain PUP-related keywords. Note that it is possible that some samples from a family get the PUP flag while other samples from the same family do not because the PUP-related keywords may not appear in the labels of all samples from the same family. To address this issue, you can combine theÂ `-pup`Â switch with theÂ `-fam`Â switch. This combination will add into the families file the classification of the family as malware or PUP, based on a majority vote among the samples in a family.
</span></span></code></pre></td></tr></table></div></div><p>python avclass_labeler.py -lb data/malheurReference_lb.json -v -pup -fam > malheurReference.labels</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>This will produce a file calledÂ _malheurReference\_lb.families_Â with five columns:
</span></span></code></pre></td></tr></table></div></div><h1 id=family--total-malware-pup-famtype>Family Total Malware PUP FamType</h1><p>virut 441 441 0 malware<br>magiccasino 173 0 173 pup<br>ejik 168 124 44 malware</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>For virut, the numbers indicate all the 441 virut samples are classified as malware, and thus the last column states that virut is a malware family. For magiccasino, all 173 samples are labeled as PUP, thus the family is PUP. For ejik, out of the 168 samples, 124 are labeled as malware and 44 as PUP, so the family is classified as malware.  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>**Ground Truth Evaluation**  
</span></span><span class=line><span class=cl>If you have ground truth for some malware samples, i.e., you know the true family for those samples, you can evaluate the accuracy of the labeling output by AVCLASS++ on those samples with respect to that ground truth. The evaluation metrics used are precision, recall, and F1 measure.
</span></span></code></pre></td></tr></table></div></div><p>python avclass_labeler.py -lb data/malheurReference_lb.json -v -gt data/malheurReference_gt.tsv -eval > data/malheurReference.labels</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>The output includes these lines:
</span></span></code></pre></td></tr></table></div></div><p>Calculating precision and recall<br>3131 out of 3131<br>Precision: 90.81 Recall: 93.95 F1-Measure: 92.35</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>The last line corresponds to the accuracy metrics obtained by comparing AVClass results with the provided ground truth.  
</span></span><span class=line><span class=cl>Each line in theÂ _`data/malheurReference_gt.tsv`_Â file has twoÂ **tab-separated**Â columns:
</span></span></code></pre></td></tr></table></div></div><p>0058780b175c3ce5e244f595951f611b8a24bee2 CASINO</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>This sample 0058780b175c3ce5e244f595951f611b8a24bee2 is known to be of theÂ _CASINO_Â family. Each sample in the input file should also appear in the ground truth file. Note that the particular label assigned to each family does not matter. What matters is that all samples in the same family are assigned the same family name (i.e., the same string in the second column)  
</span></span><span class=line><span class=cl>The ground truth can be obtained from publicly available malware datasets. The one inÂ _`data/malheurReference_gt.tsv`_Â comes from theÂ [Malheur](http://www.mlsec.org/malheur/ &#34;Malheur&#34;)Â dataset. There are other public datasets with ground truth such asÂ [Drebin](https://www.sec.cs.tu-bs.de/~danarp/drebin/ &#34;Drebin&#34;)Â andÂ [Malicia](http://malicia-project.com/dataset.html &#34;Malicia&#34;).  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>**Preparation**  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>**Generic Token Detection**  
</span></span><span class=line><span class=cl>The labeling takes as input a file with generic tokens that should be ignored in the AV labels, e.g., trojan, virus, generic, linux. By default, the labeling uses theÂ _`data/default.generics`_Â generic tokens file. You can edit that file to add additional generic tokens you feel we are missing.  
</span></span><span class=line><span class=cl>In the original AVCLASS paper \[1\] presents an automatic approach to identify generic tokens, whichÂ **requires ground truth**, i.e., it requires knowing the true family for each input sample. Not only that, butÂ **the ground truth should be large**, i.e., contain at least one hundred thousand samples. In the evaluation, AVCLASS identified generic tokens using as ground truth the concatenation of all datasets for which we had ground truth. This requirement of a large ground truth dataset is why we expect most users will skip this step and simply use our provided default file.
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>If you want to test generic token detection you can do:
</span></span></code></pre></td></tr></table></div></div><p>python avclass_generic_detect.py -lb data/malheurReference_lb.json -gt data/malheurReference_gt.tsv -tgen 10 > malheurReference.gen</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Each line in theÂ _data/malheurReference\_gt.tsv_Â file has twoÂ **tab-separated**Â columns:
</span></span></code></pre></td></tr></table></div></div><p>0058780b175c3ce5e244f595951f611b8a24bee2 CASINO</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>which indicates that sample 0058780b175c3ce5e244f595951f611b8a24bee2 is known to be of theÂ _CASINO_Â family.  
</span></span><span class=line><span class=cl>TheÂ _`-tgen 10`_Â switch is a threshold for the minimum number of families where a token has to be observed to be considered generic. If the switch is ommitted, the default threshold of 8 is used.  
</span></span><span class=line><span class=cl>The above command outputs two files:Â _`malheurReference.gen`_Â andÂ _`malheurReference_lb.gen`_. Each of them has 2 columns: token and number of families where the token was observed. FileÂ _`malheurReference.gen`_Â is the final output with the detected generic tokens for which the number of families is above the given threshold. The fileÂ _`malheurReference_lb.gen`_Â has this information for all tokens. Thus,Â _`malheurReference.gen`_Â is a subset ofÂ _`malheurReference_lb.gen`_.  
</span></span><span class=line><span class=cl>However, note that in the above command you are trying to identify generic tokens from a small dataset since Drebin only contains 3K labeled samples. Thus,Â _`malheurReference.gen`_Â only contains 25 identified generic tokens. Using those 25 generic tokens will produce significantly worse results than using the generic tokens inÂ _`data/default.generics`_.  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>**Alias Detection**  
</span></span><span class=line><span class=cl>Different vendors may assign different names (i.e., aliases) for the same family. For example, some vendors may useÂ _zeus_Â and othersÂ _zbot_Â as aliases for the same malware family. The labeling takes as input a file with aliases that should be merged. By default, the labeling uses theÂ _data/default.aliases_Â aliases file. You can edit that file to add additional aliases you feel we are missing.  
</span></span><span class=line><span class=cl>In the original AVCLASS paper \[1\] describes an automatic approach to identify aliases. Note that the alias detection approachÂ **requires as input the AV labels for large set of samples**, e.g., several million samples. In contrast with the generic token detection, the input samples for alias detectionÂ **do not need to be labeled**, i.e., no need to know their family. In the evaluation, AVCLASS identified aliases using as input the largest of unlabeled datasets, which contained nearly 8M samples. This requirement of a large input dataset is why we expect most users will skip this step and simply use our provided default file.  
</span></span><span class=line><span class=cl>If you want to test alias detection you can do:
</span></span></code></pre></td></tr></table></div></div><p>python avclass_alias_detect.py -lb data/malheurReference_lb.json -nalias 100 -talias 0.98 > malheurReference.aliases</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>TheÂ `-nalias`Â threshold provides the minimum number of samples two tokens need to be observed in to be considered aliases. If the switch is not provided the default is 20.  
</span></span><span class=line><span class=cl>TheÂ `-talias`Â threshold provides the minimum fraction of times that the samples appear together. If the switch is not provided the default is 0.94 (94%).
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>The above command outputs two files:Â _`malheurReference.aliases`_Â andÂ _`malheurReference_lb.alias`_. Each of them has 6 columns:
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>1.  t1: token that is an alias
</span></span><span class=line><span class=cl>2.  t2: family for which t1 is an alias
</span></span><span class=line><span class=cl>3.  |t1|: number of input samples where t1 was observed
</span></span><span class=line><span class=cl>4.  |t2|: number of input samples where t2 was observed
</span></span><span class=line><span class=cl>5.  |t1^t2|: number of input samples where both t1 and t2 were observed
</span></span><span class=line><span class=cl>6.  |t1^t2|/|t1|: ratio of input samples where both t1 and t2
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>These were observed over the number of input samples where t1 was observed.  
</span></span><span class=line><span class=cl>FileÂ _`malheurReference.aliases`_Â is the final output with the detected aliases that satisfy the -nalias and -talias thresholds. The fileÂ _`malheurReference_lb.alias`_Â has this information for all tokens. Thus,Â _`malheurReference.aliases`_Â is a subset ofÂ _`malheurReference_lb.alias`_.  
</span></span><span class=line><span class=cl>However, note that in the above command you are trying to identify aliases from a small dataset since Drebin only contains 3K samples. Thus,Â _`malheurReference.aliases`_Â only contains 6 identified aliases. Using those 6 aliases will produce significantly worse results than using the aliases inÂ _`data/default.aliases`_. As mentioned, to improve the identified aliases you should provide as input several million samples.  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>**Acknowledgment**  
</span></span><span class=line><span class=cl>We deeply respect original authors of AVCLASS. Reference with love:
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>*   \[1\] Marcos SebastiÃ¡n, Richard Rivera, Platon Kotzias, and Juan Caballero. 2016. AVCLASS: A tool for Massive Malware Labeling. InÂ _Proceedings of the 19th International Symposium on Research in Attacks, Intrusions and Defenses (RAID&#39;16)._Â 230--253.Â **(If you wish to cite the original AVCLASS, please cite this paper; if you wish to cite AVCLASS++, just refer to this repository URL)**
</span></span><span class=line><span class=cl>*   \[2\] Platon Kotzias, Srdjan Matic, Richard Rivera, and Juan Caballero. 2015. Certified PUP: Abuse in Authenticode Code Signing. InÂ _Proceedings of the 22nd ACM Conference on Computer and Communication Security (CCS&#39;15)._Â 465--478.
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>The techniques introduced in AVCLASS++ are based on the following papers:
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>*   \[3\] Xiaojin Zhu and Zoubin Ghahramani. 2002. Learning from Labeled and Unlabeled Data with Label Propagation.Â _Technical Report CMU-CALD-02-107, Carnegie Mellon University._
</span></span><span class=line><span class=cl>*   \[4\] Hyrum S. Anderson and Phil Roth. 2018. EMBER: An Open Dataset for Training Static PE MalwareÂ [Machine Learning](https://www.kitploit.com/search/label/Machine%20Learning &#34;Machine Learning&#34;)Â Models.Â _CoRR, abs/1804.04637._
</span></span><span class=line><span class=cl>*   \[5\] Stefano Schiavoni, Federico Maggi, Lorenzo Cavallaro, and Stefano Zanero. 2014. Phoenix: DGA-Based Botnet Tracking and Intelligence. InÂ _Proceeding of the 11th Conference on Detection of Intrusions and Malware &amp;Â [Vulnerability Assessment](https://www.kitploit.com/search/label/Vulnerability%20Assessment &#34;Vulnerability Assessment&#34;)Â (DIMVA&#39;14)._Â 192--211.
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>**[Download Avclassplusplus](http://triabicia.com/3GsL &#34;Download Avclassplusplus&#34;)**
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>**Regards**
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>**Kang Asu**
</span></span></code></pre></td></tr></table></div></div></section><footer class=article-footer><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg><span>Licensed under CC BY-NC-SA 4.0</span></section></footer></article><footer class=site-footer><section class=copyright>&copy;
2020 -
2022 0x000216</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.11.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section><script data-name=BMC-Widget src=https://cdn.buymeacoffee.com/widget/1.0.0/prod/widget.prod.min.js data-id=0x000216 data-description=coffee! data-message=coffee! data-color=#FF813F data-position=right data-x_margin=28 data-y_margin=18></script></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css integrity="sha256-c0uckgykQ9v5k+IqViZOZKc47Jn7KQil4/MP3ySA3F8=" crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.css integrity="sha256-SBLU4vv6CA6lHsZ1XyTdhyjJxCjPif/TRkjnsyGAGnE=" crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.5/dist/vibrant.min.js integrity="sha256-5NovOZc4iwiAWTYIFiIM7DxKUXKWvpVEuMEPLzcm5/g=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script>
<script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>