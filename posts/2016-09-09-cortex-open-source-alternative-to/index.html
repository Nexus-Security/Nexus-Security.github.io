<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Deploy machine learning models in production Cortex is an open source platform that takes machine learning models—trained with nearly any framework—and turns them into production web APIs in one command.
Quickstart Below, we&amp;rsquo;ll walk through how to use Cortex to deploy OpenAI&amp;rsquo;s GPT-2 model as a service on AWS. You&amp;rsquo;ll need to install Cortex on your AWS account before getting started.
Step 1: Configure your deployment Define a deployment and an api resource."><title>Cortex: An open source alternative to SageMaker</title><link rel=canonical href=https://Nexus-Security.github.io/posts/2016-09-09-cortex-open-source-alternative-to/><link rel=stylesheet href=/scss/style.min.450926226e724574a6b936335ea06111f8aeb253d932c86cb2cc807341cd2889.css><meta property="og:title" content="Cortex: An open source alternative to SageMaker"><meta property="og:description" content="Deploy machine learning models in production Cortex is an open source platform that takes machine learning models—trained with nearly any framework—and turns them into production web APIs in one command.
Quickstart Below, we&amp;rsquo;ll walk through how to use Cortex to deploy OpenAI&amp;rsquo;s GPT-2 model as a service on AWS. You&amp;rsquo;ll need to install Cortex on your AWS account before getting started.
Step 1: Configure your deployment Define a deployment and an api resource."><meta property="og:url" content="https://Nexus-Security.github.io/posts/2016-09-09-cortex-open-source-alternative-to/"><meta property="og:site_name" content="ZYChimne"><meta property="og:type" content="article"><meta property="article:section" content="Posts"><meta property="article:published_time" content="2019-10-18T02:07:00+01:00"><meta property="article:modified_time" content="2019-10-18T02:07:00+01:00"><meta name=twitter:title content="Cortex: An open source alternative to SageMaker"><meta name=twitter:description content="Deploy machine learning models in production Cortex is an open source platform that takes machine learning models—trained with nearly any framework—and turns them into production web APIs in one command.
Quickstart Below, we&amp;rsquo;ll walk through how to use Cortex to deploy OpenAI&amp;rsquo;s GPT-2 model as a service on AWS. You&amp;rsquo;ll need to install Cortex on your AWS account before getting started.
Step 1: Configure your deployment Define a deployment and an api resource."></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hue825486955cd7c56d95e38b4bd2a8e3c_229979_300x0_resize_box_3.png width=300 height=300 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>ZYChimne</a></h1><h2 class=site-description>Computer Science, Wuhan University</h2></div></header><ol class=social-menu><li><a href=https://github.com/ZYChimne target=_blank title=GitHub><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=https://twitter.com/ZChimne target=_blank title=Twitter><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-twitter" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M22 4.01c-1 .49-1.98.689-3 .99-1.121-1.265-2.783-1.335-4.38-.737S11.977 6.323 12 8v1c-3.245.083-6.135-1.395-8-4 0 0-4.182 7.433 4 11-1.872 1.247-3.739 2.088-6 2 3.308 1.803 6.913 2.423 10.034 1.517 3.58-1.04 6.522-3.723 7.651-7.742a13.84 13.84.0 00.497-3.753C20.18 7.773 21.692 5.25 22 4.009z"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg><span>Home</span></a></li><li><a href=/about-me/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg><span>About Me</span></a></li><div class=menu-bottom-section><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><span>Dark Mode</span></li></div></ol></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><div class=article-title-wrapper><h2 class=article-title><a href=/posts/2016-09-09-cortex-open-source-alternative-to/>Cortex: An open source alternative to SageMaker</a></h2></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg><time class=article-time--published>Oct 18, 2019</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><time class=article-time--reading>3 minute read</time></div></footer></div></header><section class=article-content><h1 id=httpsgithubcomcortexlabscortextreev090deploy-machine-learning-models-in-productiondeploy-machine-learning-models-in-production><a class=link href=https://github.com/cortexlabs/cortex/tree/v0.9.0#deploy-machine-learning-models-in-production target=_blank rel=noopener></a>Deploy machine learning models in production</h1><p>Cortex is an open source platform that takes machine learning models—trained with nearly any framework—and turns them into production web APIs in one command.</p><p><a class=link href=https://camo.githubusercontent.com/589ff5bd598eb953df1bf151bd8c6142738cc4ff/68747470733a2f2f636f727465782d7075626c69632e73332d75732d776573742d322e616d617a6f6e6177732e636f6d2f64656d6f2f6769662f76302e382e676966 target=_blank rel=noopener><img src=https://camo.githubusercontent.com/589ff5bd598eb953df1bf151bd8c6142738cc4ff/68747470733a2f2f636f727465782d7075626c69632e73332d75732d776573742d322e616d617a6f6e6177732e636f6d2f64656d6f2f6769662f76302e382e676966 loading=lazy alt=Demo></a></p><h2 id=httpsgithubcomcortexlabscortextreev090quickstartquickstart><a class=link href=https://github.com/cortexlabs/cortex/tree/v0.9.0#quickstart target=_blank rel=noopener></a>Quickstart</h2><p>Below, we&rsquo;ll walk through how to use Cortex to deploy OpenAI&rsquo;s GPT-2 model as a service on AWS. You&rsquo;ll need to <a class=link href=https://www.cortex.dev/install target=_blank rel=noopener>install Cortex</a> on your AWS account before getting started.</p><h3 id=httpsgithubcomcortexlabscortextreev090step-1-configure-your-deploymentstep-1-configure-your-deployment><a class=link href=https://github.com/cortexlabs/cortex/tree/v0.9.0#step-1-configure-your-deployment target=_blank rel=noopener></a>Step 1: Configure your deployment</h3><p>Define a <code>deployment</code> and an <code>api</code> resource. A <code>deployment</code> specifies a set of APIs that are deployed together. An <code>api</code> makes a model available as a web service that can serve real-time predictions. The configuration below will download the model from the <code>cortex-examples</code> S3 bucket. You can run the code that generated the model <a class=link href=https://colab.research.google.com/github/cortexlabs/cortex/blob/0.9/examples/text-generator/gpt-2.ipynb target=_blank rel=noopener>here</a>.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl># cortex.yaml - kind: deployment name: text - kind: api name: generator model: s3://cortex-examples/text-generator/gpt-2/124M request\_handler: handler.py
</span></span></code></pre></td></tr></table></div></div><h3 id=httpsgithubcomcortexlabscortextreev090step-2-add-request-handlingstep-2-add-request-handling><a class=link href=https://github.com/cortexlabs/cortex/tree/v0.9.0#step-2-add-request-handling target=_blank rel=noopener></a>Step 2: Add request handling</h3><p>The model requires encoded data for inference, but the API should accept strings of natural language as input. It should also decode the inference output. This can be implemented in a request handler file using the <code>pre_inference</code> and <code>post_inference</code> functions:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl># handler.py from encoder import get\_encoder encoder \= get\_encoder() def pre\_inference(sample, metadata): context \= encoder.encode(sample\[&#34;text&#34;\]) return {&#34;context&#34;: \[context\]} def post\_inference(prediction, metadata): response \= prediction\[&#34;sample&#34;\] return encoder.decode(response)
</span></span></code></pre></td></tr></table></div></div><h3 id=httpsgithubcomcortexlabscortextreev090step-3-deploy-to-awsstep-3-deploy-to-aws><a class=link href=https://github.com/cortexlabs/cortex/tree/v0.9.0#step-3-deploy-to-aws target=_blank rel=noopener></a>Step 3: Deploy to AWS</h3><p>Deploying to AWS is as simple as running <code>cortex deploy</code> from your CLI. <code>cortex deploy</code> takes the declarative configuration from <code>cortex.yaml</code> and creates it on the cluster. Behind the scenes, Cortex containerizes the model, makes it servable using TensorFlow Serving, exposes the endpoint with a load balancer, and orchestrates the workload on Kubernetes.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>$ cortex deploy deployment started
</span></span></code></pre></td></tr></table></div></div><p>You can track the status of a deployment using <code>cortex get</code>. The output below indicates that one replica of the API was requested and one replica is available to serve predictions. Cortex will automatically launch more replicas if the load increases and spin down replicas if there is unused capacity.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>$ cortex get generator --watch status up-to-date available requested last update avg latency live 1 1 1 8s 123ms url: http://\*\*\*.amazonaws.com/text/generator
</span></span></code></pre></td></tr></table></div></div><h3 id=httpsgithubcomcortexlabscortextreev090step-4-serve-real-time-predictionsstep-4-serve-real-time-predictions><a class=link href=https://github.com/cortexlabs/cortex/tree/v0.9.0#step-4-serve-real-time-predictions target=_blank rel=noopener></a>Step 4: Serve real-time predictions</h3><p>Once you have your endpoint, you can make requests:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>$ curl http://\*\*\*.amazonaws.com/text/generator \\ -X POST -H &#34;Content-Type: application/json&#34; \\ -d &#39;{&#34;text&#34;: &#34;machine learning&#34;}&#39; Machine learning, with more than one thousand researchers around the world today, are looking to create computer-driven machine learning algorithms that can also be applied to human and social problems, such as education, health care, employment, medicine, politics, or the environment...
</span></span></code></pre></td></tr></table></div></div><p>Any questions? <a class=link href=https://gitter.im/cortexlabs/cortex target=_blank rel=noopener>chat with us</a>.</p><h2 id=httpsgithubcomcortexlabscortextreev090more-examplesmore-examples><a class=link href=https://github.com/cortexlabs/cortex/tree/v0.9.0#more-examples target=_blank rel=noopener></a>More examples</h2><h2 id=httpsgithubcomcortexlabscortextreev090key-featureskey-features><a class=link href=https://github.com/cortexlabs/cortex/tree/v0.9.0#key-features target=_blank rel=noopener></a>Key features</h2><ul><li><p><strong>Autoscaling:</strong> Cortex automatically scales APIs to handle production workloads.</p></li><li><p><strong>Multi framework:</strong> Cortex supports TensorFlow, Keras, PyTorch, Scikit-learn, XGBoost, and more.</p></li><li><p><strong>CPU / GPU support:</strong> Cortex can run inference on CPU or GPU infrastructure.</p></li><li><p><strong>Rolling updates:</strong> Cortex updates deployed APIs without any downtime.</p></li><li><p><strong>Log streaming:</strong> Cortex streams logs from deployed models to your CLI.</p></li><li><p><strong>Prediction monitoring:</strong> Cortex monitors network metrics and tracks predictions.</p></li><li><p><strong>Minimal declarative configuration:</strong> Deployments are defined in a single <code>cortex.yaml</code> file.</p></li></ul><p>from Hacker News <a class=link href=https://github.com/cortexlabs/cortex/tree/v0.9.0 target=_blank rel=noopener>https://github.com/cortexlabs/cortex/tree/v0.9.0</a></p></section><footer class=article-footer><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg><span>Licensed under CC BY-NC-SA 4.0</span></section></footer></article><footer class=site-footer><section class=copyright>&copy;
2020 -
2022 ZYChimne</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.11.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css integrity="sha256-c0uckgykQ9v5k+IqViZOZKc47Jn7KQil4/MP3ySA3F8=" crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.css integrity="sha256-SBLU4vv6CA6lHsZ1XyTdhyjJxCjPif/TRkjnsyGAGnE=" crossorigin=anonymous></main><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#httpsgithubcomcortexlabscortextreev090quickstartquickstart><a href=https://github.com/cortexlabs/cortex/tree/v0.9.0#quickstart></a>Quickstart</a><ol><li><a href=#httpsgithubcomcortexlabscortextreev090step-1-configure-your-deploymentstep-1-configure-your-deployment><a href=https://github.com/cortexlabs/cortex/tree/v0.9.0#step-1-configure-your-deployment></a>Step 1: Configure your deployment</a></li><li><a href=#httpsgithubcomcortexlabscortextreev090step-2-add-request-handlingstep-2-add-request-handling><a href=https://github.com/cortexlabs/cortex/tree/v0.9.0#step-2-add-request-handling></a>Step 2: Add request handling</a></li><li><a href=#httpsgithubcomcortexlabscortextreev090step-3-deploy-to-awsstep-3-deploy-to-aws><a href=https://github.com/cortexlabs/cortex/tree/v0.9.0#step-3-deploy-to-aws></a>Step 3: Deploy to AWS</a></li><li><a href=#httpsgithubcomcortexlabscortextreev090step-4-serve-real-time-predictionsstep-4-serve-real-time-predictions><a href=https://github.com/cortexlabs/cortex/tree/v0.9.0#step-4-serve-real-time-predictions></a>Step 4: Serve real-time predictions</a></li></ol></li><li><a href=#httpsgithubcomcortexlabscortextreev090more-examplesmore-examples><a href=https://github.com/cortexlabs/cortex/tree/v0.9.0#more-examples></a>More examples</a></li><li><a href=#httpsgithubcomcortexlabscortextreev090key-featureskey-features><a href=https://github.com/cortexlabs/cortex/tree/v0.9.0#key-features></a>Key features</a></li></ol></nav></div></section></aside></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.5/dist/vibrant.min.js integrity="sha256-5NovOZc4iwiAWTYIFiIM7DxKUXKWvpVEuMEPLzcm5/g=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script>
<script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>