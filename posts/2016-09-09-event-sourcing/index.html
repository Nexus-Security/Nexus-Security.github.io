<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Event Sourcing May the source be with you. I recently became intrigued by the concept of event sourcing as applied to back-end architecture, specifically a microservice-oriented approach. I have spent the last few years working predominantly on the front-end, and became enamored by the simplicity and elegance of this pattern as the backbone of front-end architecture, popularized by Redux.
To better understand the trade-offs between a traditional, monolithic back-end, and a microservice-oriented, event sourced approach, I began sketching a toy architecture for the initial user flow of seemingly every web application: signing up for a user account, and receiving an activation email."><title>Event Sourcing</title><link rel=canonical href=https://Nexus-Security.github.io/posts/2016-09-09-event-sourcing/><link rel=stylesheet href=/scss/style.min.450926226e724574a6b936335ea06111f8aeb253d932c86cb2cc807341cd2889.css><meta property="og:title" content="Event Sourcing"><meta property="og:description" content="Event Sourcing May the source be with you. I recently became intrigued by the concept of event sourcing as applied to back-end architecture, specifically a microservice-oriented approach. I have spent the last few years working predominantly on the front-end, and became enamored by the simplicity and elegance of this pattern as the backbone of front-end architecture, popularized by Redux.
To better understand the trade-offs between a traditional, monolithic back-end, and a microservice-oriented, event sourced approach, I began sketching a toy architecture for the initial user flow of seemingly every web application: signing up for a user account, and receiving an activation email."><meta property="og:url" content="https://Nexus-Security.github.io/posts/2016-09-09-event-sourcing/"><meta property="og:site_name" content="ZYChimne"><meta property="og:type" content="article"><meta property="article:section" content="Posts"><meta property="article:published_time" content="2020-01-02T01:36:00+01:00"><meta property="article:modified_time" content="2020-01-02T01:36:00+01:00"><meta name=twitter:title content="Event Sourcing"><meta name=twitter:description content="Event Sourcing May the source be with you. I recently became intrigued by the concept of event sourcing as applied to back-end architecture, specifically a microservice-oriented approach. I have spent the last few years working predominantly on the front-end, and became enamored by the simplicity and elegance of this pattern as the backbone of front-end architecture, popularized by Redux.
To better understand the trade-offs between a traditional, monolithic back-end, and a microservice-oriented, event sourced approach, I began sketching a toy architecture for the initial user flow of seemingly every web application: signing up for a user account, and receiving an activation email."></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hue825486955cd7c56d95e38b4bd2a8e3c_229979_300x0_resize_box_3.png width=300 height=300 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>ZYChimne</a></h1><h2 class=site-description>Computer Science, Wuhan University</h2></div></header><ol class=social-menu><li><a href=https://github.com/Nexus-Security target=_blank title=GitHub><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=mailto:0x000216@gmail.com target=_blank title=Email><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-gmail" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#2c3e50" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M16 20h3a1 1 0 001-1V5a1 1 0 00-1-1h-3v16z"/><path d="M5 20h3V4H5A1 1 0 004 5v14a1 1 0 001 1z"/><path d="M16 4l-4 4-4-4"/><path d="M4 6.5l8 7.5 8-7.5"/></svg></a></li><li><a href=https://www.buymeacoffee.com/0x000216 target=_blank title=Coffee><svg width="884" height="1279" viewBox="0 0 884 1279" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg"><defs><path d="M0 0H884V1279H0V0z" id="path_1"/><clipPath id="mask_1"><use xlink:href="#path_1"/></clipPath></defs><g id="buymeacoffee"><path d="M0 0H884V1279H0V0z" id="Background" fill="none" fill-rule="evenodd" stroke="none"/><g clip-path="url(#mask_1)"><path d="M791.109 297.518 790.231 297.002 788.201 296.383C789.018 297.072 790.04 297.472 791.109 297.518z" id="Shape" fill="#0d0c22" stroke="none"/><path d="M803.916 388.891l-1 1 1-1z" id="Shape" fill="#0d0c22" stroke="none"/><path d="M792.113 297.647C791.776 297.581 791.447 297.462 791.127 297.29 791.108 297.622 791.108 297.958 791.127 298.29 791.488 298.216 791.83 297.995 792.113 297.647z" id="Shape" fill="#0d0c22" stroke="none"/><path d="M791.113 298.447h1v-1l-1 1z" id="Shape" fill="#0d0c22" stroke="none"/><path d="M803.111 388.726 804.591 387.883 805.142 387.573 805.641 387.04C804.702 387.444 803.846 388.016 803.111 388.726z" id="Shape" fill="#0d0c22" stroke="none"/><path d="M793.669 299.515 792.223 298.138 791.243 297.605C791.77 298.535 792.641 299.221 793.669 299.515z" id="Shape" fill="#0d0c22" stroke="none"/><path d="M430.019 1186.18C428.864 1186.68 427.852 1187.46 427.076 1188.45L427.988 1187.87C428.608 1187.3 429.485 1186.63 430.019 1186.18z" id="Shape" fill="#0d0c22" stroke="none"/><path d="M641.681 1144.63C641.681 1143.33 640.424 1143.57 640.729 1148.21 640.729 1147.84 641.035 1147.46 641.171 1147.1 641.341 1146.27 641.477 1145.46 641.681 1144.63z" id="Shape" fill="#0d0c22" stroke="none"/><path d="M619.284 1186.18C618.129 1186.68 617.118 1187.46 616.342 1188.45L617.254 1187.87C617.873 1187.3 618.751 1186.63 619.284 1186.18z" id="Shape" fill="#0d0c22" stroke="none"/><path d="M281.304 1196.06C280.427 1195.3 279.354 1194.8 278.207 1194.61 279.136 1195.06 280.065 1195.51 280.684 1195.85L281.304 1196.06z" id="Shape" fill="#0d0c22" stroke="none"/><path d="M247.841 1164.01C247.704 1162.66 247.288 1161.35 246.619 1160.16 247.093 1161.39 247.489 1162.66 247.806 1163.94L247.841 1164.01z" id="Shape" fill="#0d0c22" stroke="none"/><path d="M472.623 590.836c-45.941 19.667-98.077 41.966-165.647 41.966C278.71 632.746 250.58 628.868 223.353 621.274l46.733 479.806C271.74 1121.13 280.876 1139.83 295.679 1153.46 310.482 1167.09 329.87 1174.65 349.992 1174.65 349.992 1174.65 416.254 1178.09 438.365 1178.09 462.161 1178.09 533.516 1174.65 533.516 1174.65c20.12.0 39.503-7.57000000000016 54.303-21.2C602.619 1139.82 611.752 1121.13 613.406 1101.08l50.053-530.204C641.091 563.237 618.516 558.161 593.068 558.161 549.054 558.144 513.591 573.303 472.623 590.836z" id="Shape" fill="#fff" stroke="none"/><path d="M78.6885 386.132 79.4799 386.872 79.9962 387.182C79.5987 386.787 79.1603 386.435 78.6885 386.132z" id="Shape" fill="#0d0c22" stroke="none"/><path d="M879.567 341.849 872.53 306.352C866.215 274.503 851.882 244.409 819.19 232.898 808.711 229.215 796.821 227.633 788.786 220.01 780.751 212.388 778.376 200.55 776.518 189.572 773.076 169.423 769.842 149.257 766.314 129.143 763.269 111.85 760.86 92.4243 752.928 76.56c-10.324-21.3016-31.746-33.7591-53.048-42.001C688.965 30.4844 677.826 27.0375 666.517 24.2352 613.297 10.1947 557.342 5.03277 502.591 2.09047 436.875-1.53577 370.983-.443233 305.422 5.35968 256.625 9.79894 205.229 15.1674 158.858 32.0469c-16.948 6.1771-34.413 13.593-47.3 26.6872C95.7448 74.8221 90.5829 99.7026 102.128 119.765c8.208 14.247 22.111 24.313 36.857 30.972C158.192 159.317 178.251 165.846 198.829 170.215c57.297 12.664 116.642 17.636 175.178 19.753C438.887 192.586 503.87 190.464 568.44 183.618 584.408 181.863 600.347 179.758 616.257 177.304 634.995 174.43 647.022 149.928 641.499 132.859 634.891 112.453 617.134 104.538 597.055 107.618 594.095 108.082 591.153 108.512 588.193 108.942L586.06 109.252C579.257 110.113 572.455 110.915 565.653 111.661c-14.052 1.514-28.138 2.753-42.259 3.717C491.768 117.58 460.057 118.595 428.363 118.647c-31.144.0-62.305-.878-93.38-2.92500000000001C320.805 114.793 306.661 113.611 292.552 112.177 286.134 111.506 279.733 110.801 273.333 110.009L267.241 109.235 265.917 109.046 259.602 108.134C246.697 106.189 233.792 103.953 221.025 101.251 219.737 100.965 218.584 100.249 217.758 99.2193 216.932 98.1901 216.482 96.9099 216.482 95.5903 216.482 94.2706 216.932 92.9904 217.758 91.9612 218.584 90.9319 219.737 90.2152 221.025 89.9293H221.266C232.33 87.5721 243.479 85.5589 254.663 83.8038 258.392 83.2188 262.131 82.6453 265.882 82.0832H265.985C272.988 81.6186 280.026 80.3625 286.994 79.5366 347.624 73.2302 408.614 71.0801 469.538 73.1014 499.115 73.9618 528.676 75.6996 558.116 78.6935 564.448 79.3474 570.746 80.0357 577.043 80.8099 579.452 81.1025 581.878 81.4465 584.305 81.7391L589.191 82.4445C603.438 84.5667 617.61 87.1419 631.708 90.1703 652.597 94.7128 679.422 96.1925 688.713 119.077 691.673 126.338 693.015 134.408 694.649 142.03L696.731 151.752C696.786 151.926 696.826 152.105 696.852 152.285 701.773 175.227 706.7 198.169 711.632 221.111 711.994 222.806 712.002 224.557 711.657 226.255 711.312 227.954 710.621 229.562 709.626 230.982 708.632 232.401 707.355 233.6 705.877 234.504 704.398 235.408 702.75 235.997 701.033 236.236H700.895L697.884 236.649 694.908 237.044C685.478 238.272 676.038 239.419 666.586 240.486 647.968 242.608 629.322 244.443 610.648 245.992 573.539 249.077 536.356 251.102 499.098 252.066 480.114 252.57 461.135 252.806 442.162 252.771 366.643 252.712 291.189 248.322 216.173 239.625 208.051 238.662 199.93 237.629 191.808 236.58 198.106 237.389 187.231 235.96 185.029 235.651 179.867 234.928 174.705 234.177 169.543 233.397 152.216 230.798 134.993 227.598 117.7 224.793 96.7944 221.352 76.8005 223.073 57.8906 233.397c-15.5221 8.494-28.0851 21.519-36.013 37.338-8.1559 16.862-10.582 35.221-14.22974 53.34-3.64777 18.118-9.32591 37.613-7.17511 56.213C5.10128 420.431 33.165 453.054 73.5313 460.35 111.506 467.232 149.687 472.807 187.971 477.556 338.361 495.975 490.294 498.178 641.155 484.129 653.44 482.982 665.708 481.732 677.959 480.378 681.786 479.958 685.658 480.398 689.292 481.668S696.23 485.005 698.962 487.717 703.784 493.718 705.08 497.342C706.377 500.967 706.846 504.836 706.453 508.665L702.633 545.797c-7.697 75.031-15.394 150.057-23.091 225.077-8.029 78.783-16.111 157.56-24.244 236.326C653.004 1029.39 650.71 1051.57 648.416 1073.74 646.213 1095.58 645.904 1118.1 641.757 1139.68 635.218 1173.61 612.248 1194.45 578.73 1202.07 548.022 1209.06 516.652 1212.73 485.161 1213.01 450.249 1213.2 415.355 1211.65 380.443 1211.84 343.173 1212.05 297.525 1208.61 268.756 1180.87 243.479 1156.51 239.986 1118.36 236.545 1085.37 231.957 1041.7 227.409 998.039 222.9 954.381L197.607 711.615 181.244 554.538C180.968 551.94 180.693 549.376 180.435 546.76 178.473 528.023 165.207 509.681 144.301 510.627 126.407 511.418 106.069 526.629 108.168 546.76l12.13 116.454 25.087 240.89C152.532 972.528 159.661 1040.96 166.773 1109.41 168.15 1122.52 169.44 1135.67 170.885 1148.78 178.749 1220.43 233.465 1259.04 301.224 1269.91 340.799 1276.28 381.337 1277.59 421.497 1278.24 472.979 1279.07 524.977 1281.05 575.615 1271.72 650.653 1257.95 706.952 1207.85 714.987 1130.13 717.282 1107.69 719.576 1085.25 721.87 1062.8 729.498 988.559 737.115 914.313 744.72 840.061l24.881-242.61 11.408-111.188C781.577 480.749 783.905 475.565 787.649 471.478 791.392 467.391 796.352 464.617 801.794 463.567 823.25 459.386 843.761 452.245 859.023 435.916c24.295-25.998 29.13-59.895 20.544-94.067zM72.7365 365.835C73.247 365.68 72.3065 368.484 71.9034 369.792 71.8229 367.813 71.984 366.058 72.7365 365.835zm1.7756 16.105C74.6842 381.819 75.2003 382.508 75.7337 383.334 74.925 382.576 74.4089 382.009 74.4949 381.94H74.5121zM76.5597 384.641C77.6004 385.897 78.1569 386.689 76.5597 384.641zM80.7002 387.979h.2727C80.9729 388.313 81.473 388.645 81.6548 388.979 81.3533 388.612 81.0186 388.277 80.6548 387.979H80.7002zM800.796 382.989C793.088 390.319 781.473 393.726 769.996 395.43c-128.704 19.099-259.283 28.769-389.399 24.502C287.476 416.749 195.336 406.407 103.144 393.382 94.1102 392.109 84.3197 390.457 78.1082 383.798c-11.7004-12.561-5.9534-37.854-2.9079-53.03C77.9878 316.865 83.3218 298.334 99.8572 296.355 125.667 293.327 155.64 304.218 181.175 308.09 211.917 312.781 242.774 316.538 273.745 319.36 405.925 331.405 540.325 329.529 671.92 311.91 695.905 308.686 719.805 304.941 743.619 300.674 764.835 296.871 788.356 289.731 801.175 311.703 809.967 326.673 811.137 346.701 809.778 363.615 809.359 370.984 806.139 377.915 800.779 382.989H800.796z" id="Shape" fill="#fff" fill-rule="evenodd" stroke="none"/></g></g></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg><span>Home</span></a></li><li><a href=/about-me/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg><span>About Me</span></a></li><div class=menu-bottom-section><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><span>Dark Mode</span></li></div></ol></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><div class=article-title-wrapper><h2 class=article-title><a href=/posts/2016-09-09-event-sourcing/>Event Sourcing</a></h2></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg><time class=article-time--published>Jan 02, 2020</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><time class=article-time--reading>33 minute read</time></div></footer></div></header><section class=article-content><p><img src=https://arkwright.github.io/images/event-sourcing/bugs.svg loading=lazy alt="A marching line of various types of insects, including ants, flies, ladybugs, etc., intended as an analogy to the stream of diverse events in an event sourced system. The irony of using a stream of bugs is not lost on me."></p><h1 id=event-sourcing>Event Sourcing</h1><h2 id=may-the-source-be-with-you>May the source be with you.</h2><p>I recently became intrigued by the concept of <em><a class=link href=https://martinfowler.com/eaaDev/EventSourcing.html target=_blank rel=noopener>event sourcing</a></em> as applied to back-end architecture, specifically a microservice-oriented approach. I have spent the last few years working predominantly on the front-end, and became enamored by the simplicity and elegance of this pattern as the backbone of front-end architecture, popularized by <a class=link href=http://redux.js.org/ target=_blank rel=noopener>Redux</a>.</p><p>To better understand the trade-offs between a traditional, monolithic back-end, and a microservice-oriented, event sourced approach, I began sketching a toy architecture for the initial user flow of seemingly every web application: signing up for a user account, and receiving an activation email. Easy enough, right?</p><p><img src=https://arkwright.github.io/images/event-sourcing/alien.svg loading=lazy alt="Alien from outer space, saying &lsquo;Sup.&rsquo;, as aliens do."></p><p>Little did I realize just how alien the event sourcing pattern would feel. I quickly developed more questions than answers. I spent the next several days reading everything I could about the subject, desperately begging Google to show me the way. I learned an incredible amount during that time, and in the spirit of the great <a class=link href=https://jvns.ca/ target=_blank rel=noopener>Julia Evans</a> I felt compelled to distill and summarize what I have learned for you, my fellow traveler.</p><p>This is by no means a guide indicating the “correct” way to do anything. My hope is that, if you’re new to event sourcing, this summary might help you to start reasoning about how such a system could work.</p><h2 id=things-we-will-talk-about>Things We Will Talk About</h2><p><img src=https://arkwright.github.io/images/event-sourcing/devil.svg loading=lazy alt="Lousy stick figure drawing of the devil holding a pitchfork. &lsquo;What the hell is event sourcing?&rsquo; Get it? Get it?!"></p><h2 id=what-the-hell-is-event-sourcing>What the hell is event sourcing?</h2><p>Good question! Martin Fowler <a class=link href=https://martinfowler.com/eaaDev/EventSourcing.html target=_blank rel=noopener>can tell you</a>:</p><blockquote><p>Event Sourcing ensures that all changes to application state are stored as a sequence of events. Not just can we query these events, we can also use the event log to reconstruct past states, and as a foundation to automatically adjust the state to cope with retroactive changes.</p></blockquote><p>But — and this is true of most definitions of most things — this will just leave you with even more questions. So I’ll try to explain event sourcing instead of defining it.</p><ul><li>Your application produces a <em>log of events</em>. For example, you might log a <code>UserAccountCreated</code> event for each user account that is created. The log might be split into smaller, independent logs called <em>topics</em>, to help organize your events.</li><li>The events are the <em>source of truth</em> or <a class=link href=https://en.wikipedia.org/wiki/System_of_record target=_blank rel=noopener>system of record</a> for your application. It is common for applications to write to a database and treat it as the source of truth, but when event sourcing we write to the event log instead.</li><li>Other parts of the application can read from the event log. This allows for a pub/sub style of communication, where multiple listeners can react to events they are interested in.</li><li>Listeners can reconstruct their own application state by reading from the event log and applying the events to their own, private data store, such as a database. They might apply some of the events, or all of them, depending on their use case. Events are always applied in the total order that they appear in the log.</li></ul><p><img src=https://arkwright.github.io/images/event-sourcing/overview.svg loading=lazy alt="Diagram of application synchronously writing (appending) an event to the event log. A service named Some Service asynchronously reads a prior event from the log, processes it, and writes to its own, private database."></p><h2 id=what-can-event-sourcing-do-for-me>What can event sourcing do for me?</h2><p>I can recommend two really good sales pitches for event sourced architectures (sometimes called <em>log-oriented</em> architectures), and a more pragmatic overview. I recommend that you read and watch these in the following order:</p><ol><li>Martin Kleppmann has an <a class=link href=https://www.confluent.io/blog/using-logs-to-build-a-solid-data-infrastructure-or-why-dual-writes-are-a-bad-idea/ target=_blank rel=noopener>excellent write-up</a> to whet your appetite.</li><li>Greg Young gave <a class=link href="https://www.youtube.com/watch?v=8JKjvY4etTY" target=_blank rel=noopener>a great talk</a> which really helped me to understand how event sourcing can be useful <em>even at small traffic scales.</em></li><li>And as always, Martin Fowler will try to talk some sense into us as a part of <a class=link href="https://www.youtube.com/watch?v=aweV9FLTZkU" target=_blank rel=noopener>his fantastic overview</a>.</li></ol><p><img src=https://arkwright.github.io/images/event-sourcing/fowler-kleppmann-young.svg loading=lazy alt="Poorly drawn stick figure versions of Martin Fowler (beard), Martin Kleppmann (long hair), and Greg Young (beard and short hair). It is surprisingly hard to capture someone&rsquo;s essence using only hair."></p><p>But it’s not fair for me to dump two hours of educational materials into your lap, so I’ll do my best to summarize the observations of the great masters.</p><h3 id=historical-queries>Historical Queries</h3><p>A typical database can answer questions about your data as it exists right now, but it struggles to answer time-series queries about the historical context and evolution of your data.</p><p>For example, you can query your database to determine the number of user accounts that exist. But what if your business stakeholder wanted to know how many users create an account, delete it, and then change their mind and create it again? Your database typically will not capture this data, since it only stores the <em>current</em> state — it only stores the user account, and not the <em>steps</em> that were taken to create that account. Writing events to a <a class=link href="https://www.youtube.com/watch?v=-fQGPZTECYs" target=_blank rel=noopener>log</a> naturally makes these kinds of queries possible, because the historical data is never deleted. The ability to be able to answer <em>any</em> question that the business asks about the history of the application is incredibly valuable.</p><p><img src=https://arkwright.github.io/images/event-sourcing/history-state.svg loading=lazy alt="Diagram of event log representing time series data. The values comprising the history are: 0, +3, -5, +9, +1. When added, they compute the value 8, which is the application&rsquo;s state, depicted as being stored in a database."></p><p>Historical queries can ask, “How did we arrive at this state?”, instead of, “What does the current state look like?”</p><h3 id=immutable-data>Immutable Data</h3><p>Modeling your data as an immutable, append-only log of events greatly simplifies reasoning about how the application works. It is harder to get yourself into a confusing situation by accidentally mutating state. This is easier to understand when we consider the utility of time-traveling debugging.</p><p><img src=https://arkwright.github.io/images/event-sourcing/append.svg loading=lazy alt="Diagram of an event being appended to the end of an event log, with sweet explosion effect to emphasize that we always append, never mutate."></p><h3 id=time-traveling-debugging>Time-Traveling Debugging</h3><p>Dan Abramov (creator of Redux) has <a class=link href="https://youtu.be/xsSnOQynTHs?t=18m2s" target=_blank rel=noopener>sung the praises</a> of time-traveling debugging from a front-end perspective, and the same principle applies from a back-end one.</p><p>Given that the event log is immutable, all changes to the application’s state must be driven by <em>appending</em> to the event log instead of changing it. This means that when our application behaves in a confusing way, we can simply start from the “beginning of time” and replay events one by one until we isolate the event that is triggering the confusing behavior. This is a powerful and incredibly simple tool for debugging our application.</p><p><img src=https://arkwright.github.io/images/event-sourcing/time-travel.svg loading=lazy alt="Diagram of event log containing 8 events. A second log pulls 5 events from the first log, in original order, to reconstruct a previous application state."></p><p><em>But that’s not all!</em> Just as our version control system can “check out” code at a particular point in the project’s history, our event log can “check out” a particular point in time so that we can inspect how the state looked at that moment.</p><p>As Martin Fowler <a class=link href=https://martinfowler.com/eaaDev/EventSourcing.html target=_blank rel=noopener>pointed out</a>, instead of exclusively writing end-to-end tests we can explore a complementary approach: store and replay a sequence of events into the log, and then inspect the application’s state to ensure that it matches what we expect.</p><p><img src=https://arkwright.github.io/images/event-sourcing/testing.svg loading=lazy alt="Diagram of an event log with Mr. Potato Head pieces representing the content of events. The production environment correctly assembles the events into a very poorly drawn Mr. Potato Head, and the QA environment assembles them into a horrifying mutation. Stick figure Martin Fowler comments that &lsquo;It&rsquo;s broke.&rsquo;"></p><p>These are just some examples. Retaining the time-series data in our event log opens up numerous opportunities for building <a class=link href=http://firstround.com/review/forget-technical-debt-heres-how-to-build-technical-wealth/ target=_blank rel=noopener>technical wealth</a>.</p><p><img src=https://arkwright.github.io/images/event-sourcing/crown.svg loading=lazy alt="Drawing of a crown with jewels. I put some extra lines around it to indicate fanciness. This is a metaphor for technical wealth. The exact type of crown is left to the reader&rsquo;s imagination."></p><h3 id=easily-connect-data-consumers>Easily Connect Data Consumers</h3><p>An event sourced architecture features an event log as the central hub to which data producers write, and from which data consumers read. This pub/sub architecture minimizes or eliminates the need to write custom adaptors to get data out of one system and into another. All data is published in a standardized message format (JSON, or whatever you enjoy). Writing a new consumer becomes easier and more predictable, since systems share data in a consistent way. Multiple listeners can subscribe to an event log without a problem.</p><p><img src=https://arkwright.github.io/images/event-sourcing/central-log.svg loading=lazy alt="Diagram of an event log at the center of many services, which connect to it to consume each other&rsquo;s data. A sharpy dressed smiley face (with bow tie) connects to one of the services, as users do."></p><p>Systems often mutate into Frankenstein architectures as new features and use cases are bolted on accommodated. Martin Kleppmann does a great job of <a class=link href=https://www.confluent.io/blog/using-logs-to-build-a-solid-data-infrastructure-or-why-dual-writes-are-a-bad-idea/ target=_blank rel=noopener>describing this phenomenon</a>. Modeling data consumption as a log of events can mitigate this unsatisfactory result.</p><h3 id=reasonable-scaling-defaults>Reasonable Scaling Defaults</h3><p>An event sourced architecture provides reasonable defaults for common scalability challenges that applications face as load increases, and after exhausting vertical scaling strategies. It isn’t a silver bullet (nothing is), but we can take comfort in the fact that we are probably not painting ourselves into a corner.</p><p>If writing to the event log is the bottleneck, we can split a single log into <em>partitions</em> spread over multiple servers, each responsible for handling writes to its fair share of the partitions. This is how Apache Kafka works.</p><p><img src=https://arkwright.github.io/images/event-sourcing/partitions.svg loading=lazy alt="Diagram of two services, Service and Moar Service, each synchronously writing to two different event log partitions. Service produces events 1 through 5, and Moar Service produces events A through E. Both partitions are asynchronously read by two different consumers."></p><p>If reading from the event log is the bottleneck, we can introduce log replication and have consumers read from the replicas.</p><p><img src=https://arkwright.github.io/images/event-sourcing/replicas.svg loading=lazy alt="Diagram of a service synchronously writing events 1 through 5 to an event log. The log replicates those events to two replicas, from which two consumers are able to asynchronously read."></p><p>If consumers cannot keep up with the volume of events, we can add more consumers and parallelize the work of processing the events.</p><p><img src=https://arkwright.github.io/images/event-sourcing/parallel-consumers.svg loading=lazy alt="Diagram of a service synchronously writing events 1 through 9 to an event log. The log is asynchronously split into three partitions, with events being spread over the partitions. The partitions receive events {1, 4, 7}, {2, 5, 8}, and {3, 6, 9}, respectively. Three consumers are each dedicated to consuming events from one of the partitions."></p><p>If we run out of disk space to store the log, we can explore options for long-term storage. We could write a service to read older log messages and push them into a some kind of data warehouse. Consumers which only need to keep up with processing new-ish messages read directly from the primary log. Consumers which wish to rebuild their local state by processing all log messages from the beginning of time may do so by reading from the data warehouse until they reach the most recent warehoused message, and then switch to reading from the primary log.</p><p><img src=https://arkwright.github.io/images/event-sourcing/storage.svg loading=lazy alt="Diagram of a service synchronously writing event 12 to the event log. A Long Term Storage service asynchronously pulls event 7 from the log and synchronously appends it to its own log, which now contains events 1 through 7. A cool consumer wearing (probably expensive) sunglasses asynchronously reads events 1 through 7 from the Long Term Storage log, and events 8 through latest from the main log."></p><h3 id=fault-tolerance-and-resiliency>Fault Tolerance and Resiliency</h3><p>This is my favourite feature of a log-oriented architecture, and the one that attracted me to event sourcing.</p><p>Often, one portion of an application will need to react to a change in a different subsystem. For example, when a user account is created, we might want to send an account activation email to that user.</p><p>In a traditional monolithic system, the controller which handles this logic might look something like this pseudocode:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>user = new User(&#39;dvader@empire.gov&#39;) user.save() MailService.sendAccountActivationEmail(user) 
</span></span></code></pre></td></tr></table></div></div><p>The above logic will work 99% of the time. But every now and then the <code>MailService</code> will go offline. The new account will be created but the user will not receive their activation email. The user cannot activate their account!</p><p><img src=https://arkwright.github.io/images/event-sourcing/dual-writes.svg loading=lazy alt="Diagram of a Controller performing a dual write, first to a database, and then to a Mail Service. A cartoon-style bomb, with the silly sparkling fuse hanging out, demonstrates how the second write could fail at any time."></p><p>This is a tricky situation to recover from, and an example of the problem of <a class=link href=https://www.confluent.io/blog/using-logs-to-build-a-solid-data-infrastructure-or-why-dual-writes-are-a-bad-idea/ target=_blank rel=noopener>dual writes</a>. It would be much better if we could build an application which simply <em>pauses</em> when a subsystem goes down, and resumes from where it left off when that subsystem comes back online. This would provide tremendous peace of mind, save countless users from headache, and prevent us from wasting many days recovering from, debugging, and prematurely optimizing the availability problems of our <code>MailService</code>.</p><p><img src=https://arkwright.github.io/images/event-sourcing/hard-drive.svg loading=lazy alt="Completely ridiculous drawing of a muscled hard drive, with the glorious caption, &lsquo;World&rsquo;s Most Reliable!!!!!!1&rsquo; The hard drive is Super Duper brand, if that makes any difference."></p><p>Remember: we can often substitute rapid recovery for high availability. Instead of investing significant sums to achieve high availability, we can <a class=link href=https://en.wikipedia.org/wiki/Pareto_principle target=_blank rel=noopener>Pareto-optimize</a> by investing a smaller amount into rapid recovery. For example, instead of buying the world’s most reliable hard drive, we could simply make frequent backups. Our system can go down frequently, but the user will never notice as long as we can recover in a reasonable amount of time. As Gary Bernhardt <a class=link href=https://www.destroyallsoftware.com/compendium/network-protocols/97d3ba4c24d21147 target=_blank rel=noopener>astutely points out</a>, TCP is so good at this that we take it for granted!</p><blockquote><p>TCP is so successful at its job [packet retransmission, rapid recovery] that we don’t even think of networks as being unreliable in our daily use, even though they fail routinely under normal conditions.</p></blockquote><p>This is a great example of the unreasonable effectiveness of <a class=link href=https://en.wikipedia.org/wiki/Defense_in_depth_%28computing%29 target=_blank rel=noopener>defense in depth</a> strategies. The first layer of defense is designing for availability, and the second layer is designing for recovery.</p><p>A log-oriented architecture can give us these benefits! Let’s rewrite our pseudocode controller:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>user = new User(&#39;dvader@empire.gov&#39;) event = new AccountCreatedEvent(user) EventLog.append(event) 
</span></span></code></pre></td></tr></table></div></div><p>Notice how we are no longer performing dual writes. Instead, we perform a single append to the event log. This is equivalent to saving the user account in the first example. If we model our writes as single log appends, they become inherently atomic.</p><p><img src=https://arkwright.github.io/images/event-sourcing/single-write.svg loading=lazy alt="Diagram of a User Service performing a single, synchronous write to an event log. A Mail Service then asynchronously reads from the event log. The world-famous &lsquo;shrug emoji&rsquo; person adds much needed comic relief."></p><p>The email service would be monitoring the log for new account creation events, and would send emails in response to those events. If the email service were to go offline, it could simply pick up from where it left off. In fact, the email service could go offline for <em>days</em>, and catch up on unsent emails when it comes back online. It could also contain a memory leak which causes the system to crash every hour, but as long as the email service restarts automatically, your users will not likely perceive a service interruption.</p><h3 id=mitigation-of-data-inconsistencies>Mitigation of Data Inconsistencies</h3><p>Kleppmann <a class=link href=https://www.confluent.io/blog/using-logs-to-build-a-solid-data-infrastructure-or-why-dual-writes-are-a-bad-idea/ target=_blank rel=noopener>points out</a> that systems which employ dual writes pretty much guarantee data consistency problems.</p><p>For example, let’s say you update a user account record in the database, and then update a cache containing the now stale data. Let’s further say that the cache update operation fails. Your cache is now out of sync with your database. Have fun debugging the consequences!</p><p><img src=https://arkwright.github.io/images/event-sourcing/cache-out-of-sync.svg loading=lazy alt="Diagram of Your App attempting dual writes again, because you never learn. First to write name=jane to the Database, and then to write name=jane to the Cache. The latter write fails, due to nuclear explosion, which is surprisingly difficult to draw, because it can easily end up looking like mashed potatoes. Whatever. The Cache contains name=barb, because name=jane was not written."></p><p>A read-through cache can exhibit a similar problem. Updates to a user account in the database will not be immediately reflected in its corresponding cache entry until that entry expires. Stale cache data can be very confusing to both users and developers.</p><p>But what if we perform all writes to an event log? The cache can read and apply the events in order. The cache is always in sync with its source of truth, with the standard disclaimers about eventual consistency applying. But under normal circumstances, your cache could be quite consistent with its data source. Should anything go wrong, the cache can be rebuilt by simply starting from scratch and re-consuming the event log.</p><p><img src=https://arkwright.github.io/images/event-sourcing/cache-sync.svg loading=lazy alt="Diagram of Your App synchronously writing name=jane to an event log, which already contains one event, name=barb. Database and Cache asynchronously read events from the log, and are eventually rendered consistent, with both containing name=jane."></p><h3 id=simplicity>Simplicity</h3><p>Nothing about software architecture is truly simple. But anyone who has been burned by the legacy of a bad decision will intuitively understand that simpler solutions are generally preferable. Simple solutions reduce cognitive overload, maximizing the chances that you will correctly predict the system’s behavior.</p><p>An event sourced architecture really shines as a simplifying abstraction when compared to the Frankenstein architecture which tends to evolve from modest monolithic beginnings. Producers write to a log, consumers read from the log. This simple, unifying principle allows us to reason about data flow between subsystems without becoming bogged down in their idiosyncrasies.</p><p>Kleppmann <a class=link href=https://www.confluent.io/blog/apache-kafka-samza-and-the-unix-philosophy-of-distributed-data/ target=_blank rel=noopener>described</a> the event sourcing approach as Unix philosophy (specifically pipes) for distributed systems. The simplicity of Unix pipes is precisely what makes them so composable and powerful.</p><h3 id=forgiving-of-mistakes>Forgiving Of Mistakes</h3><p>We all love that feeling when we write a piece of code and it works on the first try. That feeling is so wonderful because it is so rare. It is more common to spend as much time debugging our code as we did writing it. Mistakes are by far the normal mode of software development. Anything our architecture can do to help us recover from mistakes will have a dramatic impact on our iteration speed.</p><p>The traditional, stateful model of data persistence is very unforgiving in this regard. A bug in your code which mutates state in the wrong way will often require a one-off, compensating transaction to correct. And it’s a race against time to make the correction, since subsequent operations based on bad data will only <a class=link href=https://en.wikipedia.org/wiki/Garbage_in,_garbage_out target=_blank rel=noopener>compound the error</a>.</p><p>But what if we can fix the bug and simply rebuild the state by re-consuming events via the patched system? We wouldn’t need to duct tape our state. When the application is corrected, so is the state. We can reduce instances of fixing the application and then <em>also</em> fixing the state.</p><p>Of course, there will always be exceptions. <a class=link href=https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/ target=_blank rel=noopener>All abstractions leak.</a> But in general we prefer boats with fewer leaks.</p><p><img src=https://arkwright.github.io/images/event-sourcing/leaks.svg loading=lazy alt="Cartoon of a stick figure in a sinking boat, saying &lsquo;We&rsquo;ll fix it in the next sprint.&rsquo; Haven&rsquo;t we all been there?"></p><h3 id=ends-normalization-debate>Ends Normalization Debate</h3><p>Kleppmann makes an <a class=link href=https://www.confluent.io/blog/turning-the-database-inside-out-with-apache-samza/ target=_blank rel=noopener>excellent observation</a> regarding the best practice of database normalization. There is a tension between read- and write-optimized schemas. At a certain point, in order to boost read performance, we are tempted to denormalize our database. We might also attempt to cache query results from the normalized database, usually employing some kind of error-prone, dual write strategy.</p><p><img src=https://arkwright.github.io/images/event-sourcing/normalization.svg loading=lazy alt="Stick figure cartoon re-enactment of that Pulp Fiction scene where Vincent and Jules point their guns at a guy, his hands in the air, and Jules yelling, &lsquo;Say normalization again!&rsquo;"></p><p>A log-oriented system breaks the tension by <em>deriving</em> one or more read models from the log. We accept from the outset that one model cannot be great at everything. The log is write-optimized, and the derived read models can be denormalized to suit their specific usage pattern.</p><h3 id=audit-trail>Audit Trail</h3><p>Greg Young <a class=link href="https://youtu.be/8JKjvY4etTY?t=1m1s" target=_blank rel=noopener>recalls</a> that he was initially attracted to event sourcing because he needed to implement auditing. Storing a log of every event that has occurred in the history of the application provides a natural audit trail.</p><p>If we aren’t working on, say, a financial application, we tend to think that auditing will not be an important use case for our software. Then an incident occurs in production, and what do we do? We check the logs!</p><p><img src=https://arkwright.github.io/images/event-sourcing/batcomputer.svg loading=lazy alt="Stick figure batman asks the Batcomputer, &lsquo;Where were the Joker&rsquo;s last three known locations?&rsquo; The caption underneath reads, &lsquo;Tragically, the Batcomputer was stateful.&rsquo;"></p><h3 id=better-business-agility>Better Business Agility</h3><p>Kleppmann sees <a class=link href=https://www.confluent.io/blog/turning-the-database-inside-out-with-apache-samza/ target=_blank rel=noopener>agility enhancing</a> benefits in this approach to building software, and I think he’s on to something.</p><p>Monolithic, stateful systems are optimized for consistency, not for change. At a certain point it becomes difficult to make changes, because those changes must render the system consistent when completed. Within a large system, that is no small feat! The result is that the rate of change decreases, because it becomes a huge pain to run even a small experiment.</p><p>The ability to connect new consumers to the log stream opens up the possibility of <em>bypassing</em> existing systems to build one-off experiments. There is no need to run a migration to modify a database schema — simply deploy a new service with a different database, and store the additional data there for the duration of the experiment. The same goes for new read models, which can provide denormalized views for experimental new queries.</p><p>Have you ever noticed that <em>changing</em> an existing system tends to trigger a bikeshedding process? <em>Adding</em> a new system, in my experience, does not produce the same strong political reaction. My hunch is that this is because changing an existing system might break something which a colleague considers incredibly valuable, even sacrosanct. So by architecting our application to allow for the easy introduction of new subsystems, it seems reasonable to expect that we could actually reduce the amount of political debate associated with the running of experiments.</p><p><img src=https://arkwright.github.io/images/event-sourcing/change.svg loading=lazy alt="Two stick figure people, one with a moneybag emoji for a head. Person: &lsquo;I&rsquo;d like to change two pixels on the homepage.&rsquo; Moneybag: &lsquo;Don&rsquo;t, we might lose revenue!&rsquo; Person: &lsquo;I&rsquo;d like to launch a new product line.&rsquo; Moneybag: &lsquo;That&rsquo;s fine.&rsquo;"></p><h2 id=what-might-event-sourcing-look-like-in-practice>What might event sourcing look like in practice?</h2><p>Recall the initial user flow I described earlier: the user signs up for an account, and receives an activation email. Thinking about how to implement these features in an event sourced architecture provides a surprising amount of insight into the pattern and its subtleties. Let’s work through it!</p><h3 id=signing-up-for-an-account>Signing Up For An Account</h3><p>Our user lands on the account sign up page and fills out the form, providing their <code>username</code>, <code>email</code>, and <code>password</code>.</p><p><img src=https://arkwright.github.io/images/event-sourcing/api-gateway.svg loading=lazy alt="Diagram of smiley face connecting to an API Gateway service over HTTP. I don&rsquo;t know why a smiley face would do that, but I also don&rsquo;t want to judge."></p><p>The user submits the form and an HTTP request is sent to our API Gateway service, which is the public-facing portion of our system. It might implement server-side rendered views, or it might expose an API or <a class=link href=http://samnewman.io/patterns/architectural/bff/ target=_blank rel=noopener>Backend For Frontend (BFF)</a> for a single-page or mobile application to consume.</p><p>We want to build this application in a microservice style, and so we have decided to delegate ownership of all write-related user logic to a User Command service.</p><p><img src=https://arkwright.github.io/images/event-sourcing/signup-fail.svg loading=lazy alt="Diagram of a neutral face emoji sending a request to an API Gateway, which optimistically sends an AccountSignUp event to the event log, both synchronously. The event log is asynchronously read by the User Command service, but validation is unsuccessful, as indicated by a smiling poop emoji who exclaims, &lsquo;Fail!&rsquo; The neutral face emoji is returned a &lsquo;success&rsquo; response, but there are no successes here. Only nightmares. I think my emoji game is improving."></p><p>We might be tempted to have the API Gateway publish an <code>AccountSignUp</code> event, which our User Command service would listen for and process. After all, this is how a lot of event-driven architectures behave — the user <em>did a thing</em> that the system can react to. Unfortunately this creates a huge UX problem: we lose the ability to provide immediate feedback to the user. There is no guarantee that the User Command service is currently available — it could be overloaded, or it might have crashed. If we publish an <code>AccountSignUp</code> event and some of the form data is invalid, we have no way of informing the user. The best we can do would be to display an optimistic “success” message, <em>hope</em> that the form data is valid, <em>hope</em> that the user account is persisted, and <em>hope</em> that, should any errors occur, the user would return to our website to try again.</p><p>The breakthrough approach here, for me, was when I understood that in an event sourced system, all of the <em>writes</em> must occur to the event log. It could be interesting or useful to log some of the antecedent details (such as requests), but the only thing we really <em>must</em> do is ensure that all writes are modeled as log appends.</p><p><img src=https://arkwright.github.io/images/event-sourcing/signup-success.svg loading=lazy alt="Diagram of smiling face emoji connecting synchronously to the API gateway, which POSTs to a /users endpoint on the User Command service, which in turn sends a synchronous AccountCreated event to the Event Log. Because the User Command service performed pessimistic validation, the success message returned to the smiling face emoji is an honest-to-goodness success."></p><p>If the user interface requires a synchronous response for immediate feedback, so be it. We can achieve this in the traditional, RESTful way, by having the API Gateway issue an HTTP request to the User Command service. Perhaps this would be modeled as a <code>POST /users</code> endpoint. The User Command service would perform any validations, write an <code>AccountCreated</code> event to the event log, and return a <code>201 Created</code> response to the API Gateway. The API Gateway would then render a success message for the user. The user account creation is considered to be a success — a historical fact — at the moment the log append occurs. (Greg Young <a class=link href="https://youtu.be/8JKjvY4etTY?t=3m3s" target=_blank rel=noopener>emphasizes the importance</a> of storing only facts in our event log.)</p><h3 id=failure-modes>Failure Modes</h3><p>Let’s think about how this part of the system would handle various failures:</p><ul><li>If the API Gateway’s HTTP request to the User Command service fails, the API Gateway can immediately render an error message for the user. The user is then able to retry their request.</li><li>If any of the form validations fail, the User Command service can return a <code>400 Bad Request</code> error to the API Gateway, which in turn can render field errors for the user.</li><li>If the event log is unavailable and the User Command service cannot write to it, the User Command service can return a <code>500 Internal Server Error</code> to the API Gateway. The API Gateway can then render an error message for the user, who may retry their request.</li><li>If the User Command service successfully writes to the event log and then dies, or its HTTP response is not delivered to the API Gateway, then the API Gateway will render an error message for the user, believing the User Command service to be unavailable. The user might then retry their request, if they don’t notice their account activation email first! This could result in a second <code>AccountCreated</code> event being published to the log. It is therefore important that consumers of the event log implement their consumption in an idempotent way.</li></ul><p><img src=https://arkwright.github.io/images/event-sourcing/poops.svg loading=lazy alt="Cartoon of two poop emojis, one bigger than another. I actually drew these as practice for other drawings, but they turned out alright and I thought, &lsquo;Hey, why not decorate with poop?&rsquo;"></p><h3 id=validation>Validation</h3><p>Whenever we are working with user generated data, there is always some validation that must occur. We can think of a few common constraints for our account sign up form:</p><ol><li>The <code>username</code> cannot be blank.</li><li>The <code>email</code> cannot be blank.</li><li>The <code>password</code> cannot be blank.</li><li>No two user accounts should have the same <code>username</code>.</li><li>No two user accounts should have the same <code>email</code>.</li></ol><p>To accommodate some of these rules, we will need to think a bit differently than we are used to.</p><p>Ensuring that fields are not blank can be accomplished in the obvious way: the User Command service checks for the existence and length of these values and returns the appropriate error code to the API Gateway in the event of an invalid submission.</p><p>But how can we enforce the constraints that no two accounts should have the same <code>username</code> or <code>email</code>? If we were using an ACID-compliant relational database, this would be easily achievable by adding a <code>UNIQUE</code> constraint to the <code>username</code> and <code>email</code> columns — the database would thereafter refuse to insert duplicates. Since our event log is not a relational database, we will have to devise another way.</p><p>Naturally, the mind will wonder if the User Command service could first read from the database used to store its corresponding read model, searching for duplicate values — if a duplicate is found, do not write to the event log. And this approach would <em>appear</em> to work at first, but due to the eventually consistent property of our system, writes to the event log are not immediately reflected in the various read models that our services maintain. A race condition has been introduced: it is possible to create two user accounts with duplicate data in rapid succession, because we cannot guarantee that the read model will be up to date with the first write at the time that the second write occurs.</p><p><img src=https://arkwright.github.io/images/event-sourcing/race-condition.svg loading=lazy alt="Diagram of Darth Vader and a Smiley emoji sending concurrent requests for the username &lsquo;dvader&rsquo; to the User Command service. User Command first checks the Database to see if that username is taken, but in both cases it is not! User Command then writes two AccountCreated events to the Event Log. The Database asynchronously reads those events from the Event Log, accidentally creating duplicate &lsquo;dvader&rsquo; accounts. A poop emoji beams a gigantic smile from within the database, because our data is now&mldr; inconsistent."></p><p>I can’t remember where I first encountered the following solution, but it struck me as a novel and contrarian approach with a lot of utility: why not simply embrace the fact that the system no longer provides an immediate consistency guarantee? We could design our system to gracefully handle some the uniqueness constraints in a different way:</p><ol><li>We could allow duplicate accounts to be created with the same email address, and simply ignore all but the first creation event. If a user accidentally signs up twice, only one account will be created. The total order of our log messages ensures that these two events will always be processed in the same order. This approach has the undesirable effect of including two account creation events in the log, which might be confusing.</li><li>We could allow more than one user to enjoy the same username. Why not? Social networks allow users to change their names at will. A surrogate key (e.g. universally unique identifier) can be used for internal purposes. The user’s email address can be used for login purposes.</li><li>We could shamelessly violate <a class=link href=https://martinfowler.com/bliki/CQRS.html target=_blank rel=noopener>CQRS</a> and perform a kind of optimistic concurrency control by allowing the read model to detect when a duplicate username is about to be inserted, and then <em>modify the username</em> to preserve its uniqueness. For example, <code>dvader</code> might be renamed to <code>dvader_1</code>. Finally, the read model would emit another event to notify the user that they should change their username. This seems like a contrived and impractical solution, but consider what happens in macOS when a file is copied and pasted on top of itself: instead of throwing an error, the operating system allows the paste, and automatically renames the second version to be <code>file 2</code>. Still, I don’t like the conflation of read/write concerns.</li></ol><p>For our user sign up flow, I think we can eliminate the uniqueness constraint for usernames. But what about email addresses? I would prefer not to have duplicate account creation events in the log if we can avoid it.</p><p><img src=https://arkwright.github.io/images/event-sourcing/lock-tag.svg loading=lazy alt="Cartoon of a &lsquo;dvader@empire.gov&rsquo; name tag with a small lock (perhaps one of those airport suitcase locks) shackled through it. The lock isn&rsquo;t attached to anything else. This is a metaphor, okay. Visual metaphors aren&rsquo;t supposed to take the complexities of life into account. Whatever."></p><h3 id=locks>Locks</h3><p>We could make judicious use of locks to enforce a uniqueness constraint for email addresses.</p><p><img src=https://arkwright.github.io/images/event-sourcing/lock-service.svg loading=lazy alt="Diagram of Darth Vader, who clearly has too much time on his hands, requesting a &lsquo;dvader&rsquo; account from the User Command service. User Command requests a lock on the username &lsquo;dvader&rsquo; from the Lock service, which replies with &lsquo;Cool.&rsquo;, as services do. 200 OK, Cool. Anyways, User Command next sends an AccountCreated event for &lsquo;dvader&rsquo; to the event log."></p><p>We would add a new Lock service to our ecosystem. The Lock service does what it says on the tin: other services can use it to obtain a lock on a resource before writing to it. This could be as simple as an HTTP service wrapping a transactional data store, but probably we would want to reach for an off-the-shelf solution.</p><p>When requesting a lock, services would specify a key which uniquely identifies the resource. For example, the key might be <code>dvader@empire.gov</code>. The corresponding value would be a unique identifier representing the service instance requesting the lock.</p><p>After successfully acquiring a lock on an email address, the User Command service can safely publish an event to create an account, or change a user’s email address. Since only the service instance which holds the lock has permission to perform writes which involve that email address, duplicate account creation events are thereby prevented.</p><p>When the write is successful, the User Command service can release the lock by sending another request to the Lock service. If this is not done, no further writes which involve that email address could be made! The lock would be stored with a time-to-live so that, in the event that the User Command service dies before it can release its lock, the lock is automatically released, preventing a deadlock.</p><p>Unfortunately, there are problems with this approach.</p><h3 id=temporal-anomalies>Temporal Anomalies</h3><p>Kleppmann does a <a class=link href=https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html target=_blank rel=noopener>great job</a> of explaining why timing-based lock algorithms cannot prevent errors. As it turns out, as soon as we apply a time-to-live to the lock, it becomes unreliable. For example, a long GC pause in a service could actually exceed the time-to-live on our lock, allowing the same lock to be acquired twice! And even if only a small number of locking errors occur during the lifetime of the application, allowing a few duplicate writes to leak through, we will need to modify <em>all</em> event log consumers to handle that exceptional case. If the event stream contains even <em>one</em> duplicate, from the consumer’s perspective it might as well contain a million of them.</p><p>If we remove the time-to-live from the lock, we will be okay until the User Command service dies immediately after acquiring the lock, but before writing the new user account. When the service restarts after this error, we will be deadlocked. The user will be unable to retry their account creation, because their email address is now permanently locked.</p><p><img src=https://arkwright.github.io/images/event-sourcing/deadlock.svg loading=lazy alt="Diagram of Darth Vader, whom I can now draw from memory, requesting user name &lsquo;dvader&rsquo; from the User Command service. User Command requests a lock on &lsquo;dvader&rsquo; from the Lock service, but explodes in a horrifying nuclear blast after acquiring the lock. User Command fails to send an event to the Event Log, and we are now deadlocked. Now would be a good time to find somebody to blame."></p><p>Really, what we need to do is <a class=link href=https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying target=_blank rel=noopener>“squeeze all the non-determinism out of the input stream”</a>. Kleppmann provides two strategies for achieving this.</p><h3 id=fencing-tokens>Fencing Tokens</h3><p>The first strategy is to have the Lock service implment a <a class=link href=https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html target=_blank rel=noopener>fencing token</a>. Basically, each time a lock is acquired, the Lock service assigns a monotonically increasing integer to the lock. If the same lock is accidentally acquired twice due to temporal anomalies, each version of the lock will have a different integer associated with it. Requests to write must then supply the integer, and the service which handles the writes is responsible for ignoring writes whose integer is not larger than that of the previous write.</p><p><img src=https://arkwright.github.io/images/event-sourcing/fencing-token.svg loading=lazy alt="Diagram of Darth Vader and, later, a Stormtrooper, attempting to create account &lsquo;dvader&rsquo;. User Command service acquires a lock with fencing token #1 for Darth Vader&rsquo;s attempt, and publishes an AccountCreated event, which somehow becomes very delayed in transit. Meanwhile, User Command does the same thing for Stormtrooper&rsquo;s request, acquiring fencing token #2, and promptly delivering an event to the Event Log. The effect is that Stormtrooper&rsquo;s event was sent after, but arrives before, Darth Vader&rsquo;s event. The Database, when asynchronously reading these events, reads Stormtrooper&rsquo;s request first, which contains fencing token #2. Next, when Database reads Darth Vader&rsquo;s request, complete with fencing token #1, it rejects it, because fencing tokens are invalid if received in decreasing order."></p><p>Notice something about this strategy? It looks awfully similar to a totally ordered log! This implies that a log-oriented solution might be possible. It also requires a heck of a lot of plumbing, in my opinion. Each service responsible for writing to a locked resource must understand and correctly implement the monotonically increasing integer check.</p><h3 id=filtering-duplicates>Filtering Duplicates</h3><p>Kleppmann’s <a class=link href=https://www.infoq.com/presentations/event-streams-kafka target=_blank rel=noopener>second strategy</a> is a log-oriented one. Basically, services wishing to acquire a lock publish a request event to a topic within the event log. A consumer service (similar to our Lock service) reads those events and essentially filters out duplicates, finally publishing a different event (the actual write) to a different topic within the event log. If the consumer service dies, it can simply reconstruct its state by replaying log events.</p><p><img src=https://arkwright.github.io/images/event-sourcing/deduplicator.svg loading=lazy alt="Diagram of Darth Vader and Boba Fett both requesting account &lsquo;dvader&rsquo; from the User Command service, which publishes two events to the Request Log. A Deduplicator service asynchronously reads from this log and writes a single event to the Write Log, representing the winning request. A database finally asynchronously reads the winning request from the Write Log, and creates a user account for real. Both Darth Vader and Boba Fett receive optimistic &lsquo;success&rsquo; messages. They are gonna be pissed later. To be honest, I&rsquo;m choosing Star Wars characters entirely based on how easy it is to draw their heads, which in practice means I&rsquo;m using only people who wear helmets. I tried drawing Yoda but honestly that was a bad idea. Same for Chewbacca. Same for R2D2. Same for C3P0. I&rsquo;m trying, okay?"></p><p>This is a very clever solution, built out of simple components, and it relieves the services handling writes from the responsibility of implementing a fencing token. Unfortunately the cost of this simplicity is losing the ability to provide a synchronous response to the user — we can’t tell them if their write was successful, because consumption of the event log might be delayed. I wonder if we can come up with a reusable solution which allows us to provide immediate feedback to the user?</p><h3 id=uniq-service>Uniq Service</h3><p>Recall the distributed-systems-as-Unix-pipes philosophy. It might be possible to create a composable Uniq service — similar to the Unix <code>uniq</code> command — which could be reused across multiple services for their event deduplication and locking needs.</p><p><img src=https://arkwright.github.io/images/event-sourcing/pipes.svg loading=lazy alt="Handwritten version of the following, for emphasis: uniq_service | uniq | event log"></p><p>How would this Uniq service work? All write events subject to uniqueness constraints would be sent to Uniq for deduplication and constraint checking purposes, before being forwarded on to the event log. Uniq could expose a RESTful API for create, update, and delete operations, . An <code>/event</code> endpoint would do nicely.</p><p><img src=https://arkwright.github.io/images/event-sourcing/uniq.svg loading=lazy alt="Diagram of Darth Vader and X-Wing Pilot Luke Skywalker (with helmet!) sending simultaneous requests for account &lsquo;dvader&rsquo; to the User Command service. User Command attempts to publish two AccountCreated events through the stateful Uniq service, which rejects the second request because &lsquo;dvader&rsquo; is already taken. Darth Vader&rsquo;s request receives a 200 OK, and Luke Skywalker&rsquo;s receives a 409 Conflict. But don&rsquo;t worry, in the movie Luke totally wins, or at least they end up on the same team. Finally, the successful AccountCreated event is synchronously written by the Uniq service to the event log. Uniq is acting in a write-through capacity, here."></p><p>When performing user account creation, the User Command service would construct its desired log message and <code>POST</code> it to the Uniq service. Uniq would support a simple configuration file which maps fields of log messages to CRUD operations. For example, when Uniq receives our <code>AccountCreated</code> event, it would extract the <code>email</code> field from that event and add that email to a set it maintains in memory. If the email does not already exist in the set, Uniq writes that event to the log, and returns a <code>200 OK</code> response. In this way, Uniq can provide a synchronous response to our User Command service, which facilitates immediate feedback for the user. Uniq acts as a proxy for events — just another piece of the pipeline.</p><p>If an email address already exists in the set, Uniq would return a <code>409 Conflict</code> response, and would <em>not</em> forward the event to the log. Use cases involving changing or deleting an existing email address are easily supported by the HTTP <code>PATCH</code> and <code>DELETE</code> semantics. Unlike the Unix <code>uniq</code>, our Uniq requires these semantics because it is stateful. It isn’t simply counting unique items, but rather allowing that set of unique items to be maintained in the face of change.</p><p>Of course, given that Uniq will be maintaining a set in memory, we must consider what will happen in the event that it crashes. If this were to occur, Uniq can rebuild its set by re-consuming log messages. When Uniq has caught up with where it left off, it can accept write traffic again. Because our log is totally ordered, and because Uniq processes write requests serially, it should never commit a duplicate write to the log, even when recovering from an outage.</p><p>If availability is a concern, a second instance of Uniq can operate in follower mode, consuming from the event log to maintain a replica of the leader’s state. When the leader dies, the follower can be promoted to leader.</p><h3 id=relational-database-envy>Relational Database Envy</h3><p>So we have our strategy for handling concurrent requests for user accounts with the same email address: we will pipe all writes through a Uniq service, which enforces the uniqueness constraint.</p><p>Couldn’t we have used a relational database to enforce this constraint instead? Well, yes, we could. Michael Ploed makes the <a class=link href="https://youtu.be/A0goyZ9F4bg?t=50m14s" target=_blank rel=noopener>wise recommendation</a> that we implement the level of consistency that our business domain requires. The ideal level of consistency for one subsystem may not be needed across the entire system. For example, it might be considered unacceptable for two user accounts to <em>ever</em> accidentally share the same email address, since this would prevent users from logging in. Therefore, we can enforce a uniqueness constraint only for email addresses, paying the complexity cost because we see it as justifiable. But for other subsystems where we might traditionally enforce a uniqueness constraint, we could employ more creative solutions. We are dialing in the amount of consistency that each part of the system requires.</p><p>So it would make sense for the User Command service to write to a relational database implementing a uniqueness constraint. But this approach creates one very unfortunate side-effect: we lose atomicity. Writing a new user to the database, and <em>then</em> writing an event to the log, opens the possibility that the first write will succeed but the second one will fail. This situation would render our data inconsistent, and a compensating transaction would be required to reconcile the two. Dual writes strike again!</p><p><img src=https://arkwright.github.io/images/event-sourcing/atomicity.svg loading=lazy alt="Diagram of user wearing fashionable top hat sending a request to the User Command service, which performs an ill-advised dual write, first to a database, and then to an Event Log. Skull and crossbones indicates that the second write is headed for a grim fate."></p><p>It might be possible to create a second table in our relational database, and write our events to that table. We could then wrap both our user write and the event write in a transaction, regaining atomicity. But now we need a way to get those events <em>out</em> of the database and into the event log, and ideally without implementing a polling strategy, which would increase replication lag. The amount of plumbing required to make this happen is excessive, in my opinion. And the solution wouldn’t be reusable across services.</p><h3 id=the-read-model>The Read Model</h3><p>So our User Command service is able to write an <code>AccountCreated</code> event to the log via the Uniq service. But how would we handle reads? One cannot simply perform queries against an event log, since query performance would decrease as the log grows in size! To support reads, we will need to implement a <em>read model</em>.</p><p>The read model consists a service wrapping a persistence mechanism. Most likely we would choose a database which provides a good fit for the types of queries we will be performing. For our User Query service we will assume a document database which stores JSON-like documents.</p><p><img src=https://arkwright.github.io/images/event-sourcing/read-model.svg loading=lazy alt="Diagram of Event Log containing names of Star Wars characters, being asynchronously read by a User Query service, which synchronously writes those characters to its own private database, in a denormalized schema, for later querying."></p><p>The read model will consume relevant events from the event log, and update its database accordingly. In the case of the User Query service, every <code>AccountCreated</code> event consumed would trigger the insertion of a new user document into the database.</p><p>Where this pattern can become very powerful is in maintaining highly optimized, incrementally computed query results. One could imagine introducing a Friends service which maintains a list of frequently contacted friends for each user, entirely derived from log messages. Batch computing this contact frequency information could take a long time, and the results would quickly become stale. Incrementally computing with each new piece of information can provide a more consistent view, while maintaining fast query response times.</p><p>Another interesting property is the potential for the elimination of schema migrations. Denormalizing the read model brings the possibility of introducing NoSQL stores. The addition of a new field would be handled in application code, and a schema “rollback”, if one were required, could be accomplished by reverting the application code and replaying events from the affected period.</p><h3 id=sending-mail>Sending Mail</h3><p>After our user has signed up, we want to send them an account activation email. To accomplish this, we will create a Mail service which monitors the event log for <code>AccountCreated</code> events, and sends activation emails to those users, probably by calling the RESTful API of a third-party email provider.</p><p><img src=https://arkwright.github.io/images/event-sourcing/mail.svg loading=lazy alt="Diagram of Event Log being asynchronously read by Mail service, which sends requests to a Fancy Cloud Email Co., represented by a huge factory puffing clouds of smoke. Cloud, get it? After each email is sent, Mail service writes a checkpoint corresponding to the event processed to a Checkpoint log. I had way too much fun trying to figure out how to draw the Fancy Cloud Email Co."></p><p>But what happens if the Mail service crashes after reading a message from the log? As it turns out, this is not a problem, provided that the mail service persists the ID of the last message it consumed — a <em>checkpoint</em>. And where better to persist this ID than to a topic within the event log!</p><p>How frequently should we store checkpoints? If we store a checkpoint for every message consumed, log consumption speed will be limited by the need to write a checkpoint in between every read. If this was inadequate for our purposes, we could have the Mail service store a checkpoint every hundred writes, or every thousand, or every 60 seconds. But then wouldn’t we be at risk of sending a hundred, or a thousand, or 60 seconds worth of duplicate emails if the Mail service crashes?</p><p>As it turns out, the Mail service cannot guarantee exactly-once delivery of emails to users. Let’s say that the Mail service has already consumed event 1, and is now consuming event 2 from the log. If an email is sent and the service crashes before checkpoint 2 can be written, when the service restarts it will begin working from the next event after its last checkpoint. The last checkpoint was 1, so event 2 will be processed again. A duplicate email will be sent!</p><p><img src=https://arkwright.github.io/images/event-sourcing/duplicates.svg loading=lazy alt="Diagram of Event Log being asynchronously consumed by Mail service, which is on fire. Drawing fire is tricky, let me tell you. I added some smoke lines to really make the effect. Anyways, Mail service sends an email to Fancy Cloud Email Co. and then suddenly dies before it can write to the Checkpoint log. Another instance Mail service, which has restarted, reads the checkpoint, reads from the event log, and sends the same email again! Finally, restarted Mail service writes a checkpoint successfully, absolutely not dying in the process. All of this to send an email. But also to prove that it&rsquo;s impossible to avoid sending duplicate emails."></p><p>Writing the checkpoint before sending the email will only make things worse. If we store checkpoint 2 and then crash before sending email 2, when the service restarts it will begin working from the next event after its last checkpoint. The last checkpoint was 2, so event 3 will be processed. In this case, event 2 will be skipped!</p><p>Since we cannot prevent the Mail service from sending duplicate emails, and since it would be a Very Bad Thing™ to fail to send any account activation emails, we can feel a bit better about setting a less frequent checkpoint rate.</p><h3 id=dependency-woes>Dependency Woes</h3><p>It is a prudent exercise to think about what would happen if our third-party email provider were to suffer various failures.</p><p>If for any reason our Mail service does not receive a response from the provider, we can retry the request. In fact, we <em>need</em> to retry the request, because the log-oriented nature of our system can only guarantee that all events are processed if they are handled sequentially. If we start skipping events, we would need to enqueue those skipped events into — you guessed it — another log for later processing. It’s logs all the way down.</p><p><img src=https://arkwright.github.io/images/event-sourcing/retries.svg loading=lazy alt="Diagram of Mail service asynchronously reading from the Event Log, and retrying attempts to send email to Fancy Cloud Email Co., which is on fire right now. I mean like, really on fire. So much so that a stick figure person wearing a top hat is holding their hand up and saying, &lsquo;Now is not a good time.&rsquo; That&rsquo;s a lot of fire. So the retries keep coming and the top hat person keeps saying no, and we never find out how this episode ends."></p><p>So the system will guarantee delivery by <em>pausing</em> when an error occurs, polling for success, and resuming when the error condition has passed. This entails installing a <a class=link href=https://martinfowler.com/bliki/CircuitBreaker.html target=_blank rel=noopener>circuit breaker</a> to gate calls to the email provider. If the provider becomes unresponsive, the Mail service will retry the request repeatedly until the circuit breaker trips, at which point it will retry the request at a slower rate. When the provider comes back online, a request will eventually be successful and the Mail service can catch up with its backlog.</p><h3 id=thats-all-folks>That’s All, Folks</h3><p>Our toy system is now complete. Obviously this represents merely the user signup flow for what would be a much larger application. I would go on, but as you can see, even this slice of architecture requires a lengthy description. Nevertheless, I hope this has been a useful dive into the finer details how we might go implementing such a system. I know I’ve learned a lot while writing it!</p><p><img src=https://arkwright.github.io/images/event-sourcing/architecture.svg loading=lazy alt="Diagram of the final architecture, just so we&rsquo;re on the same page. Darth Vader (naturally) sends a request to API Gateway, which forwards it to User Command, which writes an event through Uniq (for deduplication), which lands in the Event Log. User Query asynchronously reads from Event Log to update its own User Database. Mail also asynchronously reads from Event Log in order to send requests to Fancy Cloud Email Co. Really, it&rsquo;s not as complicated as it looks. It&rsquo;s kind of like modern art. Some people look at it and are all like, &lsquo;I could totally do that.&rsquo; Well, yeah, you probably could. In fact, I think that&rsquo;s kind of the point."></p><h2 id=where-do-we-go-from-here>Where do we go from here?</h2><p>Event sourcing is a radically different way of looking at software architecture. Predictably, this new approach is not without its learning curve. It also comes with tantalizing potential benefits. The question is how to sensibly proceed.</p><p>I am reminded of Spolsky’s <a class=link href=https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/ target=_blank rel=noopener>Law of Leaky Abstractions</a>. Event sourcing is just another abstraction which seeks to simplify the complexity of the software we write. Naturally, this abstraction will leak, creating problems for us. But it is important to keep in mind that the monolithic, relational, strongly consistent style of architecture is <em>also</em> an abstraction. Our comfort with the abstraction we know too often spares us the terrifying advantages of new ways of doing things!</p><p>One thing I have learned over the years is that I can never predict the practical consequences of introducing an unfamiliar technique into an organization. Because something always goes wrong, we actually <em>need</em> to implement the technique to discover where it breaks down. Only after introduction can we identify the concrete problems, and begin to devise solutions.</p><p>The knowledge that something <em>will</em> go wrong is often used as a justification for not experimenting with new techniques at all. “We’ll revisit this discussion <em>later</em>.” Later effectively means never. Interestingly, this seems to be the wrong conclusion to draw from the mere possibility of risk. Problems may be unavoidable, but we have the power to control the scope of the introduction, and thereby shape the size of the problems encountered. Given that we possess a “risk knob” which we can dial down to comfortable levels, what justification remains for failing to experiment with new techniques?</p><p>I think the most sensible course of action is to treat event sourcing as an evolutionary pattern. Incorporate this pattern into a portion of your project — get your feet wet. But don’t dive in, because you’ll probably drown. But don’t stay out of the pool, because then you’ll never learn to swim! Learning takes time, so the sooner you can get started, the sooner you can determine how to incorporate the benefits while mitigating the pitfalls. As the <a class=link href=http://nicholaskuechler.com/2006/10/23/favorite-quotes-chinese-proverb-best-time-to-plant-a-tree/ target=_blank rel=noopener>famous Chinese proverb</a> says:</p><blockquote><p>“The best time to [begin reinforcing event sourcing patterns] was 20 [sprints] ago.”</p></blockquote><p><img src=https://arkwright.github.io/images/event-sourcing/ants.svg loading=lazy alt="Picture of a bunch of ants marching towards an anthill, and walking inside. I was considering using this as the title graphic, but I went with the insects instead. It&rsquo;s all about artistic choices."></p><p>from Hacker News <a class=link href=https://ift.tt/2ZBtKHW target=_blank rel=noopener>https://ift.tt/2ZBtKHW</a></p></section><footer class=article-footer><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg><span>Licensed under CC BY-NC-SA 4.0</span></section></footer></article><footer class=site-footer><section class=copyright>&copy;
2020 -
2022 ZYChimne</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.11.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css integrity="sha256-c0uckgykQ9v5k+IqViZOZKc47Jn7KQil4/MP3ySA3F8=" crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.css integrity="sha256-SBLU4vv6CA6lHsZ1XyTdhyjJxCjPif/TRkjnsyGAGnE=" crossorigin=anonymous></main><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#may-the-source-be-with-you>May the source be with you.</a></li><li><a href=#things-we-will-talk-about>Things We Will Talk About</a></li><li><a href=#what-the-hell-is-event-sourcing>What the hell is event sourcing?</a></li><li><a href=#what-can-event-sourcing-do-for-me>What can event sourcing do for me?</a><ol><li><a href=#historical-queries>Historical Queries</a></li><li><a href=#immutable-data>Immutable Data</a></li><li><a href=#time-traveling-debugging>Time-Traveling Debugging</a></li><li><a href=#easily-connect-data-consumers>Easily Connect Data Consumers</a></li><li><a href=#reasonable-scaling-defaults>Reasonable Scaling Defaults</a></li><li><a href=#fault-tolerance-and-resiliency>Fault Tolerance and Resiliency</a></li><li><a href=#mitigation-of-data-inconsistencies>Mitigation of Data Inconsistencies</a></li><li><a href=#simplicity>Simplicity</a></li><li><a href=#forgiving-of-mistakes>Forgiving Of Mistakes</a></li><li><a href=#ends-normalization-debate>Ends Normalization Debate</a></li><li><a href=#audit-trail>Audit Trail</a></li><li><a href=#better-business-agility>Better Business Agility</a></li></ol></li><li><a href=#what-might-event-sourcing-look-like-in-practice>What might event sourcing look like in practice?</a><ol><li><a href=#signing-up-for-an-account>Signing Up For An Account</a></li><li><a href=#failure-modes>Failure Modes</a></li><li><a href=#validation>Validation</a></li><li><a href=#locks>Locks</a></li><li><a href=#temporal-anomalies>Temporal Anomalies</a></li><li><a href=#fencing-tokens>Fencing Tokens</a></li><li><a href=#filtering-duplicates>Filtering Duplicates</a></li><li><a href=#uniq-service>Uniq Service</a></li><li><a href=#relational-database-envy>Relational Database Envy</a></li><li><a href=#the-read-model>The Read Model</a></li><li><a href=#sending-mail>Sending Mail</a></li><li><a href=#dependency-woes>Dependency Woes</a></li><li><a href=#thats-all-folks>That’s All, Folks</a></li></ol></li><li><a href=#where-do-we-go-from-here>Where do we go from here?</a></li></ol></nav></div></section></aside></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.5/dist/vibrant.min.js integrity="sha256-5NovOZc4iwiAWTYIFiIM7DxKUXKWvpVEuMEPLzcm5/g=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script>
<script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>