<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Fly brain inspires computing algorithm Flies use an algorithmic neuronal strategy to sense and categorize odors. Dasgupta et al. applied insights from the fly system to come up with a solution to a computer science problem. On the basis of the algorithm that flies use to tag an odor and categorize similar ones, the authors generated a new solution to the nearest-neighbor search problem that underlies tasks such as searching for similar images on the web."><title>A neural algorithm for similarity search (2017)</title><link rel=canonical href=https://Nexus-Security.github.io/posts/2016-09-09-a-neural-algorithm-for-similarity/><link rel=stylesheet href=/scss/style.min.450926226e724574a6b936335ea06111f8aeb253d932c86cb2cc807341cd2889.css><meta property="og:title" content="A neural algorithm for similarity search (2017)"><meta property="og:description" content="Fly brain inspires computing algorithm Flies use an algorithmic neuronal strategy to sense and categorize odors. Dasgupta et al. applied insights from the fly system to come up with a solution to a computer science problem. On the basis of the algorithm that flies use to tag an odor and categorize similar ones, the authors generated a new solution to the nearest-neighbor search problem that underlies tasks such as searching for similar images on the web."><meta property="og:url" content="https://Nexus-Security.github.io/posts/2016-09-09-a-neural-algorithm-for-similarity/"><meta property="og:site_name" content="ZYChimne"><meta property="og:type" content="article"><meta property="article:section" content="Posts"><meta property="article:published_time" content="2019-10-28T06:27:00+01:00"><meta property="article:modified_time" content="2019-10-28T06:27:00+01:00"><meta name=twitter:title content="A neural algorithm for similarity search (2017)"><meta name=twitter:description content="Fly brain inspires computing algorithm Flies use an algorithmic neuronal strategy to sense and categorize odors. Dasgupta et al. applied insights from the fly system to come up with a solution to a computer science problem. On the basis of the algorithm that flies use to tag an odor and categorize similar ones, the authors generated a new solution to the nearest-neighbor search problem that underlies tasks such as searching for similar images on the web."></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hue825486955cd7c56d95e38b4bd2a8e3c_229979_300x0_resize_box_3.png width=300 height=300 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>ZYChimne</a></h1><h2 class=site-description>Computer Science, Wuhan University</h2></div></header><ol class=social-menu><li><a href=https://github.com/Nexus-Security target=_blank title=GitHub><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=mailto:0x000216@gmail.com target=_blank title=Email><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-gmail" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#2c3e50" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M16 20h3a1 1 0 001-1V5a1 1 0 00-1-1h-3v16z"/><path d="M5 20h3V4H5A1 1 0 004 5v14a1 1 0 001 1z"/><path d="M16 4l-4 4-4-4"/><path d="M4 6.5l8 7.5 8-7.5"/></svg></a></li><li><a href=https://www.buymeacoffee.com/0x000216 target=_blank title=Coffee><svg width="884" height="1279" viewBox="0 0 884 1279" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg"><defs><path d="M0 0H884V1279H0V0z" id="path_1"/><clipPath id="mask_1"><use xlink:href="#path_1"/></clipPath></defs><g id="buymeacoffee"><path d="M0 0H884V1279H0V0z" id="Background" fill="none" fill-rule="evenodd" stroke="none"/><g clip-path="url(#mask_1)"><path d="M791.109 297.518 790.231 297.002 788.201 296.383C789.018 297.072 790.04 297.472 791.109 297.518z" id="Shape" fill="#0d0c22" stroke="none"/><path d="M803.916 388.891l-1 1 1-1z" id="Shape" fill="#0d0c22" stroke="none"/><path d="M792.113 297.647C791.776 297.581 791.447 297.462 791.127 297.29 791.108 297.622 791.108 297.958 791.127 298.29 791.488 298.216 791.83 297.995 792.113 297.647z" id="Shape" fill="#0d0c22" stroke="none"/><path d="M791.113 298.447h1v-1l-1 1z" id="Shape" fill="#0d0c22" stroke="none"/><path d="M803.111 388.726 804.591 387.883 805.142 387.573 805.641 387.04C804.702 387.444 803.846 388.016 803.111 388.726z" id="Shape" fill="#0d0c22" stroke="none"/><path d="M793.669 299.515 792.223 298.138 791.243 297.605C791.77 298.535 792.641 299.221 793.669 299.515z" id="Shape" fill="#0d0c22" stroke="none"/><path d="M430.019 1186.18C428.864 1186.68 427.852 1187.46 427.076 1188.45L427.988 1187.87C428.608 1187.3 429.485 1186.63 430.019 1186.18z" id="Shape" fill="#0d0c22" stroke="none"/><path d="M641.681 1144.63C641.681 1143.33 640.424 1143.57 640.729 1148.21 640.729 1147.84 641.035 1147.46 641.171 1147.1 641.341 1146.27 641.477 1145.46 641.681 1144.63z" id="Shape" fill="#0d0c22" stroke="none"/><path d="M619.284 1186.18C618.129 1186.68 617.118 1187.46 616.342 1188.45L617.254 1187.87C617.873 1187.3 618.751 1186.63 619.284 1186.18z" id="Shape" fill="#0d0c22" stroke="none"/><path d="M281.304 1196.06C280.427 1195.3 279.354 1194.8 278.207 1194.61 279.136 1195.06 280.065 1195.51 280.684 1195.85L281.304 1196.06z" id="Shape" fill="#0d0c22" stroke="none"/><path d="M247.841 1164.01C247.704 1162.66 247.288 1161.35 246.619 1160.16 247.093 1161.39 247.489 1162.66 247.806 1163.94L247.841 1164.01z" id="Shape" fill="#0d0c22" stroke="none"/><path d="M472.623 590.836c-45.941 19.667-98.077 41.966-165.647 41.966C278.71 632.746 250.58 628.868 223.353 621.274l46.733 479.806C271.74 1121.13 280.876 1139.83 295.679 1153.46 310.482 1167.09 329.87 1174.65 349.992 1174.65 349.992 1174.65 416.254 1178.09 438.365 1178.09 462.161 1178.09 533.516 1174.65 533.516 1174.65c20.12.0 39.503-7.57000000000016 54.303-21.2C602.619 1139.82 611.752 1121.13 613.406 1101.08l50.053-530.204C641.091 563.237 618.516 558.161 593.068 558.161 549.054 558.144 513.591 573.303 472.623 590.836z" id="Shape" fill="#fff" stroke="none"/><path d="M78.6885 386.132 79.4799 386.872 79.9962 387.182C79.5987 386.787 79.1603 386.435 78.6885 386.132z" id="Shape" fill="#0d0c22" stroke="none"/><path d="M879.567 341.849 872.53 306.352C866.215 274.503 851.882 244.409 819.19 232.898 808.711 229.215 796.821 227.633 788.786 220.01 780.751 212.388 778.376 200.55 776.518 189.572 773.076 169.423 769.842 149.257 766.314 129.143 763.269 111.85 760.86 92.4243 752.928 76.56c-10.324-21.3016-31.746-33.7591-53.048-42.001C688.965 30.4844 677.826 27.0375 666.517 24.2352 613.297 10.1947 557.342 5.03277 502.591 2.09047 436.875-1.53577 370.983-.443233 305.422 5.35968 256.625 9.79894 205.229 15.1674 158.858 32.0469c-16.948 6.1771-34.413 13.593-47.3 26.6872C95.7448 74.8221 90.5829 99.7026 102.128 119.765c8.208 14.247 22.111 24.313 36.857 30.972C158.192 159.317 178.251 165.846 198.829 170.215c57.297 12.664 116.642 17.636 175.178 19.753C438.887 192.586 503.87 190.464 568.44 183.618 584.408 181.863 600.347 179.758 616.257 177.304 634.995 174.43 647.022 149.928 641.499 132.859 634.891 112.453 617.134 104.538 597.055 107.618 594.095 108.082 591.153 108.512 588.193 108.942L586.06 109.252C579.257 110.113 572.455 110.915 565.653 111.661c-14.052 1.514-28.138 2.753-42.259 3.717C491.768 117.58 460.057 118.595 428.363 118.647c-31.144.0-62.305-.878-93.38-2.92500000000001C320.805 114.793 306.661 113.611 292.552 112.177 286.134 111.506 279.733 110.801 273.333 110.009L267.241 109.235 265.917 109.046 259.602 108.134C246.697 106.189 233.792 103.953 221.025 101.251 219.737 100.965 218.584 100.249 217.758 99.2193 216.932 98.1901 216.482 96.9099 216.482 95.5903 216.482 94.2706 216.932 92.9904 217.758 91.9612 218.584 90.9319 219.737 90.2152 221.025 89.9293H221.266C232.33 87.5721 243.479 85.5589 254.663 83.8038 258.392 83.2188 262.131 82.6453 265.882 82.0832H265.985C272.988 81.6186 280.026 80.3625 286.994 79.5366 347.624 73.2302 408.614 71.0801 469.538 73.1014 499.115 73.9618 528.676 75.6996 558.116 78.6935 564.448 79.3474 570.746 80.0357 577.043 80.8099 579.452 81.1025 581.878 81.4465 584.305 81.7391L589.191 82.4445C603.438 84.5667 617.61 87.1419 631.708 90.1703 652.597 94.7128 679.422 96.1925 688.713 119.077 691.673 126.338 693.015 134.408 694.649 142.03L696.731 151.752C696.786 151.926 696.826 152.105 696.852 152.285 701.773 175.227 706.7 198.169 711.632 221.111 711.994 222.806 712.002 224.557 711.657 226.255 711.312 227.954 710.621 229.562 709.626 230.982 708.632 232.401 707.355 233.6 705.877 234.504 704.398 235.408 702.75 235.997 701.033 236.236H700.895L697.884 236.649 694.908 237.044C685.478 238.272 676.038 239.419 666.586 240.486 647.968 242.608 629.322 244.443 610.648 245.992 573.539 249.077 536.356 251.102 499.098 252.066 480.114 252.57 461.135 252.806 442.162 252.771 366.643 252.712 291.189 248.322 216.173 239.625 208.051 238.662 199.93 237.629 191.808 236.58 198.106 237.389 187.231 235.96 185.029 235.651 179.867 234.928 174.705 234.177 169.543 233.397 152.216 230.798 134.993 227.598 117.7 224.793 96.7944 221.352 76.8005 223.073 57.8906 233.397c-15.5221 8.494-28.0851 21.519-36.013 37.338-8.1559 16.862-10.582 35.221-14.22974 53.34-3.64777 18.118-9.32591 37.613-7.17511 56.213C5.10128 420.431 33.165 453.054 73.5313 460.35 111.506 467.232 149.687 472.807 187.971 477.556 338.361 495.975 490.294 498.178 641.155 484.129 653.44 482.982 665.708 481.732 677.959 480.378 681.786 479.958 685.658 480.398 689.292 481.668S696.23 485.005 698.962 487.717 703.784 493.718 705.08 497.342C706.377 500.967 706.846 504.836 706.453 508.665L702.633 545.797c-7.697 75.031-15.394 150.057-23.091 225.077-8.029 78.783-16.111 157.56-24.244 236.326C653.004 1029.39 650.71 1051.57 648.416 1073.74 646.213 1095.58 645.904 1118.1 641.757 1139.68 635.218 1173.61 612.248 1194.45 578.73 1202.07 548.022 1209.06 516.652 1212.73 485.161 1213.01 450.249 1213.2 415.355 1211.65 380.443 1211.84 343.173 1212.05 297.525 1208.61 268.756 1180.87 243.479 1156.51 239.986 1118.36 236.545 1085.37 231.957 1041.7 227.409 998.039 222.9 954.381L197.607 711.615 181.244 554.538C180.968 551.94 180.693 549.376 180.435 546.76 178.473 528.023 165.207 509.681 144.301 510.627 126.407 511.418 106.069 526.629 108.168 546.76l12.13 116.454 25.087 240.89C152.532 972.528 159.661 1040.96 166.773 1109.41 168.15 1122.52 169.44 1135.67 170.885 1148.78 178.749 1220.43 233.465 1259.04 301.224 1269.91 340.799 1276.28 381.337 1277.59 421.497 1278.24 472.979 1279.07 524.977 1281.05 575.615 1271.72 650.653 1257.95 706.952 1207.85 714.987 1130.13 717.282 1107.69 719.576 1085.25 721.87 1062.8 729.498 988.559 737.115 914.313 744.72 840.061l24.881-242.61 11.408-111.188C781.577 480.749 783.905 475.565 787.649 471.478 791.392 467.391 796.352 464.617 801.794 463.567 823.25 459.386 843.761 452.245 859.023 435.916c24.295-25.998 29.13-59.895 20.544-94.067zM72.7365 365.835C73.247 365.68 72.3065 368.484 71.9034 369.792 71.8229 367.813 71.984 366.058 72.7365 365.835zm1.7756 16.105C74.6842 381.819 75.2003 382.508 75.7337 383.334 74.925 382.576 74.4089 382.009 74.4949 381.94H74.5121zM76.5597 384.641C77.6004 385.897 78.1569 386.689 76.5597 384.641zM80.7002 387.979h.2727C80.9729 388.313 81.473 388.645 81.6548 388.979 81.3533 388.612 81.0186 388.277 80.6548 387.979H80.7002zM800.796 382.989C793.088 390.319 781.473 393.726 769.996 395.43c-128.704 19.099-259.283 28.769-389.399 24.502C287.476 416.749 195.336 406.407 103.144 393.382 94.1102 392.109 84.3197 390.457 78.1082 383.798c-11.7004-12.561-5.9534-37.854-2.9079-53.03C77.9878 316.865 83.3218 298.334 99.8572 296.355 125.667 293.327 155.64 304.218 181.175 308.09 211.917 312.781 242.774 316.538 273.745 319.36 405.925 331.405 540.325 329.529 671.92 311.91 695.905 308.686 719.805 304.941 743.619 300.674 764.835 296.871 788.356 289.731 801.175 311.703 809.967 326.673 811.137 346.701 809.778 363.615 809.359 370.984 806.139 377.915 800.779 382.989H800.796z" id="Shape" fill="#fff" fill-rule="evenodd" stroke="none"/></g></g></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg><span>Home</span></a></li><li><a href=/about-me/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg><span>About Me</span></a></li><div class=menu-bottom-section><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><span>Dark Mode</span></li></div></ol></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><div class=article-title-wrapper><h2 class=article-title><a href=/posts/2016-09-09-a-neural-algorithm-for-similarity/>A neural algorithm for similarity search (2017)</a></h2></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg><time class=article-time--published>Oct 28, 2019</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><time class=article-time--reading>15 minute read</time></div></footer></div></header><section class=article-content><p><img src=https://science.sciencemag.org/sites/default/files/highwire/sci/358/6364.cover-source.gif loading=lazy></p><h2 id=fly-brain-inspires-computing-algorithm>Fly brain inspires computing algorithm</h2><p>Flies use an algorithmic neuronal strategy to sense and categorize odors. Dasgupta <em>et al.</em> applied insights from the fly system to come up with a solution to a computer science problem. On the basis of the algorithm that flies use to tag an odor and categorize similar ones, the authors generated a new solution to the nearest-neighbor search problem that underlies tasks such as searching for similar images on the web.</p><p><em>Science</em>, this issue p. <a class=link href=https://science.sciencemag.org/lookup/doi/10.1126/science.aam9868 target=_blank rel=noopener>793</a></p><h2 id=abstract>Abstract</h2><p>Similarity search—for example, identifying similar images in a database or similar documents on the web—is a fundamental computing problem faced by large-scale information retrieval systems. We discovered that the fruit fly olfactory circuit solves this problem with a variant of a computer science algorithm (called locality-sensitive hashing). The fly circuit assigns similar neural activity patterns to similar odors, so that behaviors learned from one odor can be applied when a similar odor is experienced. The fly algorithm, however, uses three computational strategies that depart from traditional approaches. These strategies can be translated to improve the performance of computational similarity searches. This perspective helps illuminate the logic supporting an important sensory function and provides a conceptually new algorithm for solving a fundamental computational problem.</p><p>An essential task of many neural circuits is to generate neural activity patterns in response to input stimuli, so that different inputs can be specifically identified. We studied the circuit used to process odors in the fruit fly olfactory system and uncovered computational strategies for solving a fundamental machine learning problem: approximate similarity (or nearest-neighbors) search.</p><p>The fly olfactory circuit generates a “tag” for each odor, which is a set of neurons that fire when that odor is presented (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-1 target=_blank rel=noopener><em>1</em></a>). This tag is critical for learning behavioral responses to different odors (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-2 target=_blank rel=noopener><em>2</em></a>). For example, if a reward (e.g., sugar water) or a punishment (e.g., electric shock) is associated with an odor, that odor becomes attractive (a fly will approach the odor) or repulsive (a fly will avoid the odor), respectively. The tags assigned to odors are sparse—only a small fraction of the neurons that receive odor information respond to each odor (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-3 target=_blank rel=noopener><em>3</em></a>–<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-5 target=_blank rel=noopener><em>5</em></a>)—and nonoverlapping: Tags for two randomly selected odors share few, if any, active neurons, so that different odors can be easily distinguished (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-1 target=_blank rel=noopener><em>1</em></a>).</p><p>The tag for an odor is computed by a three-step procedure (<a class=link href=https://science.sciencemag.org/content/358/6364/793#F1 target=_blank rel=noopener>Fig. 1A</a>). The first step involves feedforward connections from odorant receptor neurons (ORNs) in the fly’s nose to projection neurons (PNs) in structures called glomeruli. There are 50 ORN types, each with a different sensitivity and selectivity for different odors. Thus, each input odor has a location in a 50-dimensional space determined by the 50 ORN firing rates. For each odor, the distribution of ORN firing rates across the 50 ORN types is exponential, with a mean that depends on the concentration of the odor (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-6 target=_blank rel=noopener><em>6</em></a>, <a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-7 target=_blank rel=noopener><em>7</em></a>). For the PNs, this concentration dependence is removed (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-7 target=_blank rel=noopener><em>7</em></a>, <a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-8 target=_blank rel=noopener><em>8</em></a>); that is, the distribution of firing rates across the 50 PN types is exponential, with close to the same mean for all odors and all odor concentrations (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-1 target=_blank rel=noopener><em>1</em></a>). Thus, the first step in the circuit essentially “centers the mean”—a standard preprocessing step in many computational pipelines—using a technique called divisive normalization (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-8 target=_blank rel=noopener><em>8</em></a>). This step is important so that the fly does not mix up odor intensity with odor type.</p><p>Fig. 1 Mapping between the fly olfactory circuit and locality-sensitive hashing (LSH).</p><p>(<strong>A</strong>) Schematic of the fly olfactory circuit. In step 1, 50 ORNs in the fly’s nose send axons to 50 PNs in the glomeruli; as a result of this projection, each odor is represented by an exponential distribution of firing rates, with the same mean for all odors and all odor concentrations. In step 2, the PNs expand the dimensionality, projecting to 2000 KCs connected by a sparse, binary random projection matrix. In step 3, the KCs receive feedback inhibition from the anterior paired lateral (APL) neuron, which leaves only the top 5% of KCs to remain firing spikes for the odor. This 5% corresponds to the tag (hash) for the odor. (<strong>B</strong>) Illustrative odor responses. Similar pairs of odors (e.g., methanol and ethanol) are assigned more similar tags than are dissimilar odors. Darker shading denotes higher activity. (<strong>C</strong>) Differences between conventional LSH and the fly algorithm. In the example, the computational complexity for LSH and the fly are the same. The input dimensionality <em>d</em> = 5. LSH computes <em>m</em> = 3 random projections, each of which requires 10 operations (five multiplications plus five additions). The fly computes <em>m</em> = 15 random projections, each of which requires two addition operations. Thus, both require 30 total operations. <strong>x</strong>, input feature vector; <em>r</em>, Gaussian random variable; <em>w</em>, bin width constant for discretization.</p><p>The second step, where the main algorithmic insight begins, involves a 40-fold expansion in the number of neurons: Fifty PNs project to 2000 Kenyon cells (KCs), connected by a sparse, binary random connection matrix (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-9 target=_blank rel=noopener><em>9</em></a>). Each KC receives and sums the firing rates from about six randomly selected PNs (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-9 target=_blank rel=noopener><em>9</em></a>). The third step involves a winner-take-all (WTA) circuit in which strong inhibitory feedback comes from a single inhibitory neuron, called APL (anterior paired lateral neuron). As a result, all but the highest-firing 5% of KCs are silenced (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-1 target=_blank rel=noopener><em>1</em></a>, <a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-3 target=_blank rel=noopener><em>3</em></a>, <a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-4 target=_blank rel=noopener><em>4</em></a>). The firing rates of these remaining 5% correspond to the tag assigned to the input odor.</p><p>From a computer science perspective, we view the fly’s circuit as a hash function, whose input is an odor and whose output is a tag (called a hash) for that odor. Although tags should discriminate odors, it is also to the fly’s advantage to associate very similar odors with similar tags (<a class=link href=https://science.sciencemag.org/content/358/6364/793#F1 target=_blank rel=noopener>Fig. 1B</a>), so that conditioned responses learned for one odor can be applied when a very similar odor, or a noisy version of the learned odor, is experienced. This led us to conjecture that the fly’s circuit produces tags that are locality-sensitive; that is, the more similar a pair of odors (as defined by the 50 ORN firing rates for that odor), the more similar their assigned tags. Locality-sensitive hash [LSH (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-10 target=_blank rel=noopener><em>10</em></a>, <a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-11 target=_blank rel=noopener><em>11</em></a>)] functions serve as the foundation for solving numerous similarity search problems in computer science. We translated insights from the fly’s circuit to develop a class of LSH algorithms for efficiently finding approximate nearest neighbors of high-dimensional points.</p><p>Imagine that you are provided an image of an elephant and seek to find the 100 images—out of the billions of images on the web—that look most similar to your elephant image. This is called the nearest-neighbors search problem, which is of fundamental importance in information retrieval, data compression, and machine learning (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-10 target=_blank rel=noopener><em>10</em></a>). Each image is typically represented as a <em>d</em>-dimensional vector of feature values. (Each odor that a fly processes is a 50-dimensional feature vector of firing rates.) A distance metric is used to compute the similarity between two images (feature vectors), and the goal is to efficiently find the nearest neighbors of any query image. If the web contained only a few images, then brute force linear search could easily be used to find the exact nearest neighbors. If the web contained many images, but each image was represented by a low-dimensional vector (e.g., 10 or 20 features), then space-partitioning methods (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-12 target=_blank rel=noopener><em>12</em></a>) would similarly suffice. However, for large databases with high-dimensional data, neither approach scales (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-11 target=_blank rel=noopener><em>11</em></a>).</p><p>In many applications, returning an approximate set of nearest neighbors that are “close enough” to the query is adequate, so long as they can be found quickly. This has motivated an approach for finding approximate nearest neighbors by LSH (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-10 target=_blank rel=noopener><em>10</em></a>). For the fly, as noted, the locality-sensitive property states that two odors that generate similar ORN responses will be represented by two tags that are themselves similar (<a class=link href=https://science.sciencemag.org/content/358/6364/793#F1 target=_blank rel=noopener>Fig. 1B</a>). Likewise, for image search, the tag of an elephant image will be more similar to the tag of another elephant image than to the tag of a skyscraper image.</p><p>Unlike a traditional (non-LSH) hash function, where the input points are scattered randomly and uniformly over the range, a LSH function provides a distance-preserving embedding of points from <em>d</em>-dimensional space into <em>m</em>-dimensional space (the latter corresponds to the tag). Thus, points that are closer to one another in input space have a higher probability of being assigned the same or a similar tag than points that are far apart. [A formal definition is given in (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-13 target=_blank rel=noopener><em>13</em></a>).]</p><p>To design a LSH function, one common trick is to compute random projections of the input data (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-10 target=_blank rel=noopener><em>10</em></a>, <a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-11 target=_blank rel=noopener><em>11</em></a>)—that is, to multiply the input feature vector by a random matrix. The Johnson-Lindenstrauss lemma (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-14 target=_blank rel=noopener><em>14</em></a>, <a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-15 target=_blank rel=noopener><em>15</em></a>) and its many variants (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-16 target=_blank rel=noopener><em>16</em></a>–<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-18 target=_blank rel=noopener><em>18</em></a>) provide strong theoretical bounds on how well locality is preserved when embedding data from <em>d</em> into <em>m</em> dimensions by using various types of random projections.</p><p>The fly also assigns tags to odors through random projections (step 2 in <a class=link href=https://science.sciencemag.org/content/358/6364/793#F1 target=_blank rel=noopener>Fig. 1A</a>; 50 PNs <em>→</em> 2000 KCs), which provides a key clue to the function of this part of the circuit. There are, however, three differences between the fly algorithm and conventional LSH algorithms. First, the fly uses sparse, binary random projections, whereas LSH functions typically use dense, Gaussian random projections that require many more mathematical operations to compute. Second, the fly expands the dimensionality of the input after projection (<em>d</em> « <em>m</em>), whereas LSH reduces the dimensionality (<em>d</em> » <em>m</em>). Third, the fly sparsifies the higher-dimensionality representation by a WTA mechanism, whereas LSH preserves a dense representation.</p><p>In the supplementary materials (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-13 target=_blank rel=noopener><em>13</em></a>), we show analytically that sparse, binary random projections of the type in the fly olfactory circuit generate tags that preserve the neighborhood structure of input points. This proves that the fly’s circuit represents a previously unknown LSH family.</p><p>We then empirically evaluated the fly algorithm versus traditional LSH (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-10 target=_blank rel=noopener><em>10</em></a>, <a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-11 target=_blank rel=noopener><em>11</em></a>) on the basis of how precisely each algorithm could identify nearest neighbors of a given query point. To perform a fair comparison, we fixed the computational complexity of both algorithms to be the same (<a class=link href=https://science.sciencemag.org/content/358/6364/793#F1 target=_blank rel=noopener>Fig. 1C</a>). That is, the two approaches were fixed to use the same number of mathematical operations to generate a hash of length <em>k</em> (i.e., a vector with <em>k</em> nonzero values) for each input (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-13 target=_blank rel=noopener><em>13</em></a>).</p><p>We compared the two algorithms for finding nearest neighbors in three benchmark data sets: SIFT (<em>d</em> = 128), GLOVE (<em>d</em> = 300), and MNIST (<em>d</em> = 784) (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-13 target=_blank rel=noopener><em>13</em></a>). SIFT and MNIST both contain vector representations of images used for image similarity search, whereas GLOVE contains vector representations of words used for semantic similarity search. We used a subset of each data set with 10,000 inputs each, in which each input was represented as a feature vector in <em>d</em>-dimensional space. To test performance, we selected 1000 random query inputs from the 10,000 and compared true versus predicted nearest neighbors. That is, for each query, we found the top 2% (200) of its true nearest neighbors in input space, determined on the basis of Euclidean distance between feature vectors. We then found the top 2% of predicted nearest neighbors in <em>m</em>-dimensional hash space, determined on the basis of the Euclidean distance between tags (hashes). We varied the length of the hash (<em>k</em>) and computed the overlap between the ranked lists of true and predicted nearest neighbors by using the mean average precision (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-19 target=_blank rel=noopener><em>19</em></a>). We averaged the mean average precision over 50 trials, in which, for each trial, the random projection matrices and the queries changed. We isolated each of the three differences between the fly algorithm and LSH to test their individual effect on nearest-neighbors retrieval performance.</p><p>Replacing the dense Gaussian random projection of LSH with a sparse binary random projection did not hurt how precisely nearest neighbors could be identified (<a class=link href=https://science.sciencemag.org/content/358/6364/793#F2 target=_blank rel=noopener>Fig. 2A</a>). These results support our theoretical calculations that the fly’s random projection is locality-sensitive. Moreover, the sparse, binary random projection achieved a computational savings of a factor of 20 relative to the dense, Gaussian random projection (fig. S1) (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-13 target=_blank rel=noopener><em>13</em></a>).</p><p>Fig. 2 Empirical comparison of different random projection types and tag-selection methods.</p><p>In all plots, the <em>x</em> axis is the length of the hash, and the <em>y</em> axis is the mean average precision denoting how accurately the true nearest neighbors are found (higher is better). (<strong>A</strong>) Sparse, binary random projections offer near-identical performance to that of dense, Gaussian random projections, but the former provide a large savings in computation. (<strong>B</strong>) The expanded-dimension (from <em>k</em> to 20_k_) plus winner-take-all (WTA) sparsification further boosts performance relative to non-expansion. Results are consistent across all three benchmark data sets. Error bars indicate standard deviation over 50 trials.</p><p>When expanding the dimensionality, sparsifying the tag using WTA resulted in better performance than using random tag selection (<a class=link href=https://science.sciencemag.org/content/358/6364/793#F2 target=_blank rel=noopener>Fig. 2B</a>). WTA selected the top <em>k</em> firing KCs as the tag, unlike random tag selection, which selected <em>k</em> random KCs. For both, we used 20_k_ random projections for the fly to equate the number of mathematical operations used by the fly and LSH (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-13 target=_blank rel=noopener><em>13</em></a>). For example, for the SIFT data set with hash length <em>k</em> = 4, random selection yielded a 17.7% mean average precision, versus roughly double that (32.4%) using WTA. Thus, selecting the top firing neurons best preserves relative distances between inputs; the increased dimensionality also makes it easier to segregate dissimilar inputs. For random tag selection, we selected <em>k</em> random (but fixed for all inputs) KCs for the tag; hence, its performance is effectively the same as doing <em>k</em> random projections, as in LSH.</p><p>With further expansion of the dimensionality (from 20_k_ to 10_d_ KCs, closer to the actual fly’s circuitry), we obtained further gains relative to LSH in identifying nearest neighbors across all data sets and hash lengths (<a class=link href=https://science.sciencemag.org/content/358/6364/793#F3 target=_blank rel=noopener>Fig. 3</a>). The gains were highest for very short hash lengths, where there was an almost threefold improvement in mean average precision (e.g., for MNIST with <em>k</em> = 4, 16.0% for LSH, versus 44.8% for the fly algorithm).</p><p>Fig. 3 Overall comparison between the fly algorithm and LSH.</p><p>In all plots, the <em>x</em> axis is the length of the hash, and the <em>y</em> axis is the mean average precision (higher is better). A 10_d_ expansion was used for the fly. Across all three data sets, the fly’s method outperforms LSH, most prominently for short hash lengths. Error bars indicate standard deviation over 50 trials.</p><p>We also found similar gains in performance when testing the fly algorithm in higher dimensions and for binary LSH (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-20 target=_blank rel=noopener><em>20</em></a>) (figs. S2 to S3). Thus, the fly algorithm is scalable and may be useful across other LSH families.</p><p>Our work identified a synergy between strategies for similarity matching in the brain (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-21 target=_blank rel=noopener><em>21</em></a>) and hashing algorithms for nearest-neighbors search in large-scale information retrieval systems. It may also have applications in duplicate detection, clustering, and energy-efficient deep learning (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-22 target=_blank rel=noopener><em>22</em></a>). There are numerous extensions to LSH (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-23 target=_blank rel=noopener><em>23</em></a>), including the use of multiple hash tables (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-11 target=_blank rel=noopener><em>11</em></a>) to boost precision (we used one for both algorithms), the use of multiprobe (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-24 target=_blank rel=noopener><em>24</em></a>) so that similar tags can be grouped together (which may be easier to implement for the fly algorithm because tags are sparse), various quantization tricks for discretizing hashes (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-25 target=_blank rel=noopener><em>25</em></a>), and learning [called data-dependent hashing (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-13 target=_blank rel=noopener><em>13</em></a>)]. There are also methods to speed up the random projection multiplication, both for LSH schemes by fast Johnson-Lindenstrauss transforms (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-26 target=_blank rel=noopener><em>26</em></a>, <a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-27 target=_blank rel=noopener><em>27</em></a>) and for the fly by fast sparse matrix multiplication. Our goal was to fairly compare two conceptually different approaches for the nearest-neighbors search problem; in practical applications, all of these extensions will need to be ported to the fly algorithm.</p><p>Some of the fly algorithm’s strategies have been used before. For example, MinHash (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-28 target=_blank rel=noopener><em>28</em></a>) and winner-take-all hash (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-29 target=_blank rel=noopener><em>29</em></a>) both use WTA-like components, though neither propose expanding the dimensionality; similarly, random projections are used in many LSH families, but none, to our knowledge, use sparse, binary projections. The fly olfactory circuit appears to have evolved to use a distinctive combination of these computational ingredients. The three hallmarks of the fly’s circuit motif may also appear in other brain regions and species (<a class=link href=https://science.sciencemag.org/content/358/6364/793#T1 target=_blank rel=noopener>Table 1</a>). Thus, locality-sensitive hashing may be a general principle of computation used in the brain (<a class=link href=https://science.sciencemag.org/content/358/6364/793#ref-30 target=_blank rel=noopener><em>30</em></a>).</p><p>Table 1 The generality of locality-sensitive hashing in the brain.</p><p>Shown are the steps used in the fly olfactory circuit and their potential analogs in vertebrate brain regions.</p><h2 id=references-and-notes>References and Notes</h2><ol><li><a class=link href=https://science.sciencemag.org/content/358/6364/793#xref-ref-1-1 title="View reference 1 in text" target=_blank rel=noopener>↵</a></li><li><a class=link href=https://science.sciencemag.org/content/358/6364/793#xref-ref-2-1 title="View reference 2 in text" target=_blank rel=noopener>↵</a></li><li><a class=link href=https://science.sciencemag.org/content/358/6364/793#xref-ref-3-1 title="View reference 3 in text" target=_blank rel=noopener>↵</a></li><li><a class=link href=https://science.sciencemag.org/content/358/6364/793#xref-ref-4-1 title="View reference 4 in text" target=_blank rel=noopener>↵</a></li><li><a class=link href=https://science.sciencemag.org/content/358/6364/793#xref-ref-5-1 title="View reference 5 in text" target=_blank rel=noopener>↵</a></li><li><a class=link href=https://science.sciencemag.org/content/358/6364/793#xref-ref-6-1 title="View reference 6 in text" target=_blank rel=noopener>↵</a></li><li><a class=link href=https://science.sciencemag.org/content/358/6364/793#xref-ref-7-1 title="View reference 7 in text" target=_blank rel=noopener>↵</a></li><li><a class=link href=https://science.sciencemag.org/content/358/6364/793#xref-ref-8-1 title="View reference 8 in text" target=_blank rel=noopener>↵</a></li><li><a class=link href=https://science.sciencemag.org/content/358/6364/793#xref-ref-9-1 title="View reference 9 in text" target=_blank rel=noopener>↵</a></li><li><a class=link href=https://science.sciencemag.org/content/358/6364/793#xref-ref-10-1 title="View reference 10 in text" target=_blank rel=noopener>↵</a></li><li><a class=link href=https://science.sciencemag.org/content/358/6364/793#xref-ref-11-1 title="View reference 11 in text" target=_blank rel=noopener>↵</a></li></ol><pre><code>A. Gionis, P. Indyk, R. Motwani, in _VLDB’99, Proceedings of the 25th International Conference on Very Large Data Bases_, M. P. Atkinson _et al_., Eds. (Morgan Kaufman, 1999), pp. 158–529.
</code></pre><ol start=12><li><a class=link href=https://science.sciencemag.org/content/358/6364/793#xref-ref-12-1 title="View reference 12 in text" target=_blank rel=noopener>↵</a></li></ol><pre><code>H. Samet, _Foundations of Multidimensional and Metric Data Structures_ (Morgan Kaufmann Series in Computer Graphics and Geometric Modeling, Morgan Kaufmann, 2005).
</code></pre><ol start=13><li><a class=link href=https://science.sciencemag.org/content/358/6364/793#xref-ref-13-1 title="View reference 13 in text" target=_blank rel=noopener>↵</a>Materials and methods are available as supplementary materials.</li><li><a class=link href=https://science.sciencemag.org/content/358/6364/793#xref-ref-14-1 title="View reference 14 in text" target=_blank rel=noopener>↵</a></li></ol><pre><code>W. Johnson, J. Lindenstrauss, in _Conference on Modern Analysis and Probability_, R. Beals, A. Beck, A. Bellow, A. Hajian, Eds., vol. 26 of _Contemporary Mathematics_ (American Mathematical Society, 1984), pp. 189–206.
</code></pre><ol start=15><li><a class=link href=https://science.sciencemag.org/content/358/6364/793#xref-ref-15-1 title="View reference 15 in text" target=_blank rel=noopener>↵</a></li><li><a class=link href=https://science.sciencemag.org/content/358/6364/793#xref-ref-16-1 title="View reference 16 in text" target=_blank rel=noopener>↵</a></li><li><a class=link href=https://science.sciencemag.org/content/358/6364/793#xref-ref-18-1 title="View reference 18 in text" target=_blank rel=noopener>↵</a></li><li><a class=link href=https://science.sciencemag.org/content/358/6364/793#xref-ref-19-1 title="View reference 19 in text" target=_blank rel=noopener>↵</a></li></ol><pre><code>Y. Lin, R. Jin, D. Cai, S. Yan, X. Li, in _2013 IEEE Conference on Computer Vision and Pattern Recognition_ (IEEE Computer Society, 2013), pp. 446–451.
</code></pre><ol start=19><li><a class=link href=https://science.sciencemag.org/content/358/6364/793#xref-ref-20-1 title="View reference 20 in text" target=_blank rel=noopener>↵</a></li></ol><pre><code>M. S. Charikar, in _Proceedings of the Thirty-Fourth Annual ACM Symposium on Theory of Computing_, _STOC ’02_ \[Association for Computing Machinery (ACM), 2002\], pp. 380–388.
</code></pre><ol start=20><li><a class=link href=https://science.sciencemag.org/content/358/6364/793#xref-ref-21-1 title="View reference 21 in text" target=_blank rel=noopener>↵</a></li></ol><pre><code>C. Pehlevan, D. B. Chklovskii, in _NIPS’15, Proceedings of the 28th International Conference on Neural Information Processing Systems_ (MIT Press, 2015), pp. 2269–2277.
</code></pre><ol start=21><li><a class=link href=https://science.sciencemag.org/content/358/6364/793#xref-ref-22-1 title="View reference 22 in text" target=_blank rel=noopener>↵</a></li><li><a class=link href=https://science.sciencemag.org/content/358/6364/793#xref-ref-23-1 title="View reference 23 in text" target=_blank rel=noopener>↵</a></li><li><a class=link href=https://science.sciencemag.org/content/358/6364/793#xref-ref-24-1 title="View reference 24 in text" target=_blank rel=noopener>↵</a></li></ol><pre><code>Q. Lv, W. Josephson, Z. Wang, M. Charikar, K. Li, in _VLDB ’07, Proceedings of the 33rd International Conference on Very Large Data Bases_ (ACM, 2007), pp. 950–961.
</code></pre><ol start=24><li><a class=link href=https://science.sciencemag.org/content/358/6364/793#xref-ref-25-1 title="View reference 25 in text" target=_blank rel=noopener>↵</a></li></ol><pre><code>P. Li, M. Mitzenmacher, A. Shrivastava, in _Proceedings of the 31st International Conference on Machine Learning_ (Proceedings of Machine Learning Research, 2014), pp. 676–684.
</code></pre><ol start=25><li><a class=link href=https://science.sciencemag.org/content/358/6364/793#xref-ref-26-1 title="View reference 26 in text" target=_blank rel=noopener>↵</a></li></ol><pre><code>A. Dasgupta, R. Kumar, T. Sarlos, in _KDD ’11, The 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining_ (ACM, 2011), pp. 1073–1081.
</code></pre><ol start=26><li><a class=link href=https://science.sciencemag.org/content/358/6364/793#xref-ref-27-1 title="View reference 27 in text" target=_blank rel=noopener>↵</a></li></ol><pre><code>A. Andoni, P. Indyk, T. Laarhoven, I. Razenshteyn, L. Schmidt, in _NIPS’15, Proceedings of the 28th International Conference on Neural Information Processing Systems_ (MIT Press, 2015), pp. 1225–1233.
</code></pre><ol start=27><li><a class=link href=https://science.sciencemag.org/content/358/6364/793#xref-ref-28-1 title="View reference 28 in text" target=_blank rel=noopener>↵</a></li></ol><pre><code>A. Broder, in _Proceedings of the Compression and Complexity of Sequences 1997_ (IEEE Computer Society, 1997), p. 21.
</code></pre><ol start=28><li><a class=link href=https://science.sciencemag.org/content/358/6364/793#xref-ref-29-1 title="View reference 29 in text" target=_blank rel=noopener>↵</a></li></ol><pre><code>J. Yagnik, D. Strelow, D. A. Ross, R.-s. Lin, in _2011 International Conference on Computer Vision_ (IEEE Computer Society, 2011), pp. 2431–2438.
</code></pre><ol start=29><li><p><a class=link href=https://science.sciencemag.org/content/358/6364/793#xref-ref-30-1 title="View reference 30 in text" target=_blank rel=noopener>↵</a></p></li><li><p><a class=link href=https://science.sciencemag.org/content/358/6364/793#xref-ref-31-1 title="View reference 31 in text" target=_blank rel=noopener>↵</a></p></li><li><p>J. Pennington, R. Socher, C. D. Manning, in <em>EMNLP 2014: The 2014 Conference on Empirical Methods in Natural Language Processing</em> (Association for Computational Linguistics, 2014), pp. 1532–1543.</p></li><li><p>Y. Weiss, A. Torralba, R. Fergus, in <em>Advances in Neural Information Processing Systems 21</em>, D. Koller, D. Schuurmans, Y. Bengio, L. Bottou, Eds. (Curran Associates, 2009), pp. 1753–1760.</p></li><li><p>H. Zhu, M. Long, J. Wang, Y. Cao, in <em>Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence</em> (AAAI Press, 2016), pp. 2415–2421.</p></li><li><p>K. Zhao, H. Lu, J. Mei, in <em>Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence</em> (AAAI Press, 2014), pp. 2874–2880.</p></li><li><p><a class=link href=https://science.sciencemag.org/content/358/6364/793#xref-ref-49-1 title="View reference 49 in text" target=_blank rel=noopener>↵</a></p></li></ol><p><strong>Acknowledgments:</strong></p><p>For funding support, C.F.S. thanks the NSF (grant EAGER PHY-1444273), and S.N. thanks the Army Research Office (grant DOD W911NF-17-1-0045). All authors thank A. Lang and J. Berkowitz for helpful comments on the manuscript. Code and data are available at</p><p><a class=link href=https://bitbucket.org/navlakha/flylsh target=_blank rel=noopener>https://bitbucket.org/navlakha/flylsh</a></p><p>.</p><p>from Hacker News <a class=link href=https://ift.tt/31OwscI target=_blank rel=noopener>https://ift.tt/31OwscI</a></p></section><footer class=article-footer><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg><span>Licensed under CC BY-NC-SA 4.0</span></section></footer></article><footer class=site-footer><section class=copyright>&copy;
2020 -
2022 ZYChimne</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.11.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css integrity="sha256-c0uckgykQ9v5k+IqViZOZKc47Jn7KQil4/MP3ySA3F8=" crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.css integrity="sha256-SBLU4vv6CA6lHsZ1XyTdhyjJxCjPif/TRkjnsyGAGnE=" crossorigin=anonymous></main><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#fly-brain-inspires-computing-algorithm>Fly brain inspires computing algorithm</a></li><li><a href=#abstract>Abstract</a></li><li><a href=#references-and-notes>References and Notes</a></li></ol></nav></div></section></aside></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.5/dist/vibrant.min.js integrity="sha256-5NovOZc4iwiAWTYIFiIM7DxKUXKWvpVEuMEPLzcm5/g=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script>
<script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>