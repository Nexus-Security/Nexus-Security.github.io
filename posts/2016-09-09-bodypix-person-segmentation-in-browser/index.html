<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="BodyPix - Person Segmentation in the Browser Note: We&amp;rsquo;ve just released Version 2.0 with multi-person support, a new ResNet model and API. Check out the new documentation below. This package contains a standalone model called BodyPix, as well as some demos, for running real-time person and body part segmentation in the browser using TensorFlow.js.
Try the demo here!
This model can be used to segment an image into pixels that are and are not part of a person, and into pixels that belong to each of twenty-four body parts."><title>BodyPix: Person Segmentation in the Browser</title><link rel=canonical href=https://Nexus-Security.github.io/posts/2016-09-09-bodypix-person-segmentation-in-browser/><link rel=stylesheet href=/scss/style.min.450926226e724574a6b936335ea06111f8aeb253d932c86cb2cc807341cd2889.css><meta property="og:title" content="BodyPix: Person Segmentation in the Browser"><meta property="og:description" content="BodyPix - Person Segmentation in the Browser Note: We&amp;rsquo;ve just released Version 2.0 with multi-person support, a new ResNet model and API. Check out the new documentation below. This package contains a standalone model called BodyPix, as well as some demos, for running real-time person and body part segmentation in the browser using TensorFlow.js.
Try the demo here!
This model can be used to segment an image into pixels that are and are not part of a person, and into pixels that belong to each of twenty-four body parts."><meta property="og:url" content="https://Nexus-Security.github.io/posts/2016-09-09-bodypix-person-segmentation-in-browser/"><meta property="og:site_name" content="ZYChimne"><meta property="og:type" content="article"><meta property="article:section" content="Posts"><meta property="article:published_time" content="2019-10-11T02:48:00+01:00"><meta property="article:modified_time" content="2019-10-11T02:48:00+01:00"><meta name=twitter:title content="BodyPix: Person Segmentation in the Browser"><meta name=twitter:description content="BodyPix - Person Segmentation in the Browser Note: We&amp;rsquo;ve just released Version 2.0 with multi-person support, a new ResNet model and API. Check out the new documentation below. This package contains a standalone model called BodyPix, as well as some demos, for running real-time person and body part segmentation in the browser using TensorFlow.js.
Try the demo here!
This model can be used to segment an image into pixels that are and are not part of a person, and into pixels that belong to each of twenty-four body parts."></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hue825486955cd7c56d95e38b4bd2a8e3c_229979_300x0_resize_box_3.png width=300 height=300 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>ZYChimne</a></h1><h2 class=site-description>Computer Science, Wuhan University</h2></div></header><ol class=social-menu><li><a href=https://github.com/Nexus-Security target=_blank title=GitHub><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=mailto:0x000216@gmail.com target=_blank title=Email><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-gmail" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#2c3e50" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M16 20h3a1 1 0 001-1V5a1 1 0 00-1-1h-3v16z"/><path d="M5 20h3V4H5A1 1 0 004 5v14a1 1 0 001 1z"/><path d="M16 4l-4 4-4-4"/><path d="M4 6.5l8 7.5 8-7.5"/></svg></a></li><li><a href=https://www.buymeacoffee.com/0x000216 target=_blank title=Coffee><svg width="884" height="1279" viewBox="0 0 884 1279" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg"><defs><path d="M0 0H884V1279H0V0z" id="path_1"/><clipPath id="mask_1"><use xlink:href="#path_1"/></clipPath></defs><g id="buymeacoffee"><path d="M0 0H884V1279H0V0z" id="Background" fill="none" fill-rule="evenodd" stroke="none"/><g clip-path="url(#mask_1)"><path d="M791.109 297.518 790.231 297.002 788.201 296.383C789.018 297.072 790.04 297.472 791.109 297.518z" id="Shape" fill="#0d0c22" stroke="none"/><path d="M803.916 388.891l-1 1 1-1z" id="Shape" fill="#0d0c22" stroke="none"/><path d="M792.113 297.647C791.776 297.581 791.447 297.462 791.127 297.29 791.108 297.622 791.108 297.958 791.127 298.29 791.488 298.216 791.83 297.995 792.113 297.647z" id="Shape" fill="#0d0c22" stroke="none"/><path d="M791.113 298.447h1v-1l-1 1z" id="Shape" fill="#0d0c22" stroke="none"/><path d="M803.111 388.726 804.591 387.883 805.142 387.573 805.641 387.04C804.702 387.444 803.846 388.016 803.111 388.726z" id="Shape" fill="#0d0c22" stroke="none"/><path d="M793.669 299.515 792.223 298.138 791.243 297.605C791.77 298.535 792.641 299.221 793.669 299.515z" id="Shape" fill="#0d0c22" stroke="none"/><path d="M430.019 1186.18C428.864 1186.68 427.852 1187.46 427.076 1188.45L427.988 1187.87C428.608 1187.3 429.485 1186.63 430.019 1186.18z" id="Shape" fill="#0d0c22" stroke="none"/><path d="M641.681 1144.63C641.681 1143.33 640.424 1143.57 640.729 1148.21 640.729 1147.84 641.035 1147.46 641.171 1147.1 641.341 1146.27 641.477 1145.46 641.681 1144.63z" id="Shape" fill="#0d0c22" stroke="none"/><path d="M619.284 1186.18C618.129 1186.68 617.118 1187.46 616.342 1188.45L617.254 1187.87C617.873 1187.3 618.751 1186.63 619.284 1186.18z" id="Shape" fill="#0d0c22" stroke="none"/><path d="M281.304 1196.06C280.427 1195.3 279.354 1194.8 278.207 1194.61 279.136 1195.06 280.065 1195.51 280.684 1195.85L281.304 1196.06z" id="Shape" fill="#0d0c22" stroke="none"/><path d="M247.841 1164.01C247.704 1162.66 247.288 1161.35 246.619 1160.16 247.093 1161.39 247.489 1162.66 247.806 1163.94L247.841 1164.01z" id="Shape" fill="#0d0c22" stroke="none"/><path d="M472.623 590.836c-45.941 19.667-98.077 41.966-165.647 41.966C278.71 632.746 250.58 628.868 223.353 621.274l46.733 479.806C271.74 1121.13 280.876 1139.83 295.679 1153.46 310.482 1167.09 329.87 1174.65 349.992 1174.65 349.992 1174.65 416.254 1178.09 438.365 1178.09 462.161 1178.09 533.516 1174.65 533.516 1174.65c20.12.0 39.503-7.57000000000016 54.303-21.2C602.619 1139.82 611.752 1121.13 613.406 1101.08l50.053-530.204C641.091 563.237 618.516 558.161 593.068 558.161 549.054 558.144 513.591 573.303 472.623 590.836z" id="Shape" fill="#fff" stroke="none"/><path d="M78.6885 386.132 79.4799 386.872 79.9962 387.182C79.5987 386.787 79.1603 386.435 78.6885 386.132z" id="Shape" fill="#0d0c22" stroke="none"/><path d="M879.567 341.849 872.53 306.352C866.215 274.503 851.882 244.409 819.19 232.898 808.711 229.215 796.821 227.633 788.786 220.01 780.751 212.388 778.376 200.55 776.518 189.572 773.076 169.423 769.842 149.257 766.314 129.143 763.269 111.85 760.86 92.4243 752.928 76.56c-10.324-21.3016-31.746-33.7591-53.048-42.001C688.965 30.4844 677.826 27.0375 666.517 24.2352 613.297 10.1947 557.342 5.03277 502.591 2.09047 436.875-1.53577 370.983-.443233 305.422 5.35968 256.625 9.79894 205.229 15.1674 158.858 32.0469c-16.948 6.1771-34.413 13.593-47.3 26.6872C95.7448 74.8221 90.5829 99.7026 102.128 119.765c8.208 14.247 22.111 24.313 36.857 30.972C158.192 159.317 178.251 165.846 198.829 170.215c57.297 12.664 116.642 17.636 175.178 19.753C438.887 192.586 503.87 190.464 568.44 183.618 584.408 181.863 600.347 179.758 616.257 177.304 634.995 174.43 647.022 149.928 641.499 132.859 634.891 112.453 617.134 104.538 597.055 107.618 594.095 108.082 591.153 108.512 588.193 108.942L586.06 109.252C579.257 110.113 572.455 110.915 565.653 111.661c-14.052 1.514-28.138 2.753-42.259 3.717C491.768 117.58 460.057 118.595 428.363 118.647c-31.144.0-62.305-.878-93.38-2.92500000000001C320.805 114.793 306.661 113.611 292.552 112.177 286.134 111.506 279.733 110.801 273.333 110.009L267.241 109.235 265.917 109.046 259.602 108.134C246.697 106.189 233.792 103.953 221.025 101.251 219.737 100.965 218.584 100.249 217.758 99.2193 216.932 98.1901 216.482 96.9099 216.482 95.5903 216.482 94.2706 216.932 92.9904 217.758 91.9612 218.584 90.9319 219.737 90.2152 221.025 89.9293H221.266C232.33 87.5721 243.479 85.5589 254.663 83.8038 258.392 83.2188 262.131 82.6453 265.882 82.0832H265.985C272.988 81.6186 280.026 80.3625 286.994 79.5366 347.624 73.2302 408.614 71.0801 469.538 73.1014 499.115 73.9618 528.676 75.6996 558.116 78.6935 564.448 79.3474 570.746 80.0357 577.043 80.8099 579.452 81.1025 581.878 81.4465 584.305 81.7391L589.191 82.4445C603.438 84.5667 617.61 87.1419 631.708 90.1703 652.597 94.7128 679.422 96.1925 688.713 119.077 691.673 126.338 693.015 134.408 694.649 142.03L696.731 151.752C696.786 151.926 696.826 152.105 696.852 152.285 701.773 175.227 706.7 198.169 711.632 221.111 711.994 222.806 712.002 224.557 711.657 226.255 711.312 227.954 710.621 229.562 709.626 230.982 708.632 232.401 707.355 233.6 705.877 234.504 704.398 235.408 702.75 235.997 701.033 236.236H700.895L697.884 236.649 694.908 237.044C685.478 238.272 676.038 239.419 666.586 240.486 647.968 242.608 629.322 244.443 610.648 245.992 573.539 249.077 536.356 251.102 499.098 252.066 480.114 252.57 461.135 252.806 442.162 252.771 366.643 252.712 291.189 248.322 216.173 239.625 208.051 238.662 199.93 237.629 191.808 236.58 198.106 237.389 187.231 235.96 185.029 235.651 179.867 234.928 174.705 234.177 169.543 233.397 152.216 230.798 134.993 227.598 117.7 224.793 96.7944 221.352 76.8005 223.073 57.8906 233.397c-15.5221 8.494-28.0851 21.519-36.013 37.338-8.1559 16.862-10.582 35.221-14.22974 53.34-3.64777 18.118-9.32591 37.613-7.17511 56.213C5.10128 420.431 33.165 453.054 73.5313 460.35 111.506 467.232 149.687 472.807 187.971 477.556 338.361 495.975 490.294 498.178 641.155 484.129 653.44 482.982 665.708 481.732 677.959 480.378 681.786 479.958 685.658 480.398 689.292 481.668S696.23 485.005 698.962 487.717 703.784 493.718 705.08 497.342C706.377 500.967 706.846 504.836 706.453 508.665L702.633 545.797c-7.697 75.031-15.394 150.057-23.091 225.077-8.029 78.783-16.111 157.56-24.244 236.326C653.004 1029.39 650.71 1051.57 648.416 1073.74 646.213 1095.58 645.904 1118.1 641.757 1139.68 635.218 1173.61 612.248 1194.45 578.73 1202.07 548.022 1209.06 516.652 1212.73 485.161 1213.01 450.249 1213.2 415.355 1211.65 380.443 1211.84 343.173 1212.05 297.525 1208.61 268.756 1180.87 243.479 1156.51 239.986 1118.36 236.545 1085.37 231.957 1041.7 227.409 998.039 222.9 954.381L197.607 711.615 181.244 554.538C180.968 551.94 180.693 549.376 180.435 546.76 178.473 528.023 165.207 509.681 144.301 510.627 126.407 511.418 106.069 526.629 108.168 546.76l12.13 116.454 25.087 240.89C152.532 972.528 159.661 1040.96 166.773 1109.41 168.15 1122.52 169.44 1135.67 170.885 1148.78 178.749 1220.43 233.465 1259.04 301.224 1269.91 340.799 1276.28 381.337 1277.59 421.497 1278.24 472.979 1279.07 524.977 1281.05 575.615 1271.72 650.653 1257.95 706.952 1207.85 714.987 1130.13 717.282 1107.69 719.576 1085.25 721.87 1062.8 729.498 988.559 737.115 914.313 744.72 840.061l24.881-242.61 11.408-111.188C781.577 480.749 783.905 475.565 787.649 471.478 791.392 467.391 796.352 464.617 801.794 463.567 823.25 459.386 843.761 452.245 859.023 435.916c24.295-25.998 29.13-59.895 20.544-94.067zM72.7365 365.835C73.247 365.68 72.3065 368.484 71.9034 369.792 71.8229 367.813 71.984 366.058 72.7365 365.835zm1.7756 16.105C74.6842 381.819 75.2003 382.508 75.7337 383.334 74.925 382.576 74.4089 382.009 74.4949 381.94H74.5121zM76.5597 384.641C77.6004 385.897 78.1569 386.689 76.5597 384.641zM80.7002 387.979h.2727C80.9729 388.313 81.473 388.645 81.6548 388.979 81.3533 388.612 81.0186 388.277 80.6548 387.979H80.7002zM800.796 382.989C793.088 390.319 781.473 393.726 769.996 395.43c-128.704 19.099-259.283 28.769-389.399 24.502C287.476 416.749 195.336 406.407 103.144 393.382 94.1102 392.109 84.3197 390.457 78.1082 383.798c-11.7004-12.561-5.9534-37.854-2.9079-53.03C77.9878 316.865 83.3218 298.334 99.8572 296.355 125.667 293.327 155.64 304.218 181.175 308.09 211.917 312.781 242.774 316.538 273.745 319.36 405.925 331.405 540.325 329.529 671.92 311.91 695.905 308.686 719.805 304.941 743.619 300.674 764.835 296.871 788.356 289.731 801.175 311.703 809.967 326.673 811.137 346.701 809.778 363.615 809.359 370.984 806.139 377.915 800.779 382.989H800.796z" id="Shape" fill="#fff" fill-rule="evenodd" stroke="none"/></g></g></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg><span>Home</span></a></li><li><a href=/about-me/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg><span>About Me</span></a></li><div class=menu-bottom-section><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><span>Dark Mode</span></li></div></ol></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><div class=article-title-wrapper><h2 class=article-title><a href=/posts/2016-09-09-bodypix-person-segmentation-in-browser/>BodyPix: Person Segmentation in the Browser</a></h2></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg><time class=article-time--published>Oct 11, 2019</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><time class=article-time--reading>21 minute read</time></div></footer></div></header><section class=article-content><h1 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixbodypix---person-segmentation-in-the-browserbodypix---person-segmentation-in-the-browser><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#bodypix---person-segmentation-in-the-browser target=_blank rel=noopener></a>BodyPix - Person Segmentation in the Browser</h1><h2 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixnote-weve-just-released-version-20-with-multi-person-support-a-new-resnet-model-and-api-check-out-the-new-documentation-belownote-weve-just-released-version-20-with-multi-person-support-a-new-resnet-model-and-api-check-out-the-new-documentation-below><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#note-weve-just-released-version-20-with-multi-person-support-a-new-resnet-model-and-api-check-out-the-new-documentation-below target=_blank rel=noopener></a>Note: We&rsquo;ve just released Version 2.0 with <strong>multi-person</strong> support, a <strong>new ResNet</strong> model and API. Check out the new documentation below.</h2><p>This package contains a standalone model called BodyPix, as well as some demos, for running real-time person and body part segmentation in the browser using TensorFlow.js.</p><p><a class=link href=https://storage.googleapis.com/tfjs-models/demos/body-pix/index.html target=_blank rel=noopener>Try the demo here!</a></p><p><a class=link href=https://github.com/tensorflow/tfjs-models/blob/master/body-pix/images/body-pix-2.0.gif target=_blank rel=noopener><img src=https://github.com/tensorflow/tfjs-models/raw/master/body-pix/images/body-pix-2.0.gif loading=lazy alt=BodyPix></a></p><p>This model can be used to segment an image into pixels that are and are not part of a person, and into pixels that belong to each of twenty-four body parts. It works for a single person, and its ideal use case is for when there is only one person centered in an input image or video. It can be combined with a person detector to segment multiple people in an image by first cropping boxes for each detected person then estimating segmentation in each of those crops, but that responsibility is currently outside of the scope of this model.</p><p>To keep track of issues we use the <a class=link href=https://github.com/tensorflow/tfjs target=_blank rel=noopener>tensorflow/tfjs</a> Github repo.</p><h2 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixcontributorscontributors><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#contributors target=_blank rel=noopener></a>Contributors</h2><h3 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixmain-contributorsmain-contributors><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#main-contributors target=_blank rel=noopener></a>Main Contributors</h3><h3 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixacknowledgementacknowledgement><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#acknowledgement target=_blank rel=noopener></a>Acknowledgement</h3><h3 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixspecial-thanks-for-participants-in-the-demo-videospecial-thanks-for-participants-in-the-demo-video><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#special-thanks-for-participants-in-the-demo-video target=_blank rel=noopener></a>Special thanks for participants in the demo video</h3><h2 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixtables-of-contentstables-of-contents><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#tables-of-contents target=_blank rel=noopener></a>Tables of Contents</h2><h2 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixinstallationinstallation><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#installation target=_blank rel=noopener></a>Installation</h2><p>You can use this as standalone es5 bundle like this:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl> &lt;script src\=&#34;https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.0.0&#34;\&gt;script&gt; &lt;script src\=&#34;https://cdn.jsdelivr.net/npm/@tensorflow-models/body-pix@2.0.0&#34;\&gt;script&gt;
</span></span></code></pre></td></tr></table></div></div><p>Or you can install it via npm for use in a TypeScript / ES6 project.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>npm install @tensorflow-models/body-pix
</span></span></code></pre></td></tr></table></div></div><h2 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixusageusage><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#usage target=_blank rel=noopener></a>Usage</h2><p>Either a person or part of the body can be segmented in an image. Each methodology has similar input parameters with different outputs.</p><h3 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixloading-a-pre-trained-bodypix-modelloading-a-pre-trained-bodypix-model><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#loading-a-pre-trained-bodypix-model target=_blank rel=noopener></a>Loading a pre-trained BodyPix Model</h3><p>In the first step of person segmentation and body part segmentation, an image is fed through a pre-trained model. BodyPix <strong>comes with a few different versions of the model,</strong> corresponding to variances of MobileNetV1 architecture and ResNet50 architecture. To get started, a model must be loaded from a checkpoint:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>const net \= await bodyPix.load();
</span></span></code></pre></td></tr></table></div></div><p>By default, <code>bodyPix.load()</code> loads a faster and smaller model that is based on MobileNetV1 architecture and has a lower accuracy. If you want to load the larger and more accurate model, specify the architecture explicitly in <code>bodyPix.load()</code> using a <code>ModelConfig</code> dictionary:</p><h4 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixmobilenet-smaller-faster-less-accuratemobilenet-smaller-faster-less-accurate><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#mobilenet-smaller-faster-less-accurate target=_blank rel=noopener></a>MobileNet (smaller, faster, less accurate)</h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>const net \= await bodyPix.load({ architecture: &#39;MobileNetV1&#39;, outputStride: 16, inputResolution: 513, multiplier: 0.75 });
</span></span></code></pre></td></tr></table></div></div><h4 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixresnet-larger-slower-more-accurate-newresnet-larger-slower-more-accurate-new><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#resnet-larger-slower-more-accurate-new target=_blank rel=noopener></a>ResNet (larger, slower, more accurate) **new!**</h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>const net \= await bodyPix.load({ architecture: &#39;ResNet50&#39;, outputStride: 32, inputResolution: 257, quantBytes: 2 });
</span></span></code></pre></td></tr></table></div></div><h4 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixconfig-params-in-bodypixloadconfig-params-in-bodypixload><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#config-params-in-bodypixload target=_blank rel=noopener></a>Config params in bodyPix.load()</h4><ul><li><p><strong>architecture</strong> - Can be either <code>MobileNetV1</code> or <code>ResNet50</code>. It determines which BodyPix architecture to load.</p></li><li><p><strong>outputStride</strong> - Can be one of <code>8</code>, <code>16</code>, <code>32</code> (Stride <code>16</code>, <code>32</code> are supported for the ResNet architecture and stride <code>8</code>, <code>16</code>, <code>32</code> are supported for the MobileNetV1 architecture). It specifies the output stride of the BodyPix model. The smaller the value, the larger the output resolution, and more accurate the model at the cost of speed. Set this to a larger value to increase speed at the cost of accuracy.</p></li><li><p><strong>inputResolution</strong> - Can be one of <code>161</code>, <code>193</code>, <code>257</code>, <code>289</code>, <code>321</code>, <code>353</code>, <code>385</code>, <code>417</code>, <code>449</code>, <code>481</code>, <code>513</code>, and <code>801</code>. Defaults to <code>257.</code> It specifies the size the image is resized to before it is fed into the BodyPix model. The larger the value, the more accurate the model at the cost of speed. Set this to a smaller value to increase speed at the cost of accuracy.</p></li><li><p><strong>multiplier</strong> - Can be one of <code>1.0</code>, <code>0.75</code>, or <code>0.50</code> (The value is used <em>only</em> by the MobileNetV1 architecture and not by the ResNet architecture). It is the float multiplier for the depth (number of channels) for all convolution ops. The larger the value, the larger the size of the layers, and more accurate the model at the cost of speed. Set this to a smaller value to increase speed at the cost of accuracy.</p></li><li><p><strong>quantBytes</strong> - This argument controls the bytes used for weight quantization. The available options are:</p><ul><li><code>4</code>. 4 bytes per float (no quantization). Leads to highest accuracy and original model size.</li><li><code>2</code>. 2 bytes per float. Leads to slightly lower accuracy and 2x model size reduction.</li><li><code>1</code>. 1 byte per float. Leads to lower accuracy and 4x model size reduction.</li></ul><p>The following table contains the corresponding BodyPix 2.0 model checkpoint sizes (widthout gzip) when using different quantization bytes:</p><p>Architecture</p><p>quantBytes=4</p><p>quantBytes=2</p><p>quantBytes=1</p><p>ResNet50</p><p>~90MB</p><p>~45MB</p><p>~22MB</p><p>MobileNetV1 (1.00)</p><p>~13MB</p><p>~6MB</p><p>~3MB</p><p>MobileNetV1 (0.75)</p><p>~5MB</p><p>~2MB</p><p>~1MB</p><p>MobileNetV1 (0.50)</p><p>~2MB</p><p>~1MB</p><p>~0.6MB</p></li><li><p><strong>modelUrl</strong> - An optional string that specifies custom url of the model. This is useful for local development or countries that don&rsquo;t have access to the models hosted on GCP.</p></li></ul><p><strong>By default,</strong> BodyPix loads a MobileNetV1 architecture with a <strong><code>0.75</code></strong> multiplier. This is recommended for computers with <strong>mid-range/lower-end GPUs.</strong> A model with a <strong><code>0.50</code></strong> multiplier is recommended for <strong>mobile.</strong> The ResNet architecture is recommended for computers with <strong>even more powerful GPUs</strong>.</p><h3 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixperson-segmentationperson-segmentation><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#person-segmentation target=_blank rel=noopener></a>Person segmentation</h3><p>Given an image with multiple people, multi-person segmentation model predicts segmentation for <em>each</em> person. It returns <em>an array</em> of <code>PersonSegmentation</code> and each corresponding to one person. Each element is a binary array for one person with 1 for the pixels that are part of the person, and 0 otherwise. The array size corresponds to the number of pixels in the image.</p><p><a class=link href=https://github.com/tensorflow/tfjs-models/blob/master/body-pix/images/two_people_segmentation.jpg target=_blank rel=noopener><img src=https://github.com/tensorflow/tfjs-models/raw/master/body-pix/images/two_people_segmentation.jpg loading=lazy alt="Multi-person Segmentation"></a></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>const net \= await bodyPix.load(); const segmentation \= await net.estimateMultiPersonInstanceSegmentation(image, { flipHorizontal: false, segmentationThreshold: 0.7, maxDetections: 10, scoreThreshold: 0.2, nmsRadius: 20, minKeypointScore: 0.3, refineSteps: 10 });
</span></span></code></pre></td></tr></table></div></div><h4 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixparams-in-estimatemultipersoninstancesegmentationparams-in-estimatemultipersoninstancesegmentation><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#params-in-estimatemultipersoninstancesegmentation target=_blank rel=noopener></a>Params in estimateMultiPersonInstanceSegmentation()</h4><ul><li><strong>image</strong> - ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement The input image to feed through the network.</li><li><strong>config</strong> - an optional dictionary containing:<ul><li><strong>flipHorizontal</strong> - Defaults to false. If the segmentation & pose should be flipped/mirrored horizontally. This should be set to true for videos where the video is by default flipped horizontally (i.e. a webcam), and you want the segmentation & pose to be returned in the proper orientation.</li><li><strong>segmentationThreshold</strong> - Defaults to 0.7. Must be between 0 and 1. For each pixel, the model estimates a score between 0 and 1 that indicates how confident it is that part of a person is displayed in that pixel. This <em>segmentationThreshold</em> is used to convert these values to binary 0 or 1s by determining the minimum value a pixel&rsquo;s score must have to be considered part of a person. In essence, a higher value will create a tighter crop around a person but may result in some pixels being that are part of a person being excluded from the returned segmentation mask.</li><li><strong>maxDetections</strong> - Defaults to 10. Maximum number of returned instance detections per image.</li><li><strong>scoreThreshold</strong> - Only return instance detections that have root part score greater or equal to this value. Defaults to 0.5</li><li><strong>nmsRadius</strong> - Defaults to 20. Non-maximum suppression part distance in pixels. It needs to be strictly positive. Two parts suppress each other if they are less than <code>nmsRadius</code> pixels away.</li><li><strong>minKeypointScore</strong> - Default to 0.3. Keypoints above the score are used for matching and assigning segmentation mask to each person..</li><li><strong>refineSteps</strong> - Default to 10. The number of refinement steps used when assigning the instance segmentation. It needs to be strictly positive. The larger the higher the accuracy and slower the inference.</li></ul></li></ul><h4 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixreturnsreturns><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#returns target=_blank rel=noopener></a>Returns</h4><p>It returns a <code>Promise</code> that resolves with <strong>an array</strong> of <code>PersonSegmentation</code>s. When there are multiple people in the image, each <code>PersonSegmentation</code> object in the array represents one person. More details about the <code>PersonSegmentation</code> object can be found in the documentation of the <code>estimateSinglePersonSegmentation</code> method.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>\[{ width: 640, height: 480, data: Uint8Array(307200) \[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1 …\] }, ... // the data array for the 1st person containing 307200 values, one for each pixel of the 640x480 image. { width: 640, height: 480, data: Uint8Array(307200) \[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, …\] }\] // the data array for the n-th person containing 307200 values, one for each pixel of the 640x480 image.
</span></span></code></pre></td></tr></table></div></div><h4 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixexample-usageexample-usage><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#example-usage target=_blank rel=noopener></a>Example Usage</h4><h5 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixvia-script-tagvia-script-tag><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#via-script-tag target=_blank rel=noopener></a>via Script Tag</h5><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>&lt;html\&gt; &lt;head\&gt;  &lt;script src\=&#34;https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.0.0&#34;\&gt;script&gt;  &lt;script src\=&#34;https://cdn.jsdelivr.net/npm/@tensorflow-models/body-pix@2.0.0&#34;\&gt;script&gt; head&gt; &lt;body\&gt; &lt;img id\=&#39;person&#39; src\=&#39;/images/person.jpg &#39;/&gt; body&gt;  &lt;script\&gt;  var imageElement \= document.getElementById(&#39;image&#39;);   bodyPix.load().then(function(net){  return net.estimateMultiPersonSegmentation(imageElement, {  flipHorizontal: false,  segmentationThreshold: 0.7,  maxDetections: 10,  scoreThreshold: 0.2,  nmsRadius: 20,  minKeypointScore: 0.3,  refineSteps: 10  });  }).then(function(allSegmentations){  console.log(allSegmentations);  })  script&gt; html&gt;
</span></span></code></pre></td></tr></table></div></div><h6 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixvia-npmvia-npm><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#via-npm target=_blank rel=noopener></a>via NPM</h6><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>import \* as bodyPix from &#39;@tensorflow-models/body-pix&#39;; const imageElement \= document.getElementById(&#39;image&#39;); // load the BodyPix model from a checkpoint const net \= await bodyPix.load(); const allSegmentations \= await net.estimateMultiPersonInstanceSegmentation(imageElement, { flipHorizontal: false, segmentationThreshold: 0.7, maxDetections: 10, scoreThreshold: 0.2, nmsRadius: 20, minKeypointScore: 0.3, refineSteps: 10 }); console.log(allSegmentations);
</span></span></code></pre></td></tr></table></div></div><h3 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixmulti-person-body-part-segmentationmulti-person-body-part-segmentation><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#multi-person-body-part-segmentation target=_blank rel=noopener></a>Multi-person body part segmentation</h3><p>Given an image with multiple people. BodyPix&rsquo;s <code>estimateMultiPersonInstancePartSegmentation</code> method predicts the 24 body part segmentations for <em>each</em> person. It returns <em>an array</em> of <code>PartSegmentation</code>s, each corresponding to one of the people. The <code>PartSegmentation</code> object contains a width, height, <code>Pose</code> and an Int32 array with a part id from 0-24 for the pixels that are part of a corresponding body part, and -1 otherwise.</p><p><a class=link href=https://github.com/tensorflow/tfjs-models/blob/master/body-pix/images/two_people_parts.jpg target=_blank rel=noopener><img src=https://github.com/tensorflow/tfjs-models/raw/master/body-pix/images/two_people_parts.jpg loading=lazy alt="Multi-person Segmentation"></a></p><h4 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixthe-body-partsthe-body-parts><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#the-body-parts target=_blank rel=noopener></a>The Body Parts</h4><p>As stated above, the result contains an array with ids for one of 24 body parts, or -1 if there is no body part:</p><p>Part Id</p><p>Part Name</p><p>Part Id</p><p>Part Name</p><p>0</p><p>left_face</p><p>12</p><p>torso_front</p><p>1</p><p>right_face</p><p>13</p><p>torso_back</p><p>2</p><p>left_upper_arm_front</p><p>14</p><p>left_upper_leg_front</p><p>3</p><p>left_upper_arm_back</p><p>15</p><p>left_upper_leg_back</p><p>4</p><p>right_upper_arm_front</p><p>16</p><p>right_upper_leg_front</p><p>5</p><p>right_upper_arm_back</p><p>17</p><p>right_upper_leg_back</p><p>6</p><p>left_lower_arm_front</p><p>18</p><p>left_lower_leg_front</p><p>7</p><p>left_lower_arm_back</p><p>19</p><p>left_lower_leg_back</p><p>8</p><p>right_lower_arm_front</p><p>20</p><p>right_lower_leg_front</p><p>9</p><p>right_lower_arm_back</p><p>21</p><p>right_lower_leg_back</p><p>10</p><p>left_hand</p><p>22</p><p>left_feet</p><p>11</p><p>right_hand</p><p>23</p><p>right_feet</p><p>(Note: Part Id value -1 represents the non-person background)</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>const net \= await bodyPix.load(); const segmentation \= await net.estimateMultiPersonInstancePartSegmentation(image, { flipHorizontal: false, segmentationThreshold: 0.7, maxDetections: 10, scoreThreshold: 0.2, nmsRadius: 20, minKeypointScore: 0.3, refineSteps: 10 });
</span></span></code></pre></td></tr></table></div></div><h4 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixparams-in-estimatemultipersoninstancesegmentation-1params-in-estimatemultipersoninstancesegmentation><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#params-in-estimatemultipersoninstancesegmentation-1 target=_blank rel=noopener></a>Params in estimateMultiPersonInstanceSegmentation</h4><ul><li><strong>image</strong> - ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement The input image to feed through the network.</li><li><strong>inferenceConfig</strong> - an object containing:<ul><li><strong>flipHorizontal</strong> - Defaults to false. If the segmentation & pose should be flipped/mirrored horizontally. This should be set to true for videos where the video is by default flipped horizontally (i.e. a webcam), and you want the segmentation & pose to be returned in the proper orientation.</li><li><strong>segmentationThreshold</strong> - Must be between 0 and 1. For each pixel, the model estimates a score between 0 and 1 that indicates how confident it is that part of a person is displayed in that pixel. This <em>segmentationThreshold</em> is used to convert these values to binary 0 or 1s by determining the minimum value a pixel&rsquo;s score must have to be considered part of a person. In essence, a higher value will create a tighter crop around a person but may result in some pixels being that are part of a person being excluded from the returned segmentation mask.</li><li><strong>maxDetections</strong> - Maximum number of returned instance detections per image. Defaults to 10</li><li><strong>scoreThreshold</strong> - Only return instance detections that have root part score greater or equal to this value. Defaults to 0.5</li><li><strong>nmsRadius</strong> - Non-maximum suppression part distance in pixels. It needs to be strictly positive. Two parts suppress each other if they are less than <code>nmsRadius</code> pixels away. Defaults to 20.</li><li><strong>minKeypointScore</strong> - Default to 0.3. Keypoints above the score are used for matching and assigning segmentation mask to each person..</li><li><strong>refineSteps</strong> - The number of refinement steps used when assigning the instance segmentation. It needs to be strictly positive. The larger the higher the accuracy and slower the inference.</li></ul></li></ul><h4 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixreturns-1returns><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#returns-1 target=_blank rel=noopener></a>Returns</h4><p>It returns a <code>Promise</code> that resolves with <strong>an array</strong> of <code>PartSegmentation</code>s. When there are multiple people in the image, each <code>PartSegmentation</code> object in the array represents one person. More details about the <code>PartSegmentation</code> object can be found in the documentation of the <code>estimateSinglePersonPartSegmentation</code> method.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>\[ { width: 680, height: 480, data: Int32Array(307200) \[\-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, 3, 3, 3, 3, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, 0, 0, 0, 0, 0, 1, 1, 2, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, 15, 15, 15, 15, 16, 16, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, 23, 23, 23, 22, 22, \-1, \-1, \-1, \-1,  …\] }, { width: 680, height: 480, data: Int32Array(307200) \[\-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, 3, 3, 3, 3, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, 0, 0, 0, 0, 0, 1, 1, 2, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, 15, 15, 15, 15, 16, 16, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, \-1, 23, 23, 23, 22, 22, \-1, \-1, \-1, \-1,  …\] } \] // the array contains 307200 values, one for each pixel of the 640x480 image that was passed to the function.
</span></span></code></pre></td></tr></table></div></div><h4 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixexample-usage-1example-usage><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#example-usage-1 target=_blank rel=noopener></a>Example Usage</h4><h5 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixvia-script-tag-1via-script-tag><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#via-script-tag-1 target=_blank rel=noopener></a>via Script Tag</h5><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>&lt;html\&gt; &lt;head\&gt;  &lt;script src\=&#34;https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.0.0&#34;\&gt;script&gt;  &lt;script src\=&#34;https://cdn.jsdelivr.net/npm/@tensorflow-models/body-pix@2.0.0&#34;\&gt;script&gt; head&gt; &lt;body\&gt; &lt;img id\=&#39;person&#39; src\=&#39;/images/person.jpg &#39;/&gt; body&gt;  &lt;script\&gt;  var imageElement \= document.getElementById(&#39;image&#39;);   bodyPix.load().then(function(net){  return net.estimateMultiPersonPartSegmentation(imageElement, {  flipHorizontal: false,  segmentationThreshold: 0.7,  maxDetections: 10,  scoreThreshold: 0.2,  nmsRadius: 20,  minKeypointScore: 0.3,  refineSteps: 10  });  }).then(function(multiPersonPartSegmentations){  console.log(multiPersonPartSegmentations);  })  script&gt; html&gt;
</span></span></code></pre></td></tr></table></div></div><h6 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixvia-npm-1via-npm><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#via-npm-1 target=_blank rel=noopener></a>via NPM</h6><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>import \* as bodyPix from &#39;@tensorflow-models/body-pix&#39;; const imageElement \= document.getElementById(&#39;image&#39;); // load the BodyPix model from a checkpoint const net \= await bodyPix.load(); const multiPersonPartSegmentations \= await net.estimateMultiPersonPartSegmentation(imageElement, { flipHorizontal: false, segmentationThreshold: 0.7, maxDetections: 10, scoreThreshold: 0.2, nmsRadius: 20, minKeypointScore: 0.3, refineSteps: 10 }); console.log(multiPersonPartSegmentations);
</span></span></code></pre></td></tr></table></div></div><p>which would produce the output:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>\[{ width: 640, height: 480, data: Uint8Array(307200) \[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, …\] }, // the data array contains 307200 values, one for each pixel of the 640x480 image that was passed to the function. { width: 640, height: 480, data: Uint8Array(307200) \[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, …\] }\] // the data array contains 307200 values, one for each pixel of the 640x480 image that was passed to the function.
</span></span></code></pre></td></tr></table></div></div><h3 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixoutput-visualization-utility-functionsoutput-visualization-utility-functions><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#output-visualization-utility-functions target=_blank rel=noopener></a>Output Visualization Utility Functions</h3><p>BodyPix contains utility functions to help with drawing and compositing using the outputs. <strong>These API methods are experimental and subject to change.</strong></p><h4 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixtomaskimagedatatomaskimagedata><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#tomaskimagedata target=_blank rel=noopener></a><code>toMaskImageData</code></h4><p>Given the output of person segmentation (or multi-person instance segmentation), generates a visualization of each pixel determined by the corresponding binary segmentation value at the pixel from the output. In other words, pixels where there is a person will be colored by the foreground color and where there is not a person will be colored by the background color. This can be used as a mask to crop a person or the background when compositing.</p><h5 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixinputsinputs><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#inputs target=_blank rel=noopener></a>Inputs</h5><ul><li><p><strong>personSegmentation</strong> The output from <a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#Single-person-segmentation target=_blank rel=noopener>estimatePersonSegmentation</a> or <a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#Multi-person-segmentation target=_blank rel=noopener>estimateMultiPersonSegmentation</a>. The former is a PersonSegmentation object and later is an <em>array</em> of PersonSegmentation object.</p></li><li><p><strong>foreground</strong> The foreground color (r,g,b,a) for visualizing pixels that belong to people.</p></li><li><p><strong>background</strong> The background color (r,g,b,a) for visualizing pixels that don&rsquo;t belong to people.</p></li><li><p><strong>drawContour</strong> Whether to draw the contour around each person&rsquo;s segmentation mask.</p></li></ul><h5 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixreturns-2returns><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#returns-2 target=_blank rel=noopener></a>Returns</h5><p>An <a class=link href=https://developer.mozilla.org/en-US/docs/Web/API/ImageData target=_blank rel=noopener>ImageData</a> with the same width and height of the personSegmentation, with color and opacity at each pixel determined by the corresponding binary segmentation value at the pixel from the output.</p><p><a class=link href=https://github.com/tensorflow/tfjs-models/blob/master/body-pix/images/toMultiPersonMaskImageData.jpg target=_blank rel=noopener><img src=https://github.com/tensorflow/tfjs-models/raw/master/body-pix/images/toMultiPersonMaskImageData.jpg loading=lazy alt=MaskImageData></a></p><p><em>With the output from <code>estimateMultiPersonSegmentation</code> on the first image above, <code>toMultiPersonMaskImageData</code> will produce an <a class=link href=https://developer.mozilla.org/en-US/docs/Web/API/ImageData target=_blank rel=noopener>ImageData</a> that either looks like the second image above if setting <code>foregroundColor</code> to {r: 0, g: 0, b: 0, a: 0} and <code>backgroundColor</code> to {r: 0, g: 0, b: 0, a: 255} (by default), or the third image if if setting <code>foregroundColor</code> to {r: 0, g: 0, b: 0, a: 255} and <code>backgroundColor</code> to {r: 0, g: 0, b: 0, a: 0}. This can be used to mask either the person or the background using the method <code>drawMask</code>.</em></p><h4 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixtocoloredpartimagedatatocoloredpartimagedata><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#tocoloredpartimagedata target=_blank rel=noopener></a><code>toColoredPartImageData</code></h4><p>Given the output from person body part segmentation (or multi-person instance body part segmentation) and an array of colors indexed by part id, generates an image with the corresponding color for each part at each pixel, and white pixels where there is no part.</p><h5 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixinputs-1inputs><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#inputs-1 target=_blank rel=noopener></a>Inputs</h5><h5 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixreturns-3returns><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#returns-3 target=_blank rel=noopener></a>Returns</h5><p>An <a class=link href=https://developer.mozilla.org/en-US/docs/Web/API/ImageData target=_blank rel=noopener>ImageData</a> with the same width and height of the estimated person part segmentation, with the corresponding color for each part at each pixel, and black pixels where there is no part.</p><h5 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixexample-usage-2example-usage><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#example-usage-2 target=_blank rel=noopener></a>Example usage</h5><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>const imageElement \= document.getElementById(&#39;person&#39;); const net \= await bodyPix.load(); const partSegmentation \= await net.estimateMultiPersonPartSegmentation(imageElement); // The rainbow colormap const rainbow \= \[ \[110, 64, 170\], \[143, 61, 178\], \[178, 60, 178\], \[210, 62, 167\], \[238, 67, 149\], \[255, 78, 125\], \[255, 94, 99\], \[255, 115, 75\], \[255, 140, 56\], \[239, 167, 47\], \[217, 194, 49\], \[194, 219, 64\], \[175, 240, 91\], \[135, 245, 87\], \[96, 247, 96\], \[64, 243, 115\], \[40, 234, 141\], \[28, 219, 169\], \[26, 199, 194\], \[33, 176, 213\], \[47, 150, 224\], \[65, 125, 224\], \[84, 101, 214\], \[99, 81, 195\] \]; // the colored part image is an rgb image with a corresponding color from thee rainbow colors for each part at each pixel, and black pixels where there is no part. const coloredPartImage \= bodyPix.toColoredPartImageData(partSegmentation, rainbow); const opacity \= 0.7; const flipHorizontal \= true; const maskBlurAmount \= 0; const canvas \= document.getElementById(&#39;canvas&#39;); // draw the colored part image on top of the original image onto a canvas. The colored part image will be drawn semi-transparent, with an opacity of 0.7, allowing for the original image to be visible under. bodyPix.drawMask( canvas, imageElement, coloredPartImageData, opacity, maskBlurAmount, flipHorizontal);
</span></span></code></pre></td></tr></table></div></div><p><a class=link href=https://github.com/tensorflow/tfjs-models/blob/master/body-pix/images/toMultiPersonColoredPartImage.jpg target=_blank rel=noopener><img src=https://github.com/tensorflow/tfjs-models/raw/master/body-pix/images/toMultiPersonColoredPartImage.jpg loading=lazy alt=toColoredPartImageData></a></p><p><em>With the output from <code>estimateMultiPersonPartSegmentation</code> on the first image above, a &lsquo;spectral&rsquo; or &lsquo;rainbow&rsquo; color scale in <code>toColoredPartImageData</code> will produce an <code>ImageData</code> that looks like the second image or the third image above.</em></p><h4 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixdrawmaskdrawmask><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#drawmask target=_blank rel=noopener></a><code>drawMask</code></h4><p>Draws an image onto a canvas and draws an <code>ImageData</code> containing a mask on top of it with a specified opacity; The <code>ImageData</code> is typically generated using <code>toMaskImageData</code>, <code>toMultiPersonMaskImageData</code>, <code>toColoredPartImageData</code> or <code>toMultiPersonColoredPartImageData</code>.</p><h5 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixinputs-2inputs><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#inputs-2 target=_blank rel=noopener></a>Inputs</h5><ul><li><strong>canvas</strong> The canvas to be drawn onto.</li><li><strong>image</strong> The original image to apply the mask to.</li><li><strong>maskImage</strong> An ImageData containing the mask. Ideally this should be generated by <code>toMaskImageData</code> or <code>toColoredPartImageData.</code></li><li><strong>maskOpacity</strong> The opacity when drawing the mask on top of the image. Defaults to 0.7. Should be a float between 0 and 1.</li><li><strong>maskBlurAmount</strong> How many pixels to blur the mask by. Defaults to 0. Should be an integer between 0 and 20.</li><li><strong>flipHorizontal</strong> If the result should be flipped horizontally. Defaults to false.</li></ul><h5 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixexample-usage-3example-usage><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#example-usage-3 target=_blank rel=noopener></a>Example usage</h5><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>const imageElement \= document.getElementById(&#39;image&#39;); const net \= await bodyPix.load(); const segmentation \= await net.estimateSinglePersonSegmentation(imageElement); const maskBackground \= true; // Convert the personSegmentation into a mask to darken the background. const foregroundColor \= {r: 0, g: 0, b: 0, a: 0}; const backgroundColor \= {r: 0, g: 0, b: 0, a: 255}; const backgroundDarkeningMask \= bodyPix.toMaskImageData(personSegmentation, foregroundColor, backgroundColor); const opacity \= 0.7; const maskBlurAmount \= 3; const flipHorizontal \= true; const canvas \= document.getElementById(&#39;canvas&#39;); // draw the mask onto the image on a canvas. With opacity set to 0.7 and maskBlurAmount set to 3, this will darken the background and blur the darkened background&#39;s edge. bodyPix.drawMask( canvas, imageElement, backgroundDarkeningMask, opacity, maskBlurAmount, flipHorizontal);
</span></span></code></pre></td></tr></table></div></div><p><a class=link href=https://github.com/tensorflow/tfjs-models/blob/master/body-pix/images/drawMask.jpg target=_blank rel=noopener><img src=https://github.com/tensorflow/tfjs-models/raw/master/body-pix/images/drawMask.jpg loading=lazy alt=drawMask></a></p><p><em>The above shows drawing a mask generated by <code>toMaskImageData</code> on top of an image and canvas using <code>toMask</code>. In this case, <code>segmentationThreshold</code> was set to a lower value of 0.25, making the mask include more pixels. The top two images show the mask drawn on top of the image, and the second two images show the mask blurred by setting <code>maskBlurAmount</code> to 9 before being drawn onto the image, resulting in a smoother transition between the person and the masked background.</em></p><h4 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixdrawpixelatedmaskdrawpixelatedmask><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#drawpixelatedmask target=_blank rel=noopener></a><code>drawPixelatedMask</code></h4><p>Draws an image onto a canvas and draws an <code>ImageData</code> containing a mask on top of it with a specified opacity; The <code>ImageData</code> is typically generated using <code>toColoredPartImageData</code>. Different from <code>drawMask</code>, this rendering function applies the pixelation effect to the BodyPix&rsquo;s body part segmentation prediction. This allows a user to display low resolution body part segmentation and thus offers an aesthetic interpretation of the body part segmentation prediction.</p><h5 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixinputs-3inputs><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#inputs-3 target=_blank rel=noopener></a>Inputs</h5><ul><li><strong>canvas</strong> The canvas to be drawn onto.</li><li><strong>image</strong> The original image to apply the mask to.</li><li><strong>maskImage</strong> An ImageData containing the mask. Ideally this should be generated by <code>toColoredPartImageData.</code></li><li><strong>maskOpacity</strong> The opacity when drawing the mask on top of the image. Defaults to 0.7. Should be a float between 0 and 1.</li><li><strong>maskBlurAmount</strong> How many pixels to blur the mask by. Defaults to 0. Should be an integer between 0 and 20.</li><li><strong>flipHorizontal</strong> If the result should be flipped horizontally. Defaults to false.</li><li><strong>pixelCellWidth</strong> The width of each pixel cell. Default to 10 px.</li></ul><h5 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixexample-usage-4example-usage><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#example-usage-4 target=_blank rel=noopener></a>Example usage</h5><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>const imageElement \= document.getElementById(&#39;person&#39;); const net \= await bodyPix.load(); const partSegmentation \= await net.estimateSinglePersonPartSegmentation(imageElement); const rainbow \= \[ \[110, 64, 170\], \[143, 61, 178\], \[178, 60, 178\], \[210, 62, 167\], \[238, 67, 149\], \[255, 78, 125\], \[255, 94, 99\], \[255, 115, 75\], \[255, 140, 56\], \[239, 167, 47\], \[217, 194, 49\], \[194, 219, 64\], \[175, 240, 91\], \[135, 245, 87\], \[96, 247, 96\], \[64, 243, 115\], \[40, 234, 141\], \[28, 219, 169\], \[26, 199, 194\], \[33, 176, 213\], \[47, 150, 224\], \[65, 125, 224\], \[84, 101, 214\], \[99, 81, 195\] \]; // the colored part image is an rgb image with a corresponding color from thee rainbow colors for each part at each pixel, and white pixels where there is no part. const coloredPartImage \= bodyPix.toColoredPartImageData(partSegmentation, rainbow); const opacity \= 0.7; const flipHorizontal \= true; const maskBlurAmount \= 0; const pixelCellWidth \= 10.0; const canvas \= document.getElementById(&#39;canvas&#39;); // draw the pixelated colored part image on top of the original image onto a canvas. Each pixel cell&#39;s width will be set to 10 px. The pixelated colored part image will be drawn semi-transparent, with an opacity of 0.7, allowing for the original image to be visible under. bodyPix.drawPixelatedMask( canvas, imageElement, coloredPartImageData, opacity, maskBlurAmount, flipHorizontal, pixelCellWidth);
</span></span></code></pre></td></tr></table></div></div><p><a class=link href=https://github.com/tensorflow/tfjs-models/blob/master/body-pix/images/drawPixelatedMask.png target=_blank rel=noopener><img src=https://github.com/tensorflow/tfjs-models/raw/master/body-pix/images/drawPixelatedMask.png loading=lazy alt=drawPixelatedMask></a></p><p><em>The pixelation effect is applied to part image using <code>drawPixelatedMask</code>; the result is shown in the image above.</em></p><h4 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixdrawbokeheffectdrawbokeheffect><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#drawbokeheffect target=_blank rel=noopener></a><code>drawBokehEffect</code></h4><p>Given a personSegmentation and an image, draws the image with its background blurred onto a canvas.</p><p>An example of applying a <a class=link href=https://www.nikonusa.com/en/learn-and-explore/a/tips-and-techniques/bokeh-for-beginners.html target=_blank rel=noopener>bokeh effect</a> can be seen in this <a class=link href=https://storage.googleapis.com/tfjs-models/demos/body-pix/index.html target=_blank rel=noopener>demo</a>:</p><p><a class=link href=https://github.com/tensorflow/tfjs-models/blob/master/body-pix/images/bokeh.gif target=_blank rel=noopener><img src=https://github.com/tensorflow/tfjs-models/raw/master/body-pix/images/bokeh.gif loading=lazy alt=Bokeh></a></p><h5 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixinputs-4inputs><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#inputs-4 target=_blank rel=noopener></a>Inputs</h5><ul><li><strong>canvas</strong> The canvas to draw the background-blurred image onto.</li><li><strong>image</strong> The image to blur the background of and draw.</li><li><strong>personSegmentation</strong> A personSegmentation object, containing a binary array with 1 for the pixels that are part of the person, and 0 otherwise. Must have the same dimensions as the image.</li><li><strong>backgroundBlurAmount</strong> How many pixels in the background blend into each other. Defaults to 3. Should be an integer between 1 and 20.</li><li><strong>edgeBlurAmount</strong> How many pixels to blur on the edge between the person and the background by. Defaults to 3. Should be an integer between 0 and 20.</li><li><strong>flipHorizontal</strong> If the output should be flipped horizontally. Defaults to false.</li></ul><h5 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixexample-usage-5example-usage><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#example-usage-5 target=_blank rel=noopener></a>Example Usage</h5><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>const imageElement \= document.getElementById(&#39;image&#39;); const net \= await bodyPix.load(); const personSegmentation \= await net.estimateSinglePersonSegmentation(imageElement); const backgroundBlurAmount \= 3; const edgeBlurAmount \= 3; const flipHorizontal \= true; const canvas \= document.getElementById(&#39;canvas&#39;); // draw the image with the background blurred onto the canvas. The edge between the person and blurred background is blurred by 3 pixels. bodyPix.drawBokehEffect( canvas, imageElement, personSegmentation, backgroundBlurAmount, edgeBlurAmount, flipHorizontal);
</span></span></code></pre></td></tr></table></div></div><p><a class=link href=https://github.com/tensorflow/tfjs-models/blob/master/body-pix/images/bokehimage.png target=_blank rel=noopener><img src=https://github.com/tensorflow/tfjs-models/raw/master/body-pix/images/bokehimage.png loading=lazy alt=bokeh></a></p><p><em>The above shows the process of applying a &lsquo;bokeh&rsquo; effect to an image (the left-most one) with <code>drawBokehEffect</code>. An <strong>inverted</strong> mask is generated from a <code>personSegmentation</code>. The original image is then drawn onto the canvas, and using the <a class=link href=https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D/globalCompositeOperation target=_blank rel=noopener>canvas compositing</a> operation <code>destination-over</code> the mask is drawn onto the canvas, causing the background to be removed. The original image is blurred and drawn onto the canvas where it doesn&rsquo;t overlap with the existing image using the compositing operation <code>destination-over</code>. The result is seen in the right-most image.</em></p><h4 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixblurbodypartblurbodypart><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#blurbodypart target=_blank rel=noopener></a><code>blurBodyPart</code></h4><p>Given a PartSegmentation (or an array of PartSegmentation) and an image, blurs some person body parts (e.g. left face and right face).</p><p>An example of applying a body part blur on <code>left_face</code> and <code>right_face</code> body parts (other body parts can be specified):</p><p><a class=link href=https://github.com/tensorflow/tfjs-models/blob/master/body-pix/images/three_people_faceblur.jpg target=_blank rel=noopener><img src=https://github.com/tensorflow/tfjs-models/raw/master/body-pix/images/three_people_faceblur.jpg loading=lazy alt=three_people_faceblur></a></p><h5 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixinputs-5inputs><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#inputs-5 target=_blank rel=noopener></a>Inputs</h5><ul><li><strong>canvas</strong> The canvas to draw the body-part blurred image onto.</li><li><strong>image</strong> The image with people to blur the body-part and draw.</li><li><strong>partSegmentation</strong> A PartSegmentation object or an array of PartSegmentation object. Must have the same dimensions as the image.</li><li><strong>bodyPartIdsToBlur</strong> Default to [0, 1] (left-face and right-face). An array of body part ids to blur. Each must be one of the 24 body part ids.</li><li><strong>backgroundBlurAmount</strong> How many pixels in the background blend into each other. Defaults to 3. Should be an integer between 1 and 20.</li><li><strong>edgeBlurAmount</strong> How many pixels to blur on the edge between the person and the background by. Defaults to 3. Should be an integer between 0 and 20.</li><li><strong>flipHorizontal</strong> If the output should be flipped horizontally. Defaults to false.</li></ul><h5 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixexample-usage-6example-usage><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#example-usage-6 target=_blank rel=noopener></a>Example Usage</h5><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>const imageElement \= document.getElementById(&#39;image&#39;); const net \= await bodyPix.load(); const partSegmentation \= await net.estimateMultiPersonInstancePartSegmentation(imageElement); const backgroundBlurAmount \= 3; const edgeBlurAmount \= 3; const flipHorizontal \= true; const faceBodyPartIdsToBlur \= \[0, 1\]; const canvas \= document.getElementById(&#39;canvas&#39;); bodyPix.blurBodyPart( canvas, imageElement, partSegmentation, faceBodyPartIdsToBlur, backgroundBlurAmount, edgeBlurAmount, flipHorizontal);
</span></span></code></pre></td></tr></table></div></div><h2 id=httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixdeveloping-the-demosdeveloping-the-demos><a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#developing-the-demos target=_blank rel=noopener></a>Developing the Demos</h2><p>Details for how to run the demos are included in the <code>demos/</code> folder.</p><p>from Hacker News <a class=link href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix target=_blank rel=noopener>https://github.com/tensorflow/tfjs-models/tree/master/body-pix</a></p></section><footer class=article-footer><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg><span>Licensed under CC BY-NC-SA 4.0</span></section></footer></article><footer class=site-footer><section class=copyright>&copy;
2020 -
2022 ZYChimne</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.11.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css integrity="sha256-c0uckgykQ9v5k+IqViZOZKc47Jn7KQil4/MP3ySA3F8=" crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.css integrity="sha256-SBLU4vv6CA6lHsZ1XyTdhyjJxCjPif/TRkjnsyGAGnE=" crossorigin=anonymous></main><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixnote-weve-just-released-version-20-with-multi-person-support-a-new-resnet-model-and-api-check-out-the-new-documentation-belownote-weve-just-released-version-20-with-multi-person-support-a-new-resnet-model-and-api-check-out-the-new-documentation-below><a href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#note-weve-just-released-version-20-with-multi-person-support-a-new-resnet-model-and-api-check-out-the-new-documentation-below></a>Note: We&rsquo;ve just released Version 2.0 with <strong>multi-person</strong> support, a <strong>new ResNet</strong> model and API. Check out the new documentation below.</a></li><li><a href=#httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixcontributorscontributors><a href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#contributors></a>Contributors</a><ol><li><a href=#httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixmain-contributorsmain-contributors><a href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#main-contributors></a>Main Contributors</a></li><li><a href=#httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixacknowledgementacknowledgement><a href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#acknowledgement></a>Acknowledgement</a></li><li><a href=#httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixspecial-thanks-for-participants-in-the-demo-videospecial-thanks-for-participants-in-the-demo-video><a href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#special-thanks-for-participants-in-the-demo-video></a>Special thanks for participants in the demo video</a></li></ol></li><li><a href=#httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixtables-of-contentstables-of-contents><a href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#tables-of-contents></a>Tables of Contents</a></li><li><a href=#httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixinstallationinstallation><a href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#installation></a>Installation</a></li><li><a href=#httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixusageusage><a href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#usage></a>Usage</a><ol><li><a href=#httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixloading-a-pre-trained-bodypix-modelloading-a-pre-trained-bodypix-model><a href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#loading-a-pre-trained-bodypix-model></a>Loading a pre-trained BodyPix Model</a><ol><li><a href=#httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixmobilenet-smaller-faster-less-accuratemobilenet-smaller-faster-less-accurate><a href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#mobilenet-smaller-faster-less-accurate></a>MobileNet (smaller, faster, less accurate)</a></li><li><a href=#httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixresnet-larger-slower-more-accurate-newresnet-larger-slower-more-accurate-new><a href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#resnet-larger-slower-more-accurate-new></a>ResNet (larger, slower, more accurate) **new!**</a></li><li><a href=#httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixconfig-params-in-bodypixloadconfig-params-in-bodypixload><a href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#config-params-in-bodypixload></a>Config params in bodyPix.load()</a></li></ol></li><li><a href=#httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixperson-segmentationperson-segmentation><a href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#person-segmentation></a>Person segmentation</a><ol><li><a href=#httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixparams-in-estimatemultipersoninstancesegmentationparams-in-estimatemultipersoninstancesegmentation><a href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#params-in-estimatemultipersoninstancesegmentation></a>Params in estimateMultiPersonInstanceSegmentation()</a></li><li><a href=#httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixreturnsreturns><a href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#returns></a>Returns</a></li><li><a href=#httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixexample-usageexample-usage><a href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#example-usage></a>Example Usage</a></li></ol></li><li><a href=#httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixmulti-person-body-part-segmentationmulti-person-body-part-segmentation><a href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#multi-person-body-part-segmentation></a>Multi-person body part segmentation</a><ol><li><a href=#httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixthe-body-partsthe-body-parts><a href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#the-body-parts></a>The Body Parts</a></li><li><a href=#httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixparams-in-estimatemultipersoninstancesegmentation-1params-in-estimatemultipersoninstancesegmentation><a href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#params-in-estimatemultipersoninstancesegmentation-1></a>Params in estimateMultiPersonInstanceSegmentation</a></li><li><a href=#httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixreturns-1returns><a href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#returns-1></a>Returns</a></li><li><a href=#httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixexample-usage-1example-usage><a href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#example-usage-1></a>Example Usage</a></li></ol></li><li><a href=#httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixoutput-visualization-utility-functionsoutput-visualization-utility-functions><a href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#output-visualization-utility-functions></a>Output Visualization Utility Functions</a><ol><li><a href=#httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixtomaskimagedatatomaskimagedata><a href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#tomaskimagedata></a><code>toMaskImageData</code></a></li><li><a href=#httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixtocoloredpartimagedatatocoloredpartimagedata><a href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#tocoloredpartimagedata></a><code>toColoredPartImageData</code></a></li><li><a href=#httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixdrawmaskdrawmask><a href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#drawmask></a><code>drawMask</code></a></li><li><a href=#httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixdrawpixelatedmaskdrawpixelatedmask><a href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#drawpixelatedmask></a><code>drawPixelatedMask</code></a></li><li><a href=#httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixdrawbokeheffectdrawbokeheffect><a href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#drawbokeheffect></a><code>drawBokehEffect</code></a></li><li><a href=#httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixblurbodypartblurbodypart><a href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#blurbodypart></a><code>blurBodyPart</code></a></li></ol></li></ol></li><li><a href=#httpsgithubcomtensorflowtfjs-modelstreemasterbody-pixdeveloping-the-demosdeveloping-the-demos><a href=https://github.com/tensorflow/tfjs-models/tree/master/body-pix#developing-the-demos></a>Developing the Demos</a></li></ol></nav></div></section></aside></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.5/dist/vibrant.min.js integrity="sha256-5NovOZc4iwiAWTYIFiIM7DxKUXKWvpVEuMEPLzcm5/g=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script>
<script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>